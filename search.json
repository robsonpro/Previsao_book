[
  {
    "objectID": "ST6.html#estacionariedade-em-séries-temporais",
    "href": "ST6.html#estacionariedade-em-séries-temporais",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "",
    "text": "6.1.1 Diferenciação\nA diferenciação é útil para tornar uma série não estacionária em estacionária. Apesar de muitas séries observadas na indústria, na economia em negócios apresentarem mudança nas suas propriedades, o comportamento da variação da série, isto é, o comportamento da série diferenciada é geralmente estacionário (Box et al. 2008). Logo, a diferenciação serve para remover a variação no nível de uma série, estabilizando sua média.\nA diferenciação consiste na variação entre observações subsequentes. Ou seja, considernado uma série com \\(T\\) observações, a série diferenciada contém ao final \\(T-1\\) observações. A série diferenciada é denotada \\(y_t'\\), sendo obtida conforme a Equação 6.1.\n\\[\ny_t' = y_t-y_{t-1}\n\\tag{6.1}\\]\nA Tabela 6.1 expõe as primeiras observações na série do índice Ibovespa e variação deste. Observa-se para estas primeiras observações variação positiva para maioria dos dias, mas também variações negativas.\n\n\n\n\nTabela 6.1: Primeiras observações do índice Ibovespa e sua variação\n\n\n\n\n\n\nFechamento\nVariação\n\n\n\n\n131,59\nNA\n\n\n132,16\n0,57\n\n\n130,57\n-1,59\n\n\n131,06\n0,50\n\n\n133,12\n2,06\n\n\n133,75\n0,62\n\n\n134,96\n1,21\n\n\n135,12\n0,16\n\n\n134,88\n-0,24\n\n\n134,03\n-0,85\n\n\n\n\n\n\n\n\nSe a série diferenciada consiste em um ruído branco, \\(\\varepsilon_t\\), então pode-se escrever:\n\\[\ny_t-y_{t-1} = \\varepsilon_t\n\\]\nUm modelo onde a observação posterior é igual à anterior adicionada de um ruído branco, \\(y_t = y_{t-1}+\\varepsilon_t\\), é chamado de caminhada aleatória (random walk). O modelo de caminhada aleatória estima a próxima observação igual à anterior, \\(\\hat y_t = y_{t-1}\\), conforme o método ingênuo. No caso de média não nula, como a maior parte das séries, pode-se adicionar uma constante, conforme segue, onde \\(c\\) é estimada pela média das diferenças.\n\\[\ny_t-y_{t-1} = \\varepsilon_t + c\n\\]\nA Figura 6.2 expõe a série não estacionária do índice Ibovespa, além da série obtida a partir da diferenciação desta, que obviamente consiste na variação diária do índice. A série diferenciada apresenta estacionariedade. A Figura exibe também os correlogramas da série do índice e da variação deste. Observa-se que a série diferenciada, ao contrário da original, não apresenta autocorrelação.\n\n\n\n\n\n\n\n\nFigura 6.2: Série temporal não estacionária, diferenciação e autocorrelação\n\n\n\n\n\nO modelo de caminhada aleatória é muito útil para séries econométricas e de finanças. Geralmente tais séries apresentam longos períodos de tendência de queda ou crescimento, com mudanças inesperadas de difícil explicação.\nEm casos onde a diferenciação de primeira ordem não garante a estacionariedade, pode-se ainda aplicar uma diferenciação de segunda ordem, conforme expresso na Equação 6.2.\n\\[\n\\begin{align}\ny_t'' &= y_t'-y_{t-1}' \\\\\n      &= (y_t-y_{t-1})-(y_{t-1}-y_{t-2}) \\\\\n      &= y_t-2y_{t-1}+y_{t-2}\n\\end{align}\n\\tag{6.2}\\]\nEm séries sazonais é importante aplicar a diferenciação sazonal, conforme exposto na Equação 6.3, onde \\(m\\) é o número de períodos sazonais.\n\\[\ny_t'= y_t - y_{t-m}\n\\tag{6.3}\\]\nA Figura 6.3 apresenta a série de passageiros em vôos do Brasil. Foi aplicado logaritmo para estabilizar a variação anual. Posteriormente, foi realizada diferenciação sazonal, \\(m=12\\). Em seguida, realizou-se a diferenciação simples, de forma a garantir a estacionariedade. Pode-se observar que a diferenciação anual elimina a sazonalidade e a mensal a tendência.\n\n\n\n\n\n\n\n\nFigura 6.3: Passageiros em vôos do Brasil: série original, log da série, variação sazonal e variação de segunda ordem\n\n\n\n\n\nTomando a diferenciação de primeira ordem como sendo sazonal, \\(y' = y_t-y_{t-m}\\), então a diferenciação de segunda ordem pode ser expressa conforme a Equação 6.4.\n\\[\n\\begin{align}\ny'' &= y'-y'_{t-1} \\\\\n    &= (y_t-y_{t-m})-(y_{t-1}-y_{t-m-1}) \\\\\n    &= y_t - y_{t-m} -y_{t-1}+y_{t-m-1} \\\\\n\\end{align}\n\\tag{6.4}\\]\n\n\n6.1.2 Testes de raízes unitárias\nUm modelo autoregressivo de primeira ordem, \\(y_t = \\phi y_{t-1}+\\varepsilon_t\\), consiste em um modelo estacionário se \\(|\\phi|&lt;1\\). Se \\(\\phi=1\\), tem-se um modelo de caminhada aleatória, a série tem raiz unitária e é, consequentemente, não estacionária (Box et al. 2008). Logo, os testes de raízes unitárias tem o objetivo de avaliar se a série apresenta ou não estacionariedade.\nO teste de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) (Kwiatkowski et al. 1992) é uma opção, com a hipótese nula indicando a estacionariedade da série. A Tabela 6.2 apresenta o resultado do teste para a série do índice Ibovespa, indicando a rejeição da hipótese nula de estacionariedade, sendo necessária a diferenciação da série. A Tabela 6.3 apresenta o resultado do teste para a série do índice diferenciada. Observa-se neste caso que o resultado sugere que a hipótese nula de estacionariedade da série não deve ser rejeitada.\n\n\n\n\nTabela 6.2: Teste KPSS para o índice Ibovespa\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n0,7490546\n0,01\n\n\n\n\n\n\n\n\n\n\n\n\nTabela 6.3: Teste KPSS para a variação do índice Ibovespa\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n0,1841354\n0,1\n\n\n\n\n\n\n\n\n\n\n6.1.3 Operador de defasagem\nO operador ou notação de defasagem (backward shift notation - \\(B\\)) é útil para trabalhar com diferenciação (Box et al. 2008), defasagem (lag) e para representação de modelos ARIMA. O operador \\(B\\) em \\(y_t\\) defasa a observação em um período no tempo, conforme Equação 6.5.\n\\[\nBy_t = y_{t-1}\n\\tag{6.5}\\]\nNo caso de defasagem de segunda ordem, tem-se:\n\\[\nB(By_t) = B^2y_t = By_{t-1} = y_{t-2}\n\\]\nPara casos sazonais pode-se usar a diferenciação sazonal. Por exemplo, em séries de frquência horária e sazonalidade diária, pode ser útil usar \\(B^{24}y_t = y_{t-24}\\), de forma a retornar na mesma hora no dia anterior.\nA diferenciação de primeira ordem com a notação de defasagem pode ser escrita segundo a Equação 6.6.\n\\[\n\\begin{align}\ny'_t &= y_t-y_{t-1} \\\\\n     &=y_t-By_t \\\\\n     &=(1-B)y_t\n\\end{align}\n\\tag{6.6}\\]\nDe forma análoga, a diferenciação de segunda ordem fica segundo a Equação 6.7.\n\\[\n\\begin{align}\ny_t'' &= y_t-2y_{t-1}+y_{t-2} \\\\\n      &= y_t-2By_t+B^2y_t \\\\\n      &= (1-B)^2y_t\n\\end{align}\n\\tag{6.7}\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#modelos-autorregressivos",
    "href": "ST6.html#modelos-autorregressivos",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.2 Modelos autorregressivos",
    "text": "6.2 Modelos autorregressivos\nUm modelo autorregressivo consiste em um modelo de regressão para a série, \\(y_t\\), em função do seu passado, isto é, em função de termos defasados da série, \\(y_{t-1}, y_{t-2}, ..., y_{t-p}\\). Um modelo autorregressivo de ordem \\(p\\) ou \\(AR(p)\\) pode ser escrito segundo a Equação 6.8.\n\\[\n\\begin{align}\ny_t &= c+\\phi_1y_{t-1} + \\phi_2y_{t-2} + \\ldots + \\phi_py_{t-p} + \\varepsilon_t \\\\\n    &= c+\\phi_1By_t + \\phi_2B^2y_t + \\ldots + \\phi_pB^py_t + \\varepsilon_t \\\\\n\\end{align}\n\\tag{6.8}\\]\nEm um modelo autoregressivo de primeira ordem, tem-se \\(y_t = c+ \\phi_1 y_{t-1} + \\varepsilon_t\\). Em uma série estacionária tem-se \\(E(y_t) = E(y_{t-1}) = \\mu_y\\). Subtraindo-se a média tanto na série quanto no termo defasado, pode-se eliminar a constante:\n\\[\n\\begin{align}\ny_t - \\mu_y=& \\phi_1(y_{t-1}-\\mu_y) + \\varepsilon_t \\\\\ny_t =& \\phi_1y_{t-1}+ \\mu_y -\\phi_1\\mu_y + \\varepsilon_t \\\\\ny_t =& \\phi_1y_{t-1}+ \\mu_y(1 -\\phi_1) + \\varepsilon_t \\\\\n\\end{align}\n\\]\nLogo, \\(c=\\mu_y(1 -\\phi_1)\\) para um modelo \\(AR(1)\\) e, generalizando, \\(c = \\mu_y(1-\\phi_1-\\phi_2-...-\\phi_p) = \\mu_y(1-\\sum_i^p \\phi_i)\\) para um modelo \\(AR(p)\\) (Makridakis, Wheelwright, e Hyndman 2008; Hamilton 1994). Para \\(\\mu_y=0\\), pode-se usar a representação com notação de defasagem da Equação 6.9. Pode-se observar que tal modelo é um modelo de regressão que ao invés de considerar outras variáveis independentes, considera valores anteriores da prória série, sendo, portanto, um modelo autoregressivo. Tal modelo não deve, entretanto, ser tratado como um modelo de regressão obtido por mínimos quadrados. Primeiro, porque a independência dos erros pode ser violada, dado o usual relacionamento entre os termos do lado direito. Segundo, pois a determinação da maior defasagem, \\(p\\), no modelo não é simples (Makridakis, Wheelwright, e Hyndman 2008).\n\\[\n(1-\\phi_1B- \\phi_2B^2 - \\ldots - \\phi_pB^p)y_t = \\varepsilon_t \\\\\n\\tag{6.9}\\]\nA Figura 6.4 expõe séries temporais que seguem processos autorregressivos \\(AR(1)\\) e \\(AR(2)\\). Na Figura 6.4(a) tem-se um processo autorregressivo de primeira ordem, \\(AR(1)\\), com \\(y_t=15-0.5y_{t-1}+\\varepsilon_t\\). Na Figura 6.4(b) tem-se um processo autorregressivo de segunda ordem, \\(AR(2)\\), com \\(y_t = 8+1.3y_{t-1}-0.7y_{t-2}+\\varepsilon_t\\).\n\n\n\n\n\n\n\n\nFigura 6.4: Processos autorregressivos\n\n\n\n\n\nOs processos autorregressivos são muito flexíveis. A mudança dos parâmetros \\(\\phi_1,..., \\phi_p\\) pode resultar em padrões de séries temporais muito distintos (R. Hyndman e Athanasopoulos 2021).\nPara um modelo \\(AR(1)\\), \\(y_t=c+\\phi_1y_{t-1} + \\varepsilon_t\\):\n\nSe \\(c=0\\) e \\(\\phi_1=0\\), tem-se um ruído branco.\nSe \\(c=0\\) e \\(\\phi_1=1\\), tem-se uma caminhada aleatória.\nSe \\(c\\neq0\\) e \\(\\phi_1=1\\), tem-se uma caminhada aleatória com deriva.\nSe \\(\\phi_1&lt;1\\), \\(y_t\\) tende a oscilar em torno da média.\n\nOs processos autorregressivos são úteis para modelar séries estacionárias, devendo satisfazer algumas restrições:\n\nPara um modelo \\(AR(1)\\): \\(-1&lt;\\phi_1&lt;1\\).\nPara um modelo \\(AR(2)\\): \\(-1&lt;\\phi_2&lt;1\\), \\(\\phi_1+\\phi_2&lt;1\\), \\(\\phi_2-\\phi_1&lt;1\\).\n\n\n6.2.1 Previsão para modelos autoregressivos\nA previsão para um modelo \\(AR(1)\\) pode ser realizada de forma simples. Seja o modelo \\(y_t = c + \\phi y_{t-1} + \\varepsilon_t\\). A previsão para um período à frente das observações disponíveis, \\(\\hat y_{T+1}\\), pode ser obtida segundo Equação 6.10.\n\\[\n\\hat y_{T+1} = c + \\phi y_{T}\n\\tag{6.10}\\]\nDe forma análoga, para dois períodos à frente, a previsão fica:\n\\[\n\\begin{align}\n\\hat y_{T+2} =& c + \\phi y_{T+1} \\\\\n\\hat y_{T+2} =& c + \\phi (c + \\phi y_{T}) \\\\\n\\hat y_{T+2} =& c + \\phi c + \\phi^2 y_{T} \\\\\n\\hat y_{T+2} =& c(1 + \\phi) + \\phi^2 y_{T} \\\\\n\\end{align}\n\\]\nSeguindo este raciocício recursivo, pode-se obter a previsão para \\(h\\) períodos à frente para um modelo \\(AR(1)\\) conforme Equação 6.11.\n\\[\n\\hat y_{T+h} = c(1 + \\phi + \\phi^2 + \\dots+\\phi^{h-1}) + \\phi^h y_{T}\n\\tag{6.11}\\]\nFazendo:\n\\[S_h = 1 + \\phi + \\phi^2 + \\dots+\\phi^{h-1}\\],\nlogo,\n\\[\\phi S_h = \\phi + \\phi^2 + \\dots+\\phi^{h}\\].\nPortanto,\n\\[\n\\begin{align}\nS_h - \\phi S_h =& 1-\\phi^h \\\\\nS_h(1-\\phi) =& 1-\\phi^h \\\\\nS_h =& \\frac{1-\\phi^h}{1-\\phi}, \\text{} |\\phi|&lt;1.\n\\end{align}\n\\]\nConsequentemente, a previsão para um modelo \\(AR(1)\\) também pode ser escrita segundo a Equação 6.12, pois, conforme já visto, \\(c=\\mu(1-\\phi)\\).\n\\[\n\\begin{align}\n\\hat y_{T+h} =& c\\frac{1-\\phi^h}{1-\\phi} + \\phi^h y_{T} \\\\\n\\hat y_{T+h} =& \\mu_y + \\phi^h (y_{T}-\\mu_y)\n\\end{align}\n\\tag{6.12}\\]\nJá para modelos de média móvel de ordem genérica, \\(AR(p)\\), não há uma fórmula tão simples, usa-se simplesmente o processo recursivo de previsão. Portanto, para \\(h=1\\), a previsão fica segundo a Equação 6.13.\n\\[\n\\hat y_{T+1} = c+\\phi_1y_{T} + \\phi_2y_{T-1} + \\ldots + \\phi_py_{T+1-p}\n\\tag{6.13}\\]\nPara \\(h\\) períodos à frente, a previsão para um modelo \\(AR(p)\\) é obtida a partir da Equação 6.14.\n\\[\n\\hat y_{T+h} = c+\\phi_1y_{T+h-1} + \\phi_2y_{T+h-2} + \\ldots + \\phi_py_{T+h-p}\n\\tag{6.14}\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#modelos-de-média-móvel",
    "href": "ST6.html#modelos-de-média-móvel",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.3 Modelos de média móvel",
    "text": "6.3 Modelos de média móvel\nUm modelo de média móvel considera os erros passados ao invés das observações passadas, sendo um modelo de média móvel de ordem \\(q\\), \\(MA(q)\\) definido conforme Equação 6.15. Como os valores do erro não são observáveis, este modelo também não é uma regressão habitual (R. Hyndman e Athanasopoulos 2021).\n\\[\n\\begin{align}\ny_t&=c+\\varepsilon_t+\\theta_1\\varepsilon_{t-1} + \\theta_2\\varepsilon_{t-2} + \\ldots + \\theta_q\\varepsilon_{t-q}\\\\\n&=c+\\varepsilon_t+\\theta_1B\\varepsilon_t+\\theta_2B^2\\varepsilon_t+\\ldots+\\theta_qB^q\\varepsilon_t \\\\\n&=c+ (1+\\theta_1B+\\theta_2B^2+\\ldots+\\theta_qB^q)\\varepsilon_t\n\\end{align}\n\\tag{6.15}\\]\nÉ importante também distinguir os modelos \\(MA(q)\\) dos modelos de média móvel para suavização. Enquanto os modelos aqui apresentados tem o objetivo de realizar previsões, os de suavização visam estimar a tendência de observações passadas de séries temporais.\nA Figura 6.5 ilustra processos de média móvel. Na Figura 6.5(a) um processo de média móvel de primeira ordem, \\(MA(1)\\), é observado com \\(y_t = 15 + \\varepsilon_t + 0.6\\varepsilon_{t-1}\\). Na Figura 6.5(b) tem-se um processo de média móvel de segunda ordem, \\(MA(2)\\), com \\(y_t = 8 + \\varepsilon_t - 0.9\\varepsilon_{t-1} + 0.5\\varepsilon_{t-2}\\). Mudando os parâmetros \\(\\theta_1, ..., \\theta_q\\) a série varia significativamente. Assim como nos modelos autorregressivos, nos de média móvel a variância do erro \\(\\sigma_\\varepsilon\\) só muda a amplitude da série, não o padrão.\n\n\n\n\n\n\n\n\nFigura 6.5: Processos de média móvel\n\n\n\n\n\nQualquer processo estacionário \\(AR(p)\\) pode ser escrito como um processo \\(MA(\\infty)\\). Para o caso \\(AR(1)\\), tem-se:\n\\[\n\\begin{align}\ny_t &= \\phi_1y_{t-1} + \\varepsilon_t\\\\\n    &=  \\phi_1(\\phi_1y_{t-2} + \\varepsilon_{t-1}) + \\varepsilon_t\\\\\n    &= \\phi_1^2y_{t-2} + \\phi_1\\varepsilon_{t-1} + \\varepsilon_t\\\\\n    &= \\phi_1^3y_{t-3} + \\phi_1^2\\varepsilon_{t-2} + \\phi_1\\varepsilon_{t-1} + \\varepsilon_t\\\\\n    &= ...\\\\\n\\end{align}\n\\]\nÀ medida que \\(k\\) aumenta, \\(\\phi_1^k\\) diminui, considerando \\(-1&lt;\\phi_1&lt;1\\), de forma que o termo de potência maior pode ser desconsiderado. Fazendo \\(\\phi_1 = \\theta_1\\), \\(\\phi_1^2 = \\theta_2\\) e assim sucessivamente, tem-se o modelo de média móvel inicialmente exposto. De forma análoga, impondo algumas restrições nos parâmetros do modelo \\(MA(q)\\) é possível escrevê-lo como um processo \\(AR(\\infty)\\).\n\n6.3.1 Previsão para modelos de média móvel\nConsiderando inicialmente um modelo de média móvel \\(MA(1)\\), \\(y_t = c + \\varepsilon_t + \\theta_1\\varepsilon_{t-1}\\), seja a previsão um período à frente, \\(h=1\\), obtida segundo a Equação 6.16, pois \\(\\varepsilon_{T+1},\\dots,\\varepsilon_{T+h}\\) são desconhecidos e tem esperança nula. A constante \\(c\\) pode ser estimada segundo a média da série, \\(c=\\mu_y\\).\n\\[\n\\begin{align}\n\\hat y_{T+1} &= c + \\varepsilon_{T+1} + \\theta_1\\varepsilon_{T} \\\\\n\\hat y_{T+1} &= c + \\theta_1\\varepsilon_{T}\n\\end{align}\n\\tag{6.16}\\]\nJá para \\(h \\ge 2\\) a previsão consiste apenas na constante, conforme Equação 6.17.\n\\[\n\\begin{align}\n\\hat y_{T+1} &= c + \\varepsilon_{T+2} + \\theta_1\\varepsilon_{T+1} \\\\\n\\hat y_{T+1} &= c\n\\end{align}\n\\tag{6.17}\\]\nPara um modelo de média-móvel de ordem \\(q\\), \\(MA(q)\\) a previsão para um período à frente pode ser obtida segundo a Equação 6.18.\n\\[\n\\begin{align}\n\\hat y_{T+1}&=c+\\varepsilon_{T+1}+\\theta_1\\varepsilon_{T} + \\theta_2\\varepsilon_{T-1} + \\ldots + \\theta_q\\varepsilon_{T+1-q} \\\\\n\\hat y_{T+1}&=c+\\theta_1\\varepsilon_{T} + \\theta_2\\varepsilon_{T-1} + \\ldots + \\theta_q\\varepsilon_{T+1-q}\n\\end{align}\n\\tag{6.18}\\]\nA previsão sempre conterá termos de erros observados, portanto, se \\(h&gt;q\\), ou seja, se o período de previsão for maior que a ordem do modelo, todos os termos de erro serão desconhecidos e a previsão será igual à constante, conforme Equação 6.19.\n\\[\n\\hat y_{T+h}=c\n\\tag{6.19}\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#modelos-arima-não-sazonais",
    "href": "ST6.html#modelos-arima-não-sazonais",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.4 Modelos ARIMA não sazonais",
    "text": "6.4 Modelos ARIMA não sazonais\nUm modelo autorregressivo integrado de média móvel (ARIMA) combina um modelo autorregressivo da série diferenciada e um de média móvel. Para diferenciação de primeira ordem o modelo é expresso segundo a Equação 6.20.\n\\[\n\\begin{align}\ny_t'&=c+\\phi_1y'_{t-1} + \\phi_2y'_{t-2} + \\ldots + \\phi_py'_{t-p} + \\theta_1\\varepsilon_{t-1} + \\theta_2\\varepsilon_{t-2} + \\ldots + \\theta_q\\varepsilon_{t-q} + \\varepsilon_t \\\\\n&= c+\\phi_1By'_t + \\phi_2B^2y'_t + \\ldots + \\phi_pB^py'_t+\\theta_1B\\varepsilon_t + \\theta_2B^2\\varepsilon_t + \\ldots + \\theta_qB^q\\varepsilon_t + \\varepsilon_t \\\\\n\\end{align}\n\\tag{6.20}\\]\nLogo, considerando ordem de diferenciação \\(d\\), pode-se representar um modelo \\(ARIMA(p,d,q)\\) usando a Equação 6.21.\n\\[\n(1-\\phi_1B- \\ldots - \\phi_pB^p)(1-B)^dy_t = c+( 1+\\theta_1B+\\ldots+\\theta_qB^q)\\varepsilon_t.\n\\tag{6.21}\\]\nQuando não é necessária a diferenciação da série, isto é, \\(d=0\\), tem-se um modelo \\(ARMA(p,d)\\) (Box et al. 2008). A Tabela 6.4 expõe a sintaxe do modelo ARIMA correspondente para alguns casos especiais já conhecidos.\n\n\n\nTabela 6.4: Casos especiais e modelos ARIMA correspondentes\n\n\n\n\n\nCaso especial\nModelo\n\n\n\n\nRuído branco\n\\(ARIMA(0,0,0)\\) sem cte\n\n\nCaminhada aleatória\n\\(ARIMA(0,1,0)\\) sem cte\n\n\nCaminhada aleatória com deriva\n\\(ARIMA(0,1,0)\\) com cte\n\n\nAutorregressão\n\\(ARIMA(p,0,0)\\)\n\n\nMédia móvel\n\\(ARIMA(0,0,q)\\)\n\n\n\n\n\n\nA Figura 6.6 expõe a série temporal do volume de produção de coque no Brasil a partir de 2021.\n\n\n\n\n\n\n\n\nFigura 6.6: Volume de produção de coque no Brasil\n\n\n\n\n\nÉ difícil selecionar apropriadamente os valores adequados de \\(p,d,q\\) ao se estimar um modelo ARIMA para uma série de interesse. O pacote fable auxilia na otimização destes parâmetros segundo a série em análise. A seguir expõe-se o resultado do modelo ARIMA obtido automaticamente.\n\n\nSeries: value \nModel: ARIMA(1,0,0) w/ mean \n\nCoefficients:\n         ar1    constant\n      0,2763  271035,558\ns.e.  0,1433    4547,139\n\nsigma^2 estimated as 969282769:  log likelihood=-516,68\nAIC=1039,35   AICc=1039,95   BIC=1044,7\n\n\nFoi obtido um modelo ARIMA(1,0,0) exposto a seguir, onde \\(\\varepsilon_t\\) é ruído branco com \\(\\sigma_\\varepsilon = 31133,31\\).\n\\[\ny_t = 271035,56 + 0,28y_{t-1} + \\varepsilon_t\n\\]\nA Figura 6.7 expõe a previsão de 10 meses à frente usando tal modelo.\n\n\n\n\n\n\n\n\nFigura 6.7\n\n\n\n\n\nA Figura 6.8 expõe a série temporal do valor da ação VALE3 a partir de 2020.\n\n\n\n\n\n\n\n\nFigura 6.8: Série temporal do valor da ação VALE3\n\n\n\n\n\nAbaixo expõe-se o modelo ARIMA obtido para a série.\n\n\nSeries: Valor \nModel: ARIMA(2,0,2) w/ mean \n\nCoefficients:\n         ar1      ar2      ma1     ma2  constant\n      1,4603  -0,7901  -0,6441  0,4800   23,9391\ns.e.  0,1549   0,1356   0,2359  0,1225    0,5966\n\nsigma^2 estimated as 25,64:  log likelihood=-135,27\nAIC=282,53   AICc=284,74   BIC=293,37\n\n\nFoi obtido um modelo \\(ARIMA(2,0,2)\\):\n\\[\ny_t = 23,94 + 1,46y_{t-1} - 0,79y_{t-2} -0,64\\varepsilon_{t-1} + 0,48\\varepsilon_{t-2} + \\varepsilon_t\n\\]\nA Figura 6.9 expõe os gráficos dos resíduos do modelo ARIMA(2,0,2) aplicado à série do preço da ação VALE3. Observa-se um padrão de ruído branco, com ausência de autocorrelação.\n\n\n\n\n\n\n\n\nFigura 6.9: Resíduos do modelo ARIMA(2,0,2) para a série do valor da ação VALE3\n\n\n\n\n\nConforme Figura 6.10, dada a previsão 10 meses à frente exibida, o modelo capturou bem o padrão cíclico não sazonal da série.\n\n\n\n\n\n\n\n\nFigura 6.10: Série temporal do valor da ação VALE3\n\n\n\n\n\n\n6.4.1 Previsão com modelos ARIMA não sazonais\nA previsão em modelos ARIMA é realizada usando o modelo ARIMA obtido, considerando o número de períodos à frente de interesse, \\(h\\), à frente das observações disponíveis, \\(T+h\\). Para um modelo ARIMA com \\(d=1\\), considerando um período à frente, \\(h=1\\), a previsão é realizada segundo a Equação 6.22, onde o termo de erro para \\(t=T+1\\) é desconhecido e tem esperança nula, \\(E[\\varepsilon_{T+1}]=0\\). Para períodos de previsão maiores, \\(h\\ge2\\), faz-se recursivamente a previsão, de forma similar ao demonstrado para os modelos autoregressivos e os de média móvel, lembrando que este último apresentará todos termos de erro nulos sempre que \\(h\\geq q\\), uma vez que são desconhecidos.\n\\[\n\\begin{align}\ny_{T+1}'&=c+\\phi_1y'_{T} + \\phi_2y'_{T-1} + \\ldots + \\phi_py'_{T+1-p} + \\theta_1\\varepsilon_{T} + \\theta_2\\varepsilon_{T-1} + \\ldots + \\theta_q\\varepsilon_{T+1-q} + \\varepsilon_{T+1} \\\\\n\\hat y_{T+1}'&=c+\\phi_1y'_{T} + \\phi_2y'_{T-1} + \\ldots + \\phi_py'_{T+1-p} + \\theta_1\\varepsilon_{T} + \\theta_2\\varepsilon_{T-1} + \\ldots + \\theta_q\\varepsilon_{T+1-q} \\\\\n\\hat y_{T+1} - y_{T} &= c + \\phi_1(y_T-y_{T-1}) + \\phi_2(y_{T-1}-y_{T-2}) + \\dots + \\theta_1\\varepsilon_{T} + \\theta_2\\varepsilon_{T-1} + \\ldots + \\theta_q\\varepsilon_{T+1-q}  \\\\\n\\hat y_{T+1} &= c + y_{T} + \\phi_1y_T-\\phi_1y_{T-1} + \\phi_2y_{T-1}-\\phi_2y_{T-2} + \\dots + \\theta_1\\varepsilon_{T} + \\theta_2\\varepsilon_{T-1} + \\ldots + \\theta_q\\varepsilon_{T+1-q}  \\\\\n\\hat y_{T+1} &= c + y_{T}(1 + \\phi_1)+y_{T-1}(\\phi_2-\\phi_1) + \\dots + \\theta_1\\varepsilon_{T} + \\theta_2\\varepsilon_{T-1} + \\ldots + \\theta_q\\varepsilon_{T+1-q}  \\\\\n\\end{align}\n\\tag{6.22}\\]\nEm um modelo ARIMA se \\(c=0\\) e \\(d=0\\), então a previsão de longo prazo tenderá para zero. Se \\(c=0\\) e \\(d=1\\), a previsão a longo prazo tenderá para uma constante. Se \\(c=0\\) e \\(d=2\\), a previsão a longo prazo será linear. Se \\(c\\neq0\\) e \\(d=0\\), a previsão a longo prazo será a média das observações. Se \\(c\\neq0\\) e \\(d=1\\) a previsão a longo prazo será linear. Para previsões cíclicas é importante \\(p\\geq2\\) (R. Hyndman e Athanasopoulos 2021).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#autocorrelação-parcial",
    "href": "ST6.html#autocorrelação-parcial",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.5 Autocorrelação parcial",
    "text": "6.5 Autocorrelação parcial\nA autocorrelação \\(r_k\\) mede a relação linear entre a série original \\(y_t\\) e a série defasada \\(y_{t-k}\\). Entretanto, se \\(y_t\\) e \\(y_{t-1}\\) são correlacionadas, então \\(y_{t-1}\\) e \\(y_{t-2}\\) também serão. Logo, haverá correlação entre \\(y_t\\) e \\(y_{t-2}\\). Porém, não porque necessariamente há uma explicação plausível para \\(y_t\\) a partir de \\(y_{t-2}\\), mas simplesmente porque ambas estão relacionadas indiretamente por \\(y_{t-1}\\).\nA autocorrelação parcial visa corrigir este viés da autocorrelação, medindo mais diretamente a relação linear entre \\(y_t\\) e \\(y_{t-k}\\) desconsiderando os efeitos das defasagens anteriores, \\(1,2,\\ldots, k-1\\).\nA Figura 6.11 expõe os correlogramas de autocorrelação (ACF) e de autocorrelação parcial (PACF) da série do preço da ação VALE3. Observa-se um padrão sinusoidal em ambos correlogramas e a última autocorrelação parcial significativa com \\(k=3\\).\n\n\n\n\n\n\n\n\nFigura 6.11: Autocorrelação e autocorrelação parcial da série VALE3\n\n\n\n\n\nOs correlogramas de ACF e PACF podem auxiliar na definição da ordem do modelo ARIMA em casos \\(ARIMA(0,d,q)\\) e \\(ARIMA(p,d,0)\\). Para séries que seguem um padrão \\(ARIMA(0,d,q)\\):\n\nA autocorrelação parcial (PACF) decai exponencialmente ou tem padrão senoidal;\nHá significância na autocorrelação (ACF) de lag \\(q\\), mas não além deste.\n\nPara séries que seguem um padrão \\(ARIMA(p,d,0)\\):\n\nA autocorrelação (ACF) decai exponencialmente ou tem padrão senoidal;\nHá significância na autocorrelação parcial (PACF) de lag \\(p\\), mas não além deste.\n\nA seguir apresenta-se o resultado do modelo ARIMA(3,0,0) para a série da ação VALE3 indicado pela interpretação dos correlogramas da Figura 6.11. O modelo obtido apresentou resultado para \\(AICc\\) muito próximo ao obtido pela estimativa automática apresentado anteriormente.\n\n\nSeries: Valor \nModel: ARIMA(3,0,0) w/ mean \n\nCoefficients:\n         ar1     ar2      ar3  constant\n      0,8779  0,1577  -0,4693   31,4916\ns.e.  0,1268  0,1812   0,1290    0,7465\n\nsigma^2 estimated as 26,71:  log likelihood=-136,62\nAIC=283,25   AICc=284,78   BIC=292,28\n\n\n\n6.5.1 Modelagem e seleção de modelos\nOs modelos ARIMA podem ser estimados de distintas formas. Para um modelo de ordem \\(p,d,q\\) pode-se maximizar o log da máxima verossimilhança para estimar os parâmetros \\(c\\), \\(\\phi_1,\\ldots,\\phi_p\\) e \\(\\theta_1,\\ldots,\\theta_q\\), conforme realizado no pacote fable. É importante esclarecer que existem distintos algoritmos e, neste sentido, linguagens e pacotes computacionais diferentes podem não reportar os mesmos resultados.\nPara comparar e selecionar modelos pode-se considerar o critério de informação de Akaike (\\(AIC\\)), calculado conforme segue, onde \\(k=0\\), se \\(c=0\\), e \\(k=1\\), caso contrário.\n\\[\nAIC = -2\\text{log}(L) + 2(p+k+q+1)\n\\]\nO AIC corrigido (\\(AICc\\)) é calculado conforme segue.\n\\[\nAIC_c = AIC+ \\frac{2(p+k+q+1)(p+k+q+2)}{T-p-q-k-2}\n\\]\nOutra métrica é o critério de informação Bayesiano (BIC):\n\\[\nBIC = AIC + [\\text{log}(T)-2](p+k+q+1)\n\\]\nO modelo que minimizar tais métricas deve ser escolhido, sugerindo-se priorizar o \\(AICc\\). Uma abordagem para seleção de modelos ARIMA para casos não sazonais pode seguir os seguintes passos (R. Hyndman e Athanasopoulos 2021):\n\nVisualize a série e identifique observações não usuais;\nRealize transformação de Box-Cox para estabilizar a variância, se necessário;\nPara séries não estacionárias, sugere-se diferenciar a série até tornar os dados estacionários;\nExamine a autocorrelação e tente identificar algum modelo \\(ARIMA(p,d,0)\\) via PACF ou \\(ARIMA(0,d,q)\\) via ACF;\nSelecione o modelo a partir do \\(AICc\\);\nAvalie os resíduos do modelo selecionado;\nRealize previsões com o modelo.\n\nEm caso de autocorrelação nos resíduos, tente ajustar outro modelo. Para exemplificar o procedimento, considere a série de produção de grãos no Brasil em toneladas, apresentada no capítulo 4, na Figura 7.6. Como a série aparenta apresentar leve heterocedasticidade, será realizada transformação de Box-Cox.\nA Figura 6.12 apresenta a série após transformação com \\(\\lambda=0,6264\\).\n\n\n\n\n\n\n\n\nFigura 6.12: Série de produção de grãos no Brasil com transformação de Box-Cox\n\n\n\n\n\nA Tabela 6.5 apresenta o resultado do teste de KPSS para a série transformada, indicando a rejeição da hipótese nula de estacionariedade desta.\n\n\n\n\nTabela 6.5: Teste KPSS para a série de produção de grãos\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n1,242214\n0,01\n\n\n\n\n\n\n\n\nA Figura 6.13 apresenta a variação da série transformada. Mesmo com a transformação de Box-Cox, após 2015 houve períodos de variação mais alta. Confirma-se estacionariedade após diferenciação de primeira ordem da série transformada, conforme Tabela 6.6.\n\n\n\n\n\n\n\n\nFigura 6.13: Variação da série transformada de produção de grãos no Brasil\n\n\n\n\n\n\n\n\n\nTabela 6.6: Teste KPSS para a variação da série transformada de produção de grãos\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n0,5364439\n0,0334586\n\n\n\n\n\n\n\n\nA Figura 6.14 expõe os correlogramas de ACF e PACF para a série diferenciada e transformada. Observa-se que o primeiro indica um modelo \\(ARIMA(0,1,1)\\), enquanto o segundo indica um modelo \\(ARIMA(1,1,0)\\).\n\n\n\n\n\n\n\n\nFigura 6.14: Autocorrelação e autocorrelação parcial da série de produção de grãos\n\n\n\n\n\nA seguir expõe-se o resultado do modelo \\(ARIMA(1,1,0)\\). Foi obtido \\(ACCc\\) = 585,42.\n\n\nSeries: valor \nModel: ARIMA(1,1,0) w/ drift \nTransformation: box_cox(valor, lambda) \n\nCoefficients:\n          ar1  constant\n      -0,4639   41,2969\ns.e.   0,1369    8,4272\n\nsigma^2 estimated as 3430:  log likelihood=-257,09\nAIC=520,17   AICc=520,73   BIC=525,72\n\n\nA seguir expõe-se o resultado do modelo \\(ARIMA(0,1,1)\\). Foi obtido \\(ACCc\\) = 586,36, indicando que o modelo anterior apresentou melhor ajuste.\n\n\nSeries: valor \nModel: ARIMA(0,1,1) w/ drift \nTransformation: box_cox(valor, lambda) \n\nCoefficients:\n          ma1  constant\n      -0,4384   28,0583\ns.e.   0,1109    4,7877\n\nsigma^2 estimated as 3446:  log likelihood=-257,18\nAIC=520,36   AICc=520,92   BIC=525,91\n\n\nA Figura 6.15 expõe os gráficos de resíduos para o modelo \\(ARIMA(1,1,0)\\) aplicado à série transformada de produção de grãos. Os resíduos são não correlacionados e não aparentam apresentar desvio significativo de normalidade.\n\n\n\n\n\n\n\n\nFigura 6.15: Resíduos do modelo ARIMA(1,1,0) para a série de produção de grãos\n\n\n\n\n\nA Tabela 6.7 resume o resultado do teste de Ljung-Box para os resíduos do modelo \\(ARIMA(1,1,0)\\) para a série de produção de grãos. O teste deve ser realizado considerando \\(K=p+q\\) graus de liberdade. O alto p-valor obtido indica não haver indícios para rejeição da hipótese nula de ausência de autocorrelação.\n\n\n\n\nTabela 6.7: Teste de Ljung-Box para os resíduos do modelo ARIMA(1,1,0) para a série de produção de grãos\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n4,580951\n0,8692027\n\n\n\n\n\n\n\n\nA Figura 6.16 expõe a previsão realizada para \\(h=10\\) anos à frente com o modelo ajustado. A previsão pontual para 2033 é de 397000 toneladas de grãos.\n\n\n\n\n\n\n\n\nFigura 6.16: Previsão com o modelo ARIMA(1,1,0) para a série de produção de grãos",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#arima-com-sazonalidade",
    "href": "ST6.html#arima-com-sazonalidade",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.6 ARIMA com sazonalidade",
    "text": "6.6 ARIMA com sazonalidade\nModelos ARIMA também podem ser aplicados a casos sazonais, sendo denotados \\(ARIMA(p,d,q)(P,D,Q)_m\\), onde \\(m\\) é o período sazonal e os termos da parte sazonal do modelo são denotados por letras maiúsculas. Um modelo \\(ARIMA(1,1,1)(1,1,1)_{12}\\) é para sazonalidade anual e pode ser escrito em notação de defasagem conforme segue, onde \\(\\Phi\\) e \\(\\Theta\\) são, respectivamente, os termos autorregressivos e de média móvel, ambos de primeira ordem, para a parte sazonal. Os modelos ARIMA sazonais são comumente chamados de SARIMA.\n\\[\n(1-\\phi_1B)(1-\\Phi_1B^{12})(1-B)(1-B^{12})y_t = c+( 1+\\theta_1B)( 1+\\Theta_1B^{12})\\varepsilon_t\n\\]\nA Figura 6.18 expõe a variação sazonal da sériede log(passageiros) em vôos do Brasil, além dos correlogramas de ACF e PACF. Pode-se observar que a série sazonalmente diferenciada ainda apresenta alta tendência. É ainda necessário uma diferenciação de primeira ordem.\n\n\n\n\n\n\n\n\nFigura 6.18: Variação sazonal no log(passageiros) de vôos no Brasil\n\n\n\n\n\nA Figura 6.19 apresenta a série mais uma vez diferenciada. Examinando-se o correlograma de ACF, pode-se sugerir um modelo MA(1) para a parte não sazonal, dada a significância no lag 1, e um modelo MA(1) para a parte sazonal, dada a significância no lag 12. Logo, pode-se sugerir um modelo \\(ARIMA(0,1,1)(0,1,1)_{12}\\). Ao observar o correlograma de PACF, há indícios de que um modelo autorregressivo de ordem AR(1) seja adequado para a parte não sazonal, enquanto um modelo AR(3) pode ser interessante para a parte sazonal, devido aos picos de 12, 24 e 26 meses. Entretanto, ao se tentar estimar um modelo \\(ARIMA(1,1,0)(3,1,0)_{12}\\) não foram reportados resultados, sendo então aproximado um modelo \\(ARIMA(1,1,0)(2,1,0)_{12}\\).\n\n\n\n\n\n\n\n\nFigura 6.19: Série de passageiros de vôos no Brasil\n\n\n\n\n\nAlém dos modelos sugeridos, o método automático do pacote fable sugere um modelo de ordem \\(ARIMA(1,1,1)(0,1,1)_{12}\\), conforme Tabela 6.7, muito próximo dos considerados inicialmente.\n\n\n\n\nTabela 6.7: Modelos ARIMA testados para a série log(passageiros)\n\n\n\n\n\n\nModelo\nOrdem\n\n\n\n\narima011011\n&lt;ARIMA(0,1,1)(0,1,1)[12]&gt;\n\n\narima110210\n&lt;ARIMA(1,1,0)(2,1,0)[12]&gt;\n\n\nauto\n&lt;ARIMA(1,1,1)(0,1,1)[12]&gt;\n\n\n\n\n\n\n\n\nA Tabela 6.8 resume o resultado dos três modelos. Considerando o AICc, o modelo automático apresentou por pouco o melhor resultado.\n\n\n\n\nTabela 6.8: Resultados dos modelos ARIMA testados para a série log(passageiros)\n\n\n\n\n\n\n.model\nsigma2\nlog_lik\nAIC\nAICc\nBIC\n\n\n\n\nauto\n0.0010447\n455.1001\n-902.2002\n-902.0201\n-888.5004\n\n\narima011011\n0.0010532\n453.7601\n-901.5202\n-901.4126\n-891.2453\n\n\narima110210\n0.0011762\n444.0289\n-880.0578\n-879.8776\n-866.3580\n\n\n\n\n\n\n\n\nA seguir são apresentados os coeficientes do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\n\nSeries: Passageiros \nModel: ARIMA(1,1,1)(0,1,1)[12] \nTransformation: log(Passageiros) \n\nCoefficients:\n         ar1      ma1     sma1\n      0.5214  -0.6437  -0.7410\ns.e.  0.2121   0.1859   0.0584\n\nsigma^2 estimated as 0.001045:  log likelihood=455.1\nAIC=-902.2   AICc=-902.02   BIC=-888.5\n\n\nA Figura 6.20 apresenta os gráficos de resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\). A série residual apresenta padrão estacionário e não há indícios de desvio de normalidade pelo histograma. Há significância na autocorrelação para defasagem de 11, 13 e 22 observações.\n\n\n\n\n\n\n\n\nFigura 6.20: Série de passageiros de vôos no Brasil\n\n\n\n\n\nA Tabela 6.9 apresenta o resultado do teste de Ljung-Box para os resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\) para a série log(passageiros). No caso sazonal, considera-se \\(K=p+q+P+Q\\) graus de liberdade no teste. Considerando um nível de significância de 0,05, não há indícios suficientes para rejeição da hipótese nula de ausência de autocorrelação residual.\n\n\n\n\nTabela 6.9: Teste Ljung-Box para o modelo ARIMA(1,1,1)(0,1,1)12 para a série log(passageiros)\n\n\n\n\n\n\n.model\nlb_stat\nlb_pvalue\n\n\n\n\nauto\n28.77407\n0.1195322\n\n\n\n\n\n\n\n\nA Figura 6.21 apresenta a previsão para 3 anos à frente para a série de passageiros em vôos do Brasil. Sabe-se que a pandemia reduziu o volume de vôos para níveis menores que os dos anos 2000. Entretanto, o modelo capturou bem a tendência dos últimos anos e o padrão de sazonalidade no número de passageiros. Após alguns anos de observação pós-pandemia, modelos ARIMA seguirão sendo úteis para modelar a variação observada em volume de passageiros em vôos do Brasil.\n\n\n\n\n\n\n\n\nFigura 6.21: Previsão para 3 anos à frente para a série de passageiros de vôos no Brasil\n\n\n\n\n\nA Figura 6.22 expõe a série de produtos não duráveis no Brasil. Observa-se padrão sazonal anual com tendência de crescimento até 2015 e depois de queda, com pior resultado em 2020, devido a pandemia. Após, 2021 observa-se tendência de recuperação.\n\n\n\n\n\n\n\n\nFigura 6.22: Produção mensal de bens não duráveis no Brasil\n\n\n\n\n\nA Figura 6.23 expõe a série de variação sazonal de bens de consumo não duráveis, considerando os dados de até dezembro de 2021. Pode-se sugerir pelo correlograma de PACF um modelo de ordem (3,1,0) para a parte não sazonal e um modelo de ordem (2,0,0) para a parte sazonal, dado o pico nos atrasos de 12 e 24 meses.\n\n\n\n\n\n\n\n\nFigura 6.23: Variação sazonal na produção de bens de consumo não duráveis\n\n\n\n\n\nA Tabela 6.10 expõe os modelos testados manualmente e o selecionado automaticamente.\n\n\n\n\nTabela 6.10: Modelos ARIMA testados para a série de bens não duráveis\n\n\n\n\n\n\nname\nModelo\nOrdem\n\n\n\n\nnao_duraveis\narima310200\n&lt;ARIMA(3,1,0)(2,0,0)[12] w/ drift&gt;\n\n\nnao_duraveis\nauto\n&lt;ARIMA(4,1,1)(0,1,1)[12]&gt;\n\n\n\n\n\n\n\n\nA Tabela 6.11 apresenta os resultados para os modelos testados na série de bens de consumo não duráveis. O modelo \\(ARIMA(4,1,1)(0,1,1)_{12}\\), selecionado via pacote fable apresenta melhor ajuste. R. J. Hyndman e Khandakar (2008) descrevem a abordagem usada no pacote para seleção automática de modelos ARIMA sem e com sazonalidade e também para modelos ETS.\n\n\n\n\nTabela 6.11: Resultados dos ARIMA testados para a série de bens não duráveis\n\n\n\n\n\n\n.model\nsigma2\nlog_lik\nAIC\nAICc\nBIC\n\n\n\n\nauto\n14.09469\n-591.4166\n1196.833\n1197.374\n1220.428\n\n\narima310200\n16.65650\n-649.3569\n1312.714\n1313.225\n1336.688\n\n\n\n\n\n\n\n\nA Figura 6.24 apresenta os gráficos residuais para o modelo \\(ARIMA(4,1,1)(0,1,1)_{12}\\) para a série de bens de consumo não duráveis. O valor discrepante março de 2021 é atribuído à pandemia. Observa-se picos de autocorrelação parcial para defasagens próximas de 2 anos. No entanto, pelo teste de Ljung-Box, apresentado na Tabela 6.12, não há indícios suficientes que indicam a rejeição da hipótese de independência dos resíduos.\n\n\n\n\n\n\n\n\nFigura 6.24: Resíduos do modelo ARIMA(4,1,1)(0,1,1)12 para série de produção de bens de consumo não duráveis\n\n\n\n\n\n\n\n\n\nTabela 6.12: Teste de Ljung-Box para os resíduos da série de produção de bens de consumo não duráveis\n\n\n\n\n\n\nname\n.model\nlb_stat\nlb_pvalue\n\n\n\n\nnao_duraveis\nauto\n25.45438\n0.1129033\n\n\n\n\n\n\n\n\nA Figura 6.25 apresenta graficamente os resultados de previsão para além de 2021, juntamente com os dados disponíveis e separados para teste. Observa-se boa proximidade com os dados não considerados para treinamento do modelo. Apesar da queda em 2021 devido à pandemia, o modelo treinado conseguiu apresentar uma boa projeção à curto e médio prazo.\n\n\n\n\n\n\n\n\nFigura 6.25: Previsão para 3 anos à frente para a série de bens de consumo não duráveis\n\n\n\n\n\nA Tabela 6.13 finaliza a análise comparando o desempenho dos modelos estimados aplicados aos dados de teste para a série de bens de consumo não duráveis. Confirma-se a superioridade do modelo estimado automaticamente.\n\n\n\n\nTabela 6.13: Métricas para comparar o desenho dos modelos testados para a série de bens de consumo não duráveis\n\n\n\n\n\n\n.model\nRMSE\nMAE\nMAPE\n\n\n\n\narima310200\n6.659694\n5.664403\n5.710309\n\n\nauto\n5.714044\n4.262668\n4.127184",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referências",
    "section": "",
    "text": "Box, George EP, Gwilym M Jenkins, Gregory C Reinsel, and Greta M Ljung.\n2008. Time Series Analysis: Forecasting and Control. John Wiley\n& Sons.\n\n\nBox, George EP, and David A Pierce. 1970. “Distribution of\nResidual Autocorrelations in Autoregressive-Integrated Moving Average\nTime Series Models.” Journal of the American Statistical\nAssociation 65 (332): 1509–26.\n\n\nCleveland, Robert B, William S Cleveland, Jean E McRae, Irma Terpenning,\net al. 1990. “STL: A Seasonal-Trend Decomposition.” J.\nOff. Stat 6 (1): 3–73.\n\n\nGardner, Everette S., and Ed. Mckenzie. 1985. “Forecasting Trends\nin Time Series.” Management Science 31 (10): 1237–46. https://doi.org/10.1287/mnsc.31.10.1237.\n\n\nGuerrero, Victor M. 1993. “Time-Series Analysis Supported by Power\nTransformations.” Journal of Forecasting 12 (1): 37–48.\n\n\nHamilton, James D. 1994. Time Series Analysis. Princeton\nuniversity press.\n\n\nHolt, Charles C. 2004. “Forecasting Seasonals and Trends by\nExponentially Weighted Moving Averages.” International\nJournal of Forecasting 20 (1): 5–10. https://doi.org/https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nHyndman, RJ, and G Athanasopoulos. 2021. Forecasting: Principles and\nPractice. OTexts. OTexts.com/fpp3.\n\n\nHyndman, Rob J, and Yeasmin Khandakar. 2008. “Automatic Time\nSeries Forecasting: The Forecast Package for r.” Journal of\nStatistical Software 27: 1–22.\n\n\nHyndman, Rob, Anne B Koehler, J Keith Ord, and Ralph D Snyder. 2008.\nForecasting with Exponential Smoothing: The State Space\nApproach. Springer Science & Business Media.\n\n\nKwiatkowski, Denis, Peter CB Phillips, Peter Schmidt, and Yongcheol\nShin. 1992. “Testing the Null Hypothesis of Stationarity Against\nthe Alternative of a Unit Root: How Sure Are We That Economic Time\nSeries Have a Unit Root?” Journal of Econometrics 54\n(1-3): 159–78.\n\n\nLjung, Greta M, and George EP Box. 1978. “On a Measure of Lack of\nFit in Time Series Models.” Biometrika 65 (2): 297–303.\n\n\nMakridakis, Spyros, Allan Andersen, Robert Carbone, Robert Fildes,\nMichele Hibon, Rudolf Lewandowski, Joseph Newton, Emanuel Parzen, and\nRobert Winkler. 1982. “The Accuracy of Extrapolation (Time Series)\nMethods: Results of a Forecasting Competition.” Journal of\nForecasting 1 (2): 111–53.\n\n\nMakridakis, Spyros, Steven C Wheelwright, and Rob J Hyndman. 2008.\nForecasting Methods and Applications. John wiley & sons.\n\n\nMontgomery, Douglas C, Cheryl L Jennings, and Murat Kulahci. 2015.\nIntroduction to Time Series Analysis and Forecasting. John\nWiley & Sons.\n\n\nWinters, Peter R. 1960. “Forecasting Sales by Exponentially\nWeighted Moving Averages.” Management Science 6 (3):\n324–42. https://doi.org/10.1287/mnsc.6.3.324.\n\n\nYule, G Udny. 1926. “Why Do We Sometimes Get Nonsense-Correlations\nBetween Time-Series?–a Study in Sampling and the Nature of\nTime-Series.” Journal of the Royal Statistical Society\n89 (1): 1–63.",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "ST1.html#introdução-às-séries-temporais-e-previsão",
    "href": "ST1.html#introdução-às-séries-temporais-e-previsão",
    "title": "1  Introdução e gráficos",
    "section": "1.1 Introdução às séries temporais e previsão",
    "text": "1.1 Introdução às séries temporais e previsão\nUma série temporal consiste em um conjunto de observações de uma variável aleatória ordenadas no tempo. Uma série temporal pode ser descrita matematicamente como \\(y_1, ..., y_T\\), onde \\(T\\) consiste no último período da série. A análise de séries temporais visa o estudo e obtenção de modelos preditivos para este tipo de dados. O objetivo ao final é realizar previsões com o modelo obtido, de forma a viabilizar ações de planejamento, prever cenários e possibilidades.\nA previsão é importante em diversos contextos das engenharias, administração e ciências. Por exemplo, para decidir o nível de produção e planejar o próximo período é necessário prever a demanda. Para avaliar se um investimento é viável é importante prever a sua rentabilidade. Para planejamento dos sistemas energéticos é importante prever o consumo de energia. Para prever a capacidade de produção de energia hidroelétrica é preciso prever a precipitação.\nNeste curso serão apresentados diversos modelos para análise e previsão de séries temporais, sendo boa parte dos exemplos obtidos de casos brasileiros. Serão consideradas séries de dados de produção, indústria, agricultura, clima, energia, economia, investimentos, mobilidade, transporte, saúde, entre outros."
  },
  {
    "objectID": "ST1.html#exemplos-de-séries-e-visualizações",
    "href": "ST1.html#exemplos-de-séries-e-visualizações",
    "title": "1  Introdução e gráficos",
    "section": "1.2 Exemplos de séries e visualizações",
    "text": "1.2 Exemplos de séries e visualizações\n\n1.2.1 Séries univariadas\nNa Figura 1.1 observa-se graficamente a série temporal do índice de preços ao consumidor (IPCA), com frequência mensal a partir de 1980. A série foi obtida em Ipeadata. As seis primeiras observações da série também são exibidas na Tabela 1.1. A primeira observação é \\(y_1 = 4,62\\), ou seja, no primeiro mês de observação da série, fevereiro de 1980, o IPCA foi de 4,62%. Já a segunda observação é \\(y_2 = 6,04\\) e assim sucessivamente, conforme disposição na Tabela. Observa-se graficamente a estabilização do índice a partir de 1994, a partir da adoção do plano real.\n\n\n\n\n\n\n\n\nFigura 1.1: IPCA no Brasil\n\n\n\n\n\n\n\n\n\nTabela 1.1: IPCA no Brasil\n\n\n\n\n\n\ndata\nipca\n\n\n\n\n1980-02-01\n4,62\n\n\n1980-03-01\n6,04\n\n\n1980-04-01\n5,29\n\n\n1980-05-01\n5,70\n\n\n1980-06-01\n5,31\n\n\n1980-07-01\n5,55\n\n\n\n\n\n\n\n\nPara visualizar melhor como o IPCA variou nos últimos 20 anos, pode-se selecionar os dados a partir do ano 2000. O resultado é plotado na Figura 1.2.\n\n\n\n\n\n\n\n\nFigura 1.2: IPCA no Brasil a partir de 2000\n\n\n\n\n\nA Tabela 1.2 exibe as primeiras observações da série temporal de volume de carros produzidos no Brasil a partir de 1990. A série foi obtida em dados estatísticos ANFAVEA e apresenta frequência mensal.\n\n\n\n\nTabela 1.2: Produção de carros no Brasil\n\n\n\n\n\n\ndata\nquantidade\n\n\n\n\n1990-02-01\n57258\n\n\n1990-03-01\n32740\n\n\n1990-04-01\n32812\n\n\n1990-05-01\n58464\n\n\n1990-06-01\n37632\n\n\n1990-07-01\n43697\n\n\n\n\n\n\n\n\nA série é plotada na Figura 1.3. Pode-se observar alguns períodos de queda no volume, por exemplo, próximo de 2015 durante a crise política do país e em 2020 durante a pandemia, onde a demanda chegou a níveis anteriores aos dos anos 2000.\n\n\n\n\n\n\n\n\nFigura 1.3: Vendas de carros no Brasil\n\n\n\n\n\n\n\n1.2.2 Séries temporais multivariadas\nA Figura 1.4 expõe a série temporal com frequência horária do volume de ônibus e caminhões de dois eixos trafegando na Br040 no quilômetro 709 nos meses de agosto e setembro de 2025. São plotadas as séries no sentido crescente (C) e decrescente (D). A série está disponível em dados do plano nacional de contagem de tráfego. Observa-se padrões sazonais diário e semanal. O primeiro dia do mês de agosto de 2023 foi uma terça-feira. A partir da primeira hora do dia observa-se o crescimento do volume de veículo até um pico de tráfego próximo de 60 veículos com posterior decréscimo com o avançar da noite até um volume mínimo bem próximo de zero. O padrão diário se repete, porém, com menor volume nos fins de semana. O padrão semanal é identificado pela repetição de cinco ciclos de maior fluxo, caracterizando os dias de semana, e dois com menor fluxo, consistindo nos fins de semana.\n\n\n\n\n\n\n\n\nFigura 1.4: Tráfego de ônibus e caminhões de dois eixos na BR040 no quilômetro 709\n\n\n\n\n\nNa Tabela 1.3 são exibidas apenas as primeiras observações da série temporal em frequência horária de produção de energia eólica no ano de 2023 no Brasil. Os dados estão disponíveis em Dados abertos do operador nacional do sistema elétrico.\n\n\n\n\nTabela 1.3: Produção de energia no Brasil em 2023\n\n\n\n\n\n\ndata\ntipo\nenergia\n\n\n\n\n2023-01-01 00:00:00\neolica\n14138,75\n\n\n2023-01-01 01:00:00\neolica\n13790,86\n\n\n2023-01-01 02:00:00\neolica\n13612,57\n\n\n2023-01-01 03:00:00\neolica\n13277,32\n\n\n2023-01-01 04:00:00\neolica\n13009,72\n\n\n2023-01-01 05:00:00\neolica\n12311,20\n\n\n\n\n\n\n\n\nAs séries temporais de energia eólica, hidráulica, solar e térmica são plotadas na Figura 1.5 para o mês de dezembro de 2023. De forma geral é possível ver o padrão cíclico diário de produção. Enquanto a energia solar é obviamente produzida durante os períodos de sol, a eólica tem maior volume de produção durante a noite e madrugada, quando venta mais forte. Já a energia elétrica, fonte dominante no Brasil, pode ser controlada para complementar as demais. A energia térmica, menos sustentável que as demais, é produzida em momentos de queda nos níveis de produção das demais fontes, justificando seu padrão menos previsível. A visualização em painéis separados é útil, uma vez que possibilita avaliar melhor o padrão e variabilidade de cada série, permitindo ajustar a escala de cada série de forma individual.\n\n\n\n\n\n\n\n\nFigura 1.5: Produção de energia no Brasil em dezembro de 2023\n\n\n\n\n\nOutro exemplo de série multivariada é a de índices de produção de bens de capital, de consumo duráveis, intermediários e de consumo não duráveis, plotada na Figura 1.6 em um mesmo painel gráfico. A série foi obtida em Pesquisa industrial mensal - produção física do IBGE. Essa visualização em um úncio painel é interessante em casos onde as séries apresentam escala similar, possibilitando a comparação destas.\n\n\n\n\n\n\n\n\nFigura 1.6: Bens de consumo duráveis, intermediários e de consumo não duráveis\n\n\n\n\n\nUm último exemplo de série temporal multivariada considera dados de visualizações de 4 vídeos da playlist Tolerâncias e ajustes do canal da engenharia de manufatura e qualidade. A série multivariada é plotada na Figura 1.7. A série se inicia em 2018, ano de lançamento do canal, porém só tem dados segundo a data de lançamento de cada vídeo.\n\n\n\n\n\n\n\n\nFigura 1.7: Visualizações de vídeos de tolerâncias e ajustes no youtube\n\n\n\n\n\n\n\n1.2.3 Gráficos de sazonalidade\nÉ possível visualizar padrões sazonais de forma distintas. Sejam os dados de tráfego de veículos de passeio na BR040 no quilômetro 709. A Figura Figura 1.8 ilustra um gráfico de sazonalidade diária para o mês de agosto de 2023 para ambos sentidos de tráfego. Os dias são plotados em escala de cor, enquanto o horizonte diário em horas é plotado no eixo horizontal. Observa-se um tráfego mais baixo nas primeiras horas do dia, com aumento no volume de 3 às 9 da manhã, estabilidade durante a manhã e decréscimo com o início da noite. É possível observar também que para a maior parte dos dias o volume de tráfego nas horas mais movimentadas tem pico em 250 veículos. Porém há dias com volume maior.\n\n\n\n\n\n\n\n\nFigura 1.8: Sazonalidade diária no tráfego de veículos de passeio na BR040\n\n\n\n\n\nPara uma melhor visualização sejam os dias de semana separados em distintos painéis, conforme Figura Figura 1.9. Observa-se agora mais claramente o padrão para cada dia de semana. Domingos são os dias mais movimentados considerando este tipo de veículo. De terça a quinta o tráfego apresenta padrão similar.\n\n\n\n\n\n\n\n\nFigura 1.9: Sazonalidade diária no tráfego na BR040, padrões de dias de semana\n\n\n\n\n\nAinda considerando os dados de tráfego na BR-040 é possível visualizar a sazonalidade semanal. A Figura 1.10 considera as semanas em cores e no eixo horizontal o horizonte semanal. Observa-se um padrão consistente para as distintas semanas do mês de Agosto.\n\n\n\n\n\n\n\n\nFigura 1.10: Sazonalidade diária no tráfego de veículos de passeio na BR040\n\n\n\n\n\nTomando novamente os dados de visualizações de vídeos no youtube, pode-se visualizar os dados da série do vídeo 4 em subséries anuais, para avaliar se há sazonalidade. A Figura 1.11 expõe o gráfico de sazonalidade. Os dados foram agregados mensalmente. O padrão cíclico não é tão claro, possivelmente devido a diferenças nos calendários de ensino entre os anos e também devido à pandemia de COVID-19. Pode-se visualizar os picos de visualizações de abril a junho e de Setembro a Novembro, coincidindo com períodos de picos de estudos nos dois semestres anuais.\n\n\n\n\n\n\n\n\nFigura 1.11: Gráfico sazonal de Visualizações do vídeo 4\n\n\n\n\n\nUm gráfico de subsérie sazonal considera uma unidade de tempo em distintos painéis e um múltiplo desta unidade no eixo horizontal. A Figura Figura 1.12 plota tal gráfico para a série de índice de bens de capital. As linhas horizontais em azul consistem nas médias mensais, permitindo observar a variação ao longo do ano considerando tais médias. Já a subsérie observada em cada painel permitem observar a tendência ao longo dos anos dentro de cada mês. Para este índice, independente do mês observa-se um aumento na produção de bens de capital até 2013/2014, seguido de queda e posterior recuperação seguida de nova queda, provavelmente devido à pandemia de COVID-19.\n\n\n\n\n\n\n\n\nFigura 1.12: Gráfico de subséries sazonais: Visualizações do vídeo 4\n\n\n\n\n\n\n\n1.2.4 Correlação entre séries\nA Figura 1.13 exibe diagramas de dispersão e correlações aos pares para a série multivariada de produção de bens exposta na Figura Figura 1.6. Pode-se confirmar a alta relação linear entre tais índices, com correlação linear positiva variando de 0,70 a 0,84.\n\n\n\n\n\n\n\n\nFigura 1.13: Bens de consumo duráveis, intermediários e de consumo não duráveis\n\n\n\n\n\n\n\n1.2.5 Gráficos de decomposição\nExistem diversas formas de decompor séries temporais. A Tabela 1.4 expõe os resultados de uma decomposição aditiva usando o método STL para a série de produção de bens de capital. Tal método será explicado no capítulo 3. A componente cíclica é removida e o restante é suavizado para aproximar a tendência. O resíduo consiste na série original subtraída da tendência e da componente sazonal.\n\n\n\n\nTabela 1.4: Decomposição da série de produção de bens de capital\n\n\n\n\n\n\nData\nvalor\ntrend\nseason_year\nremainder\n\n\n\n\n2002 jan\n58,19\n66,25\n-8,87\n0,81\n\n\n2002 fev\n56,75\n65,93\n-9,81\n0,63\n\n\n2002 mar\n64,68\n65,62\n1,80\n-2,74\n\n\n2002 abr\n68,90\n65,30\n-2,54\n6,14\n\n\n2002 mai\n66,66\n65,02\n1,92\n-0,28\n\n\n2002 jun\n61,72\n64,74\n-0,13\n-2,90\n\n\n\n\n\n\n\n\nA Figura 1.14 expõe graficamente a decomposição da série do índice de produção de bens de capital. Observa-se claramente a separação da tendência e do padrão sazonal da série, facilitando a interpretação desta.\n\n\n\n\n\n\n\n\nFigura 1.14: Gráficos de decomposição da série de produção de bens de capital\n\n\n\n\n\n\n\n1.2.6 Gráficos de previsão\nUm dos objetivos principais da análise e modelagem de séries temporais é a realização de previsões. Quando a série tem padrão não aleatório, com tendência e/ou sazonalidade, por exemplo, existem diversos métodos adequados para realizar modelagem e obter boas previsões. Obviamente quanto maior o horiznte de previsão almejado, maior a dificuldade de obter bons resultados.\nA Figura Figura 4.16 exibe a série de temperatura instantânea na cidade de São joão del-Rei dos dias 15 a 29 de maio. Os dados foram obtidos em Instituto Nacional de Meteorologia. Observa-se que a série plotada em cor preta exibe comportamento cíclico dada a variação diária entre a temperatura mínima, que varia de 8 a 13 ºC, e a máxima diárias, que gira em torno de 25 a 28 ºC no período. Também é possível observar uma tendência de aumento na temperatura nos dias considerados. A Figura expõe a previsão para dois dias à frente em azul, com intervalos de confiança de 80 e 95%.\n\n\n\n\n\n\n\n\nFigura 1.15: Previsão da temperatura em São João del-Rei",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução e gráficos</span>"
    ]
  },
  {
    "objectID": "ST1.html#implementação-em-r",
    "href": "ST1.html#implementação-em-r",
    "title": "1  Introdução e gráficos",
    "section": "1.3 Implementação em R",
    "text": "1.3 Implementação em R\nA seguir apresenta-se boa parte da implementação na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo. Os dados utilizados estão disponíveis em Previsão, por Robson Bruno Dutra Pereira.\nCarregando pacotes.\n\nlibrary(forecast)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(GGally)\ntheme_set(theme_bw())\n\nLeitura dos dados de IPCA. Os dados em extensão *.csv são inicialmente armazenados em um data.frame no R, com duas colunas, data e ipca.\n\nipca &lt;- read.csv(\"ipca.csv\", header = T)\n\nÉ necessário transformar o data.frame em um tipo de dados ideal para séries temporais. O tipo tsibble é adequado para a sintaxe que será usada neste curso. Antes, porém, é necessário transformar a coluna data em Date, de forma que o R entenda como tal, pois inicialmente a coluna com data como lida de um *.csv pode ser reconhecida como character ou como numeric, dependendo do formato desta coluna. O operador |&gt; é o operador pipe do R, o qual serve para encadear operações. O comando mutate é usado junto com o comando as.Date para mudar a coluna data para Data. É necessário entender como os dados estão armazenados para definir o argumento format, com a ordem adequada de entrada. O dia é identificado com \"%d\", enquanto o mês numérico com \"%m\" ou mês character com \"%b\", enquanto o dia é identificado com \"%d\". Sugere-se usar ?as.Date para mais detalhes e exemplos. O comando as_tsibble visa transformar o data.frame em tsibble, sendo que o argumento index deve receber uma coluna do tipo Date.\n\nipca_ts &lt;- ipca |&gt;\n  mutate(data = yearmonth(as.Date(paste(\"01\", data), format = \"%d %Y %b\"))) |&gt;\n  as_tsibble(index = data)\n\nhead(ipca_ts)\n\nPara visualizar a série pode-se usar o comando autoplot.\n\nipca_ts |&gt;\n  autoplot(ipca) + \n  labs(y = \"IPCA\", x = \"\", title=\"IPCA no Brasil\")\n\nVizualizando a série a partir de 2018, usando o comando filter_index.\n\nipca_ts |&gt;\n  filter_index(\"2018\" ~ .) |&gt;\n  # filter(year(data) &gt;= 2018) |&gt; # outra opcao\n  autoplot(ipca) + \n  labs(x=\"\", y=\"IPCA\", \n       title=\"IPCA no Brasil a partir de 2018\")\n\nSérie de volume de produção de carros no Brasil.\n\ncarros &lt;- read.csv(\"vendas_veiculos.csv\", \n                   sep=\";\")\n\ncarros_ts &lt;- carros |&gt;\n  mutate(data = as.Date(data, format = \"%d/%m/%Y\")) |&gt;\n  as_tsibble(index=data)\n\nhead(carros_ts)\n\nVisualizando a série.\n\ncarros_ts |&gt;\n  autoplot(quantidade) +\n  labs(x=\"\", y=\"Carros produzidos\",\n       title=\"Produção de carros no Brasil\")\n\nSérie multivariada de produção de energia em 2023 no Brasil.\n\nenergia_2023 &lt;- read.csv(\"energia_2023_sin.csv\", header = T)\n# head(energia_2023) |&gt; gt()\n\nNo caso de séries com frequência horária é importante usar o comando as.POSIXct, definindo também hora - \"%H\", minuto - \"%M\", e segundo - \"%S\". Séries multivariadas podem ser alocadas em múltiplas colunas, como no caso da série em questão. Pode-se empilhar as séries com o comando pivot_longer, identificando corretamente o nome da coluna com as séries com o argumento values_to e o nome da coluna com a identificação das séries com o argumento values_to. Ao transformar em tsibble após empilhar as séries é importante identificar as séries com o argumento key.\n\nenergia_2023_ts &lt;- energia_2023 |&gt;\n  mutate(data = as.POSIXct(data, format = \"%Y-%m-%d %H:%M:%S\")) |&gt;\n  pivot_longer(!data, names_to = \"tipo\", values_to = \"energia\") |&gt;\n  as_tsibble(index = data, \n             key = tipo)\n\nenergia_2023_ts|&gt; head()\n\nVisualizando os dados de dezembro em painéis separados. Usa-se para tal o comando facet_wrap para plotar cada série em um painel gráfico.\n\nenergia_2023_ts |&gt;\n  filter_index(\"2023-12\") |&gt;   \n  autoplot(energia) + \n  facet_wrap(nrow=4, ~ tipo, scales = \"free_y\") + \n  labs(y = \"Energia\", \n       x = \"\",\n       title=\"Produção de energia no Brasil em dezembro de 2023\") +\n  guides(colour=\"none\")\n\nSérie de índices de produção de bens de consumo.\n\nprod &lt;- read.csv(\"Producao_bens.csv\", header=T)\n\nprod$Data &lt;- yearmonth(seq(as.Date(\"2002/1/1\"), \n                 length=271, by=\"month\"))\n\nprod &lt;- prod |&gt;\n  pivot_longer(cols = capital:nao_duraveis,\n               names_to = \"indice\", values_to = \"valor\")\n\nprod_ts &lt;- prod |&gt; \n  as_tsibble(key = indice, index = Data)\n\nVisualizando em um único gráfico.\n\nprod_ts |&gt;\n  autoplot(valor)\n\nSeja a série de fluxo de veículos na BR040 no quilômetro 709 no ano de 2023. A série apresenta frequência horária. O comando dmy_h pode ser usado para criar a data a partir das colunas de data e hora, após concatená-las com paste. Essa série é duplamente multivariada uma vez que apresenta dois sentidos e diversos tipos de veículos identificados de A a L. Porém, neste caso, será considera apenas a série de veículos de passeio (I) nos dois sentidos, crescente (C) e decrescente (D).\n\nbr040_709 &lt;- read.csv(\"040_709_2023.csv\", header = T)\n\nbr040_709_ts &lt;- br040_709 |&gt;\n  mutate(\n    datatempo = dmy_h(paste(Data, Hora))) |&gt;\n  select(-Data, -Hora) |&gt;  \n  as_tsibble(index = datatempo, \n             key = Sentido)\n\nO gráfico sazonal ´pode ser obtido com o comando gg_season. Para esta série é interessante visualizar tanto a sazonalidade diária, period = \"1d\", quanto a semanal, period = \"1w\".\n\nbr040_709_ts |&gt; \n  filter_index(\"2023-08\") |&gt;\n  # filter(Sentido == \"C\") |&gt;\n  fill_gaps() |&gt;\n  gg_season(I, period = \"1d\") +\n  labs(x = \"hora\", \n       y = \"Veículos\",\n       title = \"Sazonalidade diária no tráfego na BR040\")\n\nO Gráfico de subséries sazonais pode ser obtido com o comando gg_subseries.\n\nprod_ts |&gt;\n  filter(indice == \"capital\") |&gt;\n  gg_subseries(valor) + \n  labs(y=\"\", x=\"\", title=\"\")\n\nPara avaliar a correlação entre séries os dados devem estar no fromato de data.frame. Logo, pode-se usar o comando pivot_wider para desempilhar as séries. Sugere-se usar o comando ggpairs que provê gráficos de dispersão aos apres entre as séries, gráficos de densidades amostrais individuais e o coeficiente de correlação de Pearson para todos os pares de séries.\n\ndf_prod &lt;- prod_ts |&gt;\n  pivot_wider(names_from=indice,\n              values_from=valor)\n\nggpairs(df_prod, columns = 2:5, progress = F)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução e gráficos</span>"
    ]
  },
  {
    "objectID": "ST1.html#execícios-propostos",
    "href": "ST1.html#execícios-propostos",
    "title": "1  Introdução e gráficos",
    "section": "1.4 Execícios propostos",
    "text": "1.4 Execícios propostos\n\nFaça o gráfico da série temporal multivariada de produção de energia para o mês de julho de 2023.\n\n\nFaça o gráfico anterior em painéis separados.\n\n\nO código abaixo carrega os dados da série de visualização de vídeos do youtube. tol4_tsibble consiste na série do vídeo 4. Obtenha o gráfico da série do vídeo 4.\n\n\ntol &lt;- read.csv(\"tolerancia_ajuste.csv\")\n\ntol_ts &lt;- tol |&gt;\n  mutate(Date = as.Date(Date, format = \"%Y-%m-%d\")) |&gt;\n  as_tsibble(index = Date, key = Video)\n\ntol4_ts &lt;- tol_ts |&gt;\n  filter(Video == \"#4\", year(Date) &gt;= 2019,\n         year(Date)&lt;2024)\n\n\nO código abaixo acumula mensalmente as visualizações do vídeo 4. Obtenha os gráficos sazonais para a série mensal. Defina labels = \"left\" e labels_repel = T para identificar os anos próximos às linhas.\n\n\ntol4_mensal &lt;- tol4_ts |&gt;\n  index_by(YearMonth = yearmonth(Date)) |&gt;\n  summarise(Views = sum(Views))\n\n\nO código a seguir carrega a série de temperatura horária de São João del-Rei para 2024. Considerando os dados de 14 dias faça o gráfico de sazonalidade diária e interprete-o.\n\n\ntempo_sjdr &lt;- read.csv(\"sjdr2024.csv\",\n                       header=T)\ntempo_sjdr_ts &lt;- tempo_sjdr |&gt;\n  mutate(Data = as.POSIXct(paste(Data,Hora), \n                           format = \"%Y/%m/%d %H\")) |&gt;\n  select(!Hora) |&gt;\n  as_tsibble(index = Data)\n\ntempo_sjdr_14_dias &lt;- tempo_sjdr_ts |&gt;\n  filter_index(\"2024-06-15 00:00:00\" ~ \"2024-06-2923:00:00\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução e gráficos</span>"
    ]
  },
  {
    "objectID": "ST3.html#decomposição",
    "href": "ST3.html#decomposição",
    "title": "3  Decomposição de séries temporais",
    "section": "",
    "text": "3.1.1 Ajustes e transformações\nAlguns ajustes são comumente necessários antes de realizar a decomposição de uma série temporal. Por exemplo, em alguns casos é importante corrigir a sazonalidades devido à diferenças de calendário. Em séries que exibem alguma variável com frequência mensal, pode haver alguma sazonalidade nos meses com número menor de dias, sendo interessante talvez trabalhar com a média mensal, dividindo a variável pelo número de dias de cada mês.\nDados relacionados à população também podem ser ajustados per capita, ou por pessoa. Este ajuste é muito comum no PIB e em outras variáveis econômicas, por exemplo. Em séries relacionadas a disponibilidade de algum serviço para a população é mais fácil avaliar a disponibilidade ajustando os dados por mil pessoas, por exemplo, de forma a eliminar o efeito do crescimento populacional. O mesmo pode ser feito para séries de saúde pública, por exemplo de número de pessoas infectadas ou a mortalidade pode ser dividida por 1000 ou 100 mil, dependendo da ordem de grandeza de cada série, de forma a viabilizar comparação entre populações de localidades distintas. Em séries econômicas às vezes é importante considerar a inflação, de forma a dar uma dimensão real da série, permitindo comparação em diferentes momentos. Para deflacionar uma série basta dividí-la pelo deflator, um índice que corrige a inflação.\nTransformações como a de Box-Cox ou outra mais simples também podem ser úteis para facilitar o tratamento da série. Conforme visto anteriormente, uma série que exibe uma variação sazonal não constante, ou heterocedástica, ao ser transformada pode exibir um padrão de sazonalidade de mais fácil decomposição ou tratamento.\nA série plotada na Figura 3.1 consiste na produção mensal de gás natural no Brasil a partir os anos 2000. A série está disponível em Dados estatísticos - Agência nacional de petróleo.\n\n\n\n\n\n\n\n\nFigura 3.1: Produção mensal de gás natural no Brasil\n\n\n\n\n\nA Figura 3.2 plota novamente a série considerando a normalização por número de dias no mês.\n\n\n\n\n\n\n\n\nFigura 3.2: Produção mensal de gás natural no Brasil\n\n\n\n\n\nA série normalizada é submetida a uma transformação de Box-Cox de forma a corrigir a heterocedasticidade, com \\(\\lambda=-0.06\\), sendo o resultado plotado na Figura 3.3.\n\n\n\n\n\n\n\n\nFigura 3.3: Produção mensal de gás natural no Brasil com transformação de Box-Cox",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#componentes-de-uma-série",
    "href": "ST3.html#componentes-de-uma-série",
    "title": "3  Decomposição de séries temporais",
    "section": "3.2 Componentes de uma série",
    "text": "3.2 Componentes de uma série\nAssumindo uma decomposição aditiva, pode-se escrever:\n\\[\ny_t = S_t+ T_t+R_t,\n\\]\nonde \\(S_t\\) é a componente sazonal, \\(T_t\\) é a tendência e \\(R_t\\) é o resto no período \\(t\\). No caso multiplicativo tem-se:\n\\[\ny_t = S_t \\times T_t \\times R_t\n\\]\nO caso multiplicativo é ideal quando a variação em séries sazonais muda com o tempo, seguindo padrão heterocedástico.\nA série plotada na Figura 3.4 exibe o índice de produção física mensal de bens intermediários, ou seja, aqueles empregados na produção de produtos finais, tais como produtos minerais, produtos metalúrgicos, têxteis, papel e celulose, produtos químicos, borracha, plásticos, componentes elétricos e eletrônicos.\n\n\n\n\n\n\n\n\nFigura 3.4: Produção mensal de produtos intermediários no Brasil\n\n\n\n\n\nA Tabela 3.1 exibe as primeiras linhas das componentes da série, considerando a decomposição aditivavia método STL.\n\n\n\n\nTabela 3.1: Decomposição aditiva da série do índice de produção mensal de produtos intermediários no Brasil\n\n\n\n\n\n\nData\nValor\nTendência\nSazonalidade\nResto\n\n\n\n\n2002 jan\n87,97245\n95,10887\n-7,0894994\n-0,0469214\n\n\n2002 fev\n85,22869\n95,33164\n-11,1630761\n1,0601292\n\n\n2002 mar\n94,94150\n95,55440\n0,8473573\n-1,4602601\n\n\n2002 abr\n96,00238\n95,77717\n-2,0387398\n2,2639509\n\n\n2002 mai\n99,12757\n95,99987\n3,8247141\n-0,6970134\n\n\n2002 jun\n97,15759\n96,22257\n1,7226365\n-0,7876163\n\n\n\n\n\n\n\n\nA série é plotada novamente na Figura 3.5 com a tendência em destaque. Observam-se dois períodos de queda mais acentuada relativos à crise de 2008/2009 e à pandemia de COVID-19.\n\n\n\n\n\n\n\n\nFigura 3.5: Produção mensal de produtos intermediários no Brasil com tendência em destaque\n\n\n\n\n\nAs componentes são plotadas separadamente na Figura 3.6.\n\n\n\n\n\n\n\n\nFigura 3.6: Componentes da série de produtos intermediários",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#dados-com-sazonalidade-ajustada",
    "href": "ST3.html#dados-com-sazonalidade-ajustada",
    "title": "3  Decomposição de séries temporais",
    "section": "3.3 Dados com sazonalidade ajustada",
    "text": "3.3 Dados com sazonalidade ajustada\nPode ser útil remover a sazonalidade da série, resultando em uma série com sazonalidade ajustada. Para casos aditivos a série resultante seria dada por \\(y_t-S_t\\), enquanto que para casos multiplicativos seria \\(y_t/S_t\\).\nNa Figura 3.7 plota-se a série de produtos intermediários ajustada sazonalmente.\n\n\n\n\n\n\n\n\nFigura 3.7: Série de produtos intermediários com ajuste da sazonalidade",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#média-móvel",
    "href": "ST3.html#média-móvel",
    "title": "3  Decomposição de séries temporais",
    "section": "3.4 Média móvel",
    "text": "3.4 Média móvel\nUm dos métodos clássicos para estimar a tendência é a média móvel. Uma média móvel de ordem \\(m\\) pode ser escrita como segue.\n\\[\n\\hat{T}_t=\\frac{1}{m}\\sum_{j=-k}^{k} y_{t+j}\n\\]\nDenota-se uma média móvel como \\(m\\)-MA, ou média móvel de ordem \\(m\\). A título de exemplo seja a série \\(5,10,12,20,23,27\\). Considerando \\(k = 2\\), tem-se uma média móvel de ordem \\(m=5\\), 5-MA. Para este caso, seguem os cálculos das médias móveis para a terceira e quarta observações, \\(t=3,4\\). Observa-se que o \\(k\\) determina o número de observações não suavizadas no ínico e fim da série.\n\\[\n\\hat{T}_3=\\frac{1}{2\\times2+1}(5+10+12+20+23)=14\n\\]\n\\[\n\\hat{T}_4=\\frac{1}{2\\times2+1}(10+12+20+23+27)=18,4\n\\]\nNa Figura 6.5 observa-se graficamente a média móvel com diferentes ordens, para a série de volume de carros produzidos no Brasil. Quando maior a ordem da série, mais suave o resultado.\n\n\n\n\n\n\n\n\nFigura 3.8: Média móvel para a série de carros produzidos com distintas defasagens\n\n\n\n\n\nÉ interessante em alguns casos realizar a média móvel de uma média móvel, com o objetivo final de centrar médias móveis pares. Uma média móvel \\(2\\times4\\)-MA consiste em uma média móvel \\(4\\)-MA seguida de uma \\(2\\)-MA.\nPor exemplo, para a série da Tabela 3.2 o problema da média móvel \\(4\\)-MA é que ela não é simétrica em relação à série original, tendo uma observação não estimada no início e duas no final. Ao tomar desta série resultante uma média móvel de ordem \\(2\\)-MA, resultando na \\(2\\times4\\)-MA, tem-se uma série média móvel simétrica com a original, com duas observações ausentes no início e fim. É importante observar que a média móvel \\(4\\)-MA considera uma observação anterior, e duas posteriores, além da observação no período \\(t\\). Já a média móvel \\(2\\)-MA considera a observação anterior e a do o período \\(t\\).\n\n\n\nTabela 3.2: \\(2\\times4\\)-MA\n\n\n\n\n\nSérie\n\\(4\\)-MA\n\\(2\\times4\\)-MA\n\n\n\n\n5\n\n\n\n\n10\n11,75\n\n\n\n12\n16,25\n14\n\n\n20\n20,5\n18,375\n\n\n23\n25\n22,75\n\n\n27\n\n\n\n\n30",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#estimando-a-tendência-com-dados-sazonais",
    "href": "ST3.html#estimando-a-tendência-com-dados-sazonais",
    "title": "3  Decomposição de séries temporais",
    "section": "3.5 Estimando a tendência com dados sazonais",
    "text": "3.5 Estimando a tendência com dados sazonais\nAo realizar uma média móvel \\(2\\times4\\)-MA, a estimativa feita ao final fica conforme a Equação abaixo, consistindo em uma média ponderada.\n\\[\n\\hat{T}_t=\\frac{1}{8}y_{t-2}+\\frac{1}{4}y_{t-1}+\\frac{1}{4}y_{t}+\\frac{1}{4}y_{t+1}+\\frac{1}{8}y_{t+2}\n\\]\nEste modelo pode ser usado para estimar tendência de séries com sazonalidade quadrimestral, por exemplo. Recomenda-se usar uma média móvel de ordem \\(2\\times m\\)-MA para estimar a tendência de uma série com sazonalidade de ordem \\(m\\).\nNa Figura 3.9 observa-se novamente a série de índice de produção de itens intermediários plotada sazonalmente. Como ficou clara a sazonalidade anual, pode-se pensar na suavização de ordem \\(2\\times 12\\)-MA.\n\n\n\n\n\n\n\n\nFigura 3.9: Gráfico sazonal da série de produtos intermediários\n\n\n\n\n\nA Figura 3.10 exibe a série do índice de produção de produtos intermediários com média móvel \\(2\\times 12\\)-MA. Pode-se confirmar que a sazonalidade foi eliminada. A tendência estimada é muito similar à obtida anteriormente com método mais sofisticado.\n\n\n\n\n\n\n\n\nFigura 3.10: Tendência para a série de produtos intermediários estimada com média móvel",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#decomposição-clássica",
    "href": "ST3.html#decomposição-clássica",
    "title": "3  Decomposição de séries temporais",
    "section": "3.6 Decomposição clássica",
    "text": "3.6 Decomposição clássica\nA decomposição clássica tem um século de tradição e é o primeiro método de decomposição (Makridakis, Wheelwright, e Hyndman 2008). Ela contempla a forma aditiva e a multiplicativa. A seguir são expostos os passos para a decomposição aditiva:\n\nSe o período sazonal, \\(m\\), é par, estime a tendência, \\(\\hat{T}_t\\),, como uma média móvel \\(2\\times m\\)-MA. Se \\(m\\) é ímpar, estime a tendência com uma média móvel \\(m\\)-MA.\nCalcule a série sem a tendência, \\(y_t - \\hat{T}_t\\).\nCalcule a componente sazonal para cada estação como a média de todos os períodos desta. Por exemplo, para uma série com sazonalidade anual. O mês de janeiro terá como valor de \\(\\hat{S}_t\\) a média de todas as observações de janeiro. O procedimento é realizado para todos os meses.\nCalcule o resto tomando a diferença da série em relação à tendência a sazonalidade, \\(\\hat{R}_t=y_t - \\hat{T}_t - \\hat{S}_t\\).\n\nA Figura 3.11 expõe o resultado gráfico da decomposição clássica da série de produtos intermediários. Pode-se observar que neste caso a sazonalidade é constante, diferente do resultado óbtido com método mais sofisticado.\n\n\n\n\n\n\n\n\nFigura 3.11: Decomposição clássica da série de produtos intermediários\n\n\n\n\n\nPassos para a decomposição multiplicativa.\n\nSe o período sazonal, \\(m\\), é par, estime a tendência \\(\\hat{T}_t\\) como uma média móvel \\(2\\times m\\)-MA. Se \\(m\\) é ímpar, estime a tendência com uma média móvel \\(m\\)-MA.\nCalcule a série sem a tendência, \\(y_t / \\hat{T}_t\\).\nCalcule a componente sazonal para cada estação como a média de todos os períodos desta. Por exemplo, para uma série com sazonalidade anual. O mês de janeiro terá como valor de \\(\\hat{S}_t\\) a média de todas as observações de janeiro. O procedimento é realizado para todos os meses.\nCalcule o resto tomando a razão da série em relação à tendência e à sazonalidade, \\(\\hat{R}_t=y_t / (\\hat{T}_t \\times \\hat{S}_t)\\).\n\nA Figura 3.12 plota o número de passageiros em vôos no Brasil, disponível em Dados Abertos da Agência Nacional de Aviação Civil (ANAC). Pode-se observar além da tendência uma variação cíclica com amplitude crescente ao longo dos anos.\n\n\n\n\n\n\n\n\nFigura 3.12: Série de passageiros de vôos no Brasil\n\n\n\n\n\nObserva-se na Figura 3.13 sazonalidade anual com picos nos períodos de férias escolares, em Julho e Dezembro/Janeiro. A mudança ao longo dos anos na inclinação das linhas nos períodos de pico confirma o padrão heterocedástico da série.\n\n\n\n\n\n\n\n\nFigura 3.13: Gráfico sazonal da série de passageiros de vôos no Brasil\n\n\n\n\n\nA Figura 3.14 expõe o resultado gráfico da decomposição clássica multiplicativa da série de passageiros em vôos no Brasil.\n\n\n\n\n\n\n\n\nFigura 3.14: Decomposição clássica multiplicativa da série de passageiros de vôos no Brasil",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#métodos-usados-por-agências-de-estatística",
    "href": "ST3.html#métodos-usados-por-agências-de-estatística",
    "title": "3  Decomposição de séries temporais",
    "section": "3.7 Métodos usados por agências de estatística",
    "text": "3.7 Métodos usados por agências de estatística\nO método X-11 é discutido em Dagum & Bianconcini (2016). Possibilita a decomposição aditiva e a multiplicativa, é robusto a altas variações e outliers e a estimativa de tendência é disponível em toda série. O método também captura outras formas de sazonalidade e feriados.\nA Figura 3.15 exibe o resultado da decomposição aditiva pelo método X-11 na série do índice de produção de produtos intermediários.\n\n\n\n\n\n\n\n\nFigura 3.15: Decomposição da série de produtos intermediários via X-11\n\n\n\n\n\nO método SEATS consiste em uma decomposição sazonal de séries temporais por ARIMA (ARIMA será discutida futuramente) e foi proposto pelo Banco da Espanha. A Figura 3.16 expõe o resultado gráfico do método SEATS para decompor a série de passageiros em vôos do Brasil.\n\n\n\n\n\n\n\n\nFigura 3.16: Decomposição da série de produtos intermediários via SEATS",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST2.html#estatísticas-descritivas",
    "href": "ST2.html#estatísticas-descritivas",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "",
    "text": "2.1.1 Estatísticas simples\nA Tabela 2.1 expõe a média e o desvio-padrão para a série multivariada de energia produzida em MWh no Brasil em 2023, segundo cada fonte. Observa-se a superioridade da série hidráulica em relação às demais, confirmando a dependência desta fonte na matriz energética brasileira.\n\n\n\n\nTabela 2.1: Média e desvio-padrão da série multivariada de Energia\n\n\n\n\n\n\nTipo\nMédia\nsd\n\n\n\n\nsolar\n4909,736\n6929,487\n\n\ntermica\n8250,471\n1886,645\n\n\neolica\n10887,856\n3931,696\n\n\nhidraulica\n50466,854\n11061,858\n\n\n\n\n\n\n\n\nA Tabela 2.2 expõe os quartis da mesma série para todas as fontes consideradas. Recordando, os quartis são valores na série que dividem os dados em quatro partes iguais. O primeiro quartil deixa 25% das observações abaixo deste, o segundo, também chamado de mediana, deixa 50% das observações abaixo, enquanto o terceiro e último deixa 75% dos dados abaixo. Observa-se também o mínimo (0%) e máximo (100%) de cada série.\n\n\n\n\nTabela 2.2: Média e desvio-padrão da série multivariada de Energia\n\n\n\n\n\n\nTipo\n0%\n25%\n50%\n75%\n100%\n\n\n\n\neolica\n692,913\n7975,784\n11133,851\n13983,090\n20166,24\n\n\nhidraulica\n23565,749\n41825,293\n50623,416\n58907,708\n81006,77\n\n\nsolar\n0,237\n4,913\n588,847\n7368,716\n27222,57\n\n\ntermica\n4415,886\n6868,407\n8269,444\n9438,016\n19248,15",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#autocorrelação",
    "href": "ST2.html#autocorrelação",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.2 Autocorrelação",
    "text": "2.2 Autocorrelação\nA autocorrelação é uma estatística importante para avaliar padrões de séries temporais, uma vez que consiste na correlação entre distintos segmentos da série temporal (Yule 1926). Para estimar a autocorrelação de uma série, deve-se defasá-la, isto é, atrasá-la em uma ou mais observações, e testar a correlação da série original com a série defasada. Para uma defasagem (lag) de uma observação, \\(k= 1\\), calcula-se a correlação \\(r_1\\) entre \\(y_t\\) e \\(y_{t-1}\\). Para uma defasagem de duas observações, \\(k = 2\\), calcula-se a correlação \\(r_2\\) entre \\(y_t\\) e \\(y_{t-2}\\) e assim sucessivamente. A autocorrelação para uma defasagem de ordem \\(k\\) pode ser calculada conforme a Equação 2.1.\n\\[\nr_k = \\frac{\\sum_{t=k+1}^T (y_t-\\bar{y})(y_{t-k}-\\bar{y})}{\\sum_{t=1}^T (y_t-\\bar{y})^2}\n\\tag{2.1}\\]\nA Tabela 2.3 expõe as dez primeiras observações de uma série temporal arbitrária \\(y_t\\). A série defasada de uma observação, \\(y_{t-1}\\), é observada à direita. Nas colunas seguintes são observadas a série com defasagem de duas e três observações, respectivamente. A autocorrelação para defasagem de uma observação, \\(r_1\\), consiste na correlação entre \\(y_t\\) e \\(y_{t-1}\\). A autocorrelação é geralmente calculada para diversas defasagens e o correlograma é um gráfico que plota as autocorrelações, facilitando a interpretação da série.\n\n\n\n\nTabela 2.3: Série temporal arbitrária defasada de 1, 2 e 3 observações\n\n\n\n\n\n\ntempo\n\\(y_t\\)\n\\(y_{t-1}\\)\n\\(y_{t-2}\\)\n\\(y_{t-3}\\)\n\n\n\n\n1\n5\nNA\nNA\nNA\n\n\n2\n13\n5\nNA\nNA\n\n\n3\n12\n13\n5\nNA\n\n\n4\n14\n12\n13\n5\n\n\n5\n10\n14\n12\n13\n\n\n6\n16\n10\n14\n12\n\n\n7\n6\n16\n10\n14\n\n\n8\n10\n6\n16\n10\n\n\n9\n12\n10\n6\n16\n\n\n10\n19\n12\n10\n6\n\n\n\n\n\n\n\n\nA Figura 2.1 expõe o diagrama de dispersão da série arbitrária \\(y_t\\) da Tabela 2.3 e da mesma série defasada de uma observação, \\(y_{t-1}\\). Observa-se que há uma relação linear positiva entre a série completa e a mesma defasada de uma observação, sugerindo que a série defasada explica boa parte da variação da série original. A autocorrelação mede tal relação.\n\n\n\n\n\n\n\n\nFigura 2.1: Diagrama de dispersão entre \\(y_t\\) e \\(y_{t-1}\\)\n\n\n\n\n\nSeja a série temporal de exportações do Brasil em US$ FOB, disponível em Resultados do Comércio Exterior Brasileiro - Dados Consolidados plotada na Figura 2.2. Observa-se em geral tendência de crescimento com estagnação de 2016 a 2021 devido a crise político-econômica e a pandemia. Também é possível observar um padrão sazonal anual, com maior volume de exportações nos meses de maior atividade econômica em cada ano.\n\n\n\n\n\n\n\n\nFigura 2.2: Exportações do Brasil\n\n\n\n\n\nA Figura 2.3 plota o correlograma da série de exportações. As linhas horizontais tracejadas azuis consistem nas linhas que determinam a significância estatística das autocorrelações, de forma que as que estão acima destas, são significativas. Tais limites são calculados como \\(\\pm 1,96 /\\sqrt{T}\\), onde \\(1,96\\) consiste no valor do quantil na distribuição normal-padrão \\(z\\), com 0,95 de probabilidade ou confiança.\n\n\n\n\n\n\n\n\nFigura 2.3: Correlograma da série de exportações do Brasil\n\n\n\n\n\nSéries com tendência geralmente apresentam autocorrelação positiva decrescente com o aumento da defasagem. Séries com sazonalidade apresentam autocorrelação alta no período sazonal. Para o caso plotado, pode-se confirmar a presença de tendência e de sazonalidade anual na série.\nNa Figura 2.4 são plotadas algumas séries temporais com o correlograma correspondente. A série da Figura 2.4(a) corresponde a um ruído branco (white noise) ou uma sequência de números aleatórios segundo a distribuição normal. Tal série não apresenta autocorrelação significativa, conforme indica o seu correlograma, exibido na Figura 2.4(d). A série da Figura 2.4(b) apresenta padrão cíclico com sazonalidade de 24h. O seu correlograma, plotado na Figura 2.4(e), é característico deste tipo de série, por apresentar correlação positiva decrescente com o aumento da defasagem até ficar negativa com mínimo na defasagem de 12h, metade do período sazonal. Já a série da Figura 2.4(c), com frequência mensal, apresenta tendência linear clara juntamente com sazonalidade anual. O seu correlograma, exibido na Figura 2.4(f), apresenta autocorrelação positiva decrescente com a defasagem, além do padrão cíclico anual, devido aos ciclos de 12 em 12 meses.\n\n\n\n\n\n\n\n\nFigura 2.4: Séries e respectivos correlogramas",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#métodos-simples-de-previsão",
    "href": "ST2.html#métodos-simples-de-previsão",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.3 Métodos simples de previsão",
    "text": "2.3 Métodos simples de previsão\nAlguns métodos simples de previsão para séries temporais serão expostos com afinalidade de expor a terminologia para previsão, entender o raciocínio necessário para realizar previsões e prover previsões que servem de comparação com resultados de métodos mais sofisticados, os quais serão explicitados nos próximos capítulos.\n\n2.3.1 Média\nSeja a série histórica \\(y_1, ..., y_T\\). Seja \\(h\\) o número de períodos à frente que se deseja prever. A previsão de séries temporais a partir da média, pode ser útil para algumas séries estacionárias, sendo uma ou mais observações futuras previstas a partir da média das \\(T\\) observações disponíveis da série. A Equação 2.2 é usada para previsão via média.\n\\[\n\\hat{y}_{T+h|T}=\\frac{1}{T}\\sum_{t=1}^Ty_t=\\frac{y_1+y_2+...+y_T}{T}\n\\tag{2.2}\\]\nNa Figura 2.5 expõe-se a previsão com a média para três anos à frente para a série temporal do IPCA no Brasil.\n\n\n\n\n\n\n\n\nFigura 2.5: Previsão por média para a série do IPCA\n\n\n\n\n\n\n\n2.3.2 Método ingênuo\nO método ingênuo propõe prever as observações futuras como a última observação disponível Box et al. (2008). A Equação 2.3 é útil para realizar previsões via método ingênuo.\n\\[\n\\hat{y}_{T+h|T}=y_T\n\\tag{2.3}\\]\nNa Figura 2.6 expõe-se a previsão com o método ingênuo para três anos à frente para a série temporal do IPCA no Brasil.\n\n\n\n\n\n\n\n\nFigura 2.6: Previsão pelo método ingênuo na série do IPCA\n\n\n\n\n\n\n\n2.3.3 Ingênuo sazonal\nO método ingênuo sazonal é indicado para séries claramente sazonais e propõe prever as observações futuras iguais aos períodos das estações anteriores, por exemplo mesmo valor do mês do ano anterior (Makridakis et al. 1982). Na formulação dos valores previstos à seguir, \\(m\\) consiste no período sazonal e \\(k\\) é a parte inteira de \\((h-1)/m\\), ou seja, o número completo de anos do período de previsão antes de \\(T+h\\). A Equação 2.4 é usada para realizar previsões com o método ingênuo sazonal.\n\\[\n\\hat{y}_{T+h|T}=y_{T+h-m(k+1)}\n\\tag{2.4}\\]\nA Figura 2.7 apresenta a série de temperatura instantânea coletada de hora em hora das duas primeiras semanas de maio de 2024 para a cidade de São joão del-Rei. Foram considerados os dados da primeira semana para treinar os modelos, sendo as previsões plotadas para a semana seguinte juntamente com as observações. pode-se observar que as previsões para o dia 08/05 à frente são exatamente iguais ao observado no dia 07 de maio. As previsões obtidas com o método ingênuo sazonal apresentam bom ajuste aos dados, uma vez que a temperatua desta semana apresentou padrão estável.\n\n\n\n\n\n\n\n\nFigura 2.7: Previsão da temperatura em São João del-Rei em maio de 2024 pelos três métodos benchmarking apresentados\n\n\n\n\n\n\n\n2.3.4 Deriva\nO método da deriva é uma variação do ingênuo que permite a previsão de observações com tendência de crescimento ou decréscimo segundo a variação observada entre a primeira e última observação (Hyndman e Athanasopoulos 2021). A Equação 2.5 viabiliza a previsão via método da deriva.\n\\[\n\\hat{y}_{T+h|T} = y_T + \\frac{h}{T-1}\\sum_{t=2}^T(y_t-y_{t-1}) =y_T+h \\bigg(\\frac{y_T-y_1}{T-1}\\bigg)\n\\tag{2.5}\\]\nNa Figura 2.8 aplica-se a previsão com o método da deriva para três dias à frente para a série temporal de produção de carros no Brasil.\n\n\n\n\n\n\n\n\nFigura 2.8: Previsão por deriva na série de vendas de carros no Brasil",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#resíduos-e-valores-ajustados",
    "href": "ST2.html#resíduos-e-valores-ajustados",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.4 Resíduos e valores ajustados",
    "text": "2.4 Resíduos e valores ajustados\nOs valores ajustados, ou seja, os valores aproximados pelo modelo estimado para as observações da série de interesse, \\(y_t\\), também referidos como ajustados, são denotados por \\(\\hat{y}_{t|t-1}\\). Tal notação implica que a estimativa de \\(y_t\\), dita \\(\\hat y_t\\), é baseada nas observações anteriores, \\(y_1, ..., y_{t-1}\\). É importante diferenciar os valores ajustados dos valores previstos, \\(\\hat y_{T+h|T}\\). Enquanto os primeiros são aqueles aproximados a partir de um modelo para os dados observados da série, \\(t=1,\\dots,T\\), os previstos consistem em observações futuras projetadas para a série em questão para \\(h\\) períodos à frente.\nOs resíduos de uma série temporal consistem no erro, sendo calculados como a diferença entre o observado e o ajustado em cada instante de tempo, \\(e_t=y_t-\\hat{y}_t\\).\nNa Tabela 2.4 são explicitados os valores ajustados e os resíduos obtidos com o método ingênuo sazonal para as últimas horas do dia 07 de maio da série temporal de temperatura em São João del-Rei.\n\n\n\n\nTabela 2.4: Valores ajustados e residuais obtidos pelo método ingênuo para a série de temperatura em São João del-Rei\n\n\n\n\n\n\nData\nTemperatura\najustados\nresíduos\n\n\n\n\n2024-05-07 18:00:00\n27,8\n26,4\n1,4\n\n\n2024-05-07 19:00:00\n27,9\n25,6\n2,3\n\n\n2024-05-07 20:00:00\n25,8\n24,1\n1,7\n\n\n2024-05-07 21:00:00\n23,0\n22,4\n0,6\n\n\n2024-05-07 22:00:00\n20,3\n21,8\n-1,5\n\n\n2024-05-07 23:00:00\n18,8\n20,7\n-1,9\n\n\n\n\n\n\n\n\n\n2.4.1 Diagnóstico dos resíduos\nOs resíduos de um modelo de série temporal contém informações importantes a respeito da qualidade do modelo estimado. Os resíduos de um modelo de série temporal devem ser:\n\nNão correlacionados.\nCom média nula.\n\nSe os resíduos forem correlacionados, eles apresentam informações que deveriam ser incorporadas ao modelo, de forma a melhorar as previsões, implicando que o método usado não foi capaz de descrever toda a informação contida na série e possivelmente há alguum método que resultará em um modelo melhor para a série. Se os resíduos apresentam média diferente de zero, o modelo apresenta um viés. O viés pode ser corrigido subtraindo-o das previsões. Já a autocorrelação entre os resíduos tem correção mais trabalhosa, sendo este tema tratado posteriormente.\nÉ interessante, porém não-obrigatório, que os resíduos sejam:\n\nHomocedásticos, ou seja, que apresentem variâncias iguais.\nNormalmente distribuídos.\n\nA homocedasticidade consiste na igualdade de variâncias. Séries com resíduos heterocedásticos podem ser tranformadas, visando obter homocedasticidade e normalidade.\nNa Figura 2.9 é plotada a série histórica de 187 observações do índice Ibovespa, para o ano de 2024. A série está disponível em Cotação do índice Ibovespa - Infomoney.\n\n\n\n\n\n\n\n\nFigura 2.9: Série do índice Ibovespa\n\n\n\n\n\nA previsão de índices da bolsa é geralmente feita usando o método ingênuo. Este método considera como valor previsto a última observação disponível. Neste caso os resíduos serão calculados como a diferença da observação atual e a anterior, \\(e_t = y_t - \\hat{y}_t = y_t - y_{t-1}\\). Na Figura 2.10 são plotados os resíduos para tal método. De forma geral estes aparentam apresentar boa distribuição, sem assimetrias e tendência.\n\n\n\n\n\n\n\n\nFigura 2.10: Resíduos da série do índice Ibovespa para o método ingênuo\n\n\n\n\n\nNa Figura 2.11 é plotado o histograma dos resíduos, o qual aparenta adequar-se bem à distribuição normal.\n\n\n\n\n\n\n\n\nFigura 2.11: Histograma dos resíduos da série do índice Ibovespa\n\n\n\n\n\nNa Figura 2.12 observa-se o correlograma da série do índice Ibovespa. Pode-se observar que a série é autocorrelacionada considerando defasagem de até 22 observações.\n\n\n\n\n\n\n\n\nFigura 2.12: Correlograma da série do índice Ibovespa\n\n\n\n\n\nEm sequência, na Figura 2.13, plota-se o correlograma dos resíduos do modelo obtido via método ingênuo. Pode-se observar que o método ingênuo resultou em resíduos não correlacionados, de forma que o modelo considera toda a informação disponível nos dados. Obviamente podem haver outros modelos que também garantam a ausência de autocorrelação residual.\n\n\n\n\n\n\n\n\nFigura 2.13: Correlograma dos resíduos da série do índice Ibovespa",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#testes-para-diagnóstico-de-autocorrelação",
    "href": "ST2.html#testes-para-diagnóstico-de-autocorrelação",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.5 Testes para diagnóstico de autocorrelação",
    "text": "2.5 Testes para diagnóstico de autocorrelação\nUm teste para diagnóstico de autocorrelação é um teste para averiguar se as \\(l\\) primeiras autocorrelações são diferentes do que se esperaria para um ruído branco. Um destes testes seria o de Box-Pierce (Box e Pierce 1970), com estatística calculada conforme Equação 2.6. Sugere-se \\(l=10\\) autocorrelações para séries não sazonais e \\(l=2m\\) para casos sazonais, onde \\(m\\) é a dimensão do período sazonal. Porém, o teste não é adequado para \\(l\\) alto, sugerindo-se no máximo \\(l=T/5\\).\n\\[\nQ = T\\sum_{k=1}^l r_k^2\n\\tag{2.6}\\]\nUm teste mais adequado é o de Ljung-Box (Ljung e Box 1978), com estatística calculada conforme Equação 2.7.\n\\[\nQ^* = T(T+2)\\sum_{k=1}^l (T-k)^{-1}r_k^2\n\\tag{2.7}\\]\nO teste de Ljung-Box é similar ao de Box-Pierce com peso \\((T + 2)/(T- k)\\) no quadrado da autocorrelação de lag \\(k\\). Para altos valores de \\(T\\) ambos os testes reportam resultados muito próximos (Montgomery, Jennings, e Kulahci 2015). A hipótese nula de ambos os testes reside na nulidade de todas as alto correlações. Em ambos os casos um alto valor de \\(Q^*\\) (ou \\(Q\\)) sugere que as autocorrelações não vem de um ruído branco. Para decisão, considera-se que \\(Q^*\\) (ou \\(Q\\)) segue a distribuição \\(\\chi^2\\) com \\(l\\) graus de liberdade. O teste de Ljung-Box apresenta poder do teste mais alto, por isso é o mais recomendado.\nNa Tabela 2.5 expõe-se o valor \\(Q\\) e \\(Q^*\\) para os resíduos do modelo ingênuo para os dados do índice Ibovespa. O p-valor consiste na probabilidade associada à estatística calculada, \\(Q\\)/\\(Q^*\\). Como \\(Q\\)/\\(Q^*\\) &lt; \\(\\chi^2_{(df=10, \\alpha = 0,05)} = 18,31\\) ou como o p-valor &gt; 0,05 = \\(\\alpha\\), para ambos os testes, não se rejeita a hipótese nula. Logo, pode-se concluir que as autocorrelações dos resíduos não diferem das de um ruído branco.\n\n\n\n\nTabela 2.5: Valores das estatísticas Q e Q* para os resíduos do método ingênuo para o índice Ibovespa\n\n\n\n\n\n\nTeste\nestatística\npvalor\n\n\n\n\nBox-Pierce (Q)\n9,180843\n0,5150314\n\n\nLjung-Box (Q*)\n9,508178\n0,4846474",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#previsão-e-intervalos-de-confiança",
    "href": "ST2.html#previsão-e-intervalos-de-confiança",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.6 Previsão e intervalos de confiança",
    "text": "2.6 Previsão e intervalos de confiança\nAs previsões via modelos de séries temporais visam projetar para um horizonte futuro de interesse estimativas da série, de forma a viabilizar ações de planejamento. O horizonte de previsão de interesse, também chamado de lead time, \\(h\\), consiste no número de períodos à frente que deseja-se prever (Montgomery, Jennings, e Kulahci 2015). Obviamente, quanto maior o lead time, maior a incerteza nas previsões. Além da estimativa pontual, pode-se considerar um intervalo de confiança para a previsão com nível de probabilidade ou confiança de interesse. Para, por exemplo, um intervalo de previsão de 0,95 os valores obtidos consistem nos limites que garantem que o valor previsto está entre eles com 0,95 de confiança.\nUm intervalo de previsão para \\(h\\) períodos à frente com 0,95 de confiança pode ser calculado conforme Equação 2.8.\n\\[\n\\hat{y}_{T+h|T} \\pm1,96 \\hat\\sigma_h,\n\\tag{2.8}\\]\nonde \\(1,96\\) consiste no valor do quantil na distribuição normal-padrão \\(z\\), com 0,95 de probabilidade ou confiança. Obviamente, caso seja desejado um intervalo com nível de confiança diferente, deve-se selecionar o valor \\(z\\) adequado.\nO desvio-padrão para previsões com \\(h=1\\) (um período a frente) pode ser calculado como o desvio-padrão dos resíduos, conforme Equação 2.9 onde \\(K\\) é o número de parâmetros do modelo e \\(M\\) o número de valores ausentes nos resíduos (para o método ingênuo e o da deriva, por exemplo, \\(M=1\\), uma vez que a primeira observação não pode ser estimada).\n\\[\n\\hat\\sigma = \\sqrt{\\frac{1}{T-K-M}\\sum_{t=1}^T e_t^2}\n\\tag{2.9}\\]\nPara previsões com \\(h&gt;1\\) a estimativa de \\(\\sigma_h\\) é mais complexa. A Tabela 2.6 expõe as Equações para estimar o desvio-padrão para os métodos até aqui expostos, onde \\(m\\) é o período sazonal e \\(k\\) consiste na parte inteira de \\((h−1)/m\\).\n\n\n\nTabela 2.6: Desvio-padrão para previsão para os métodos considerados\n\n\n\n\n\nMétodo\ndesvio-padrão para \\(h\\) previsões\n\n\n\n\nMédia\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{1+1/T}\\)\n\n\nIngênuo\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{h}\\)\n\n\nIngênuo sazonal\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{k+1}\\)\n\n\nDeriva\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{h(1+h/(T-1))}\\)\n\n\n\n\n\n\nA Figura 2.14 plota a previsão para 10 dias à frente com os intervalos de confiança de 0,80 e 0,95 para o método ingênuo para a série do índice Ibovespa. Observa-se que à medida que o horizonte de previsão aumenta, aumenta-se a incerteza quanto ao valor previsto.\n\n\n\n\n\n\n\n\nFigura 2.14: Intervalo de previsão para a série do índice Ibovespa",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#transformações",
    "href": "ST2.html#transformações",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.7 Transformações",
    "text": "2.7 Transformações\nHá diversos casos de séries temporais que seguem um padrão de variação cíclica com amplitude variável com o tempo. Tal variabilidade dita heterocedástica pode dificultar a modelagem da série. Transformações podem ser usadas nas séries temporais, de forma a garantir, por exemplo, que as pressuposições sobre os resíduos sejam cumpridas, ou que alguma variação que aumenta ou cresce com o tempo seja corrigida. A transformação logarítmica é geralmente útil para estabilizar a variação de séries. Tomando a série original, \\(y_1, y_2, ..., y_T\\), a série transformada fica \\(w_1, w_2, ..., w_T\\), com \\(w_t =log(y_t)\\), \\(t=1,...,T\\). Uma mudança de uma unidade na escala log de base 10 corresponde a uma multiplicação por 10 na escala original.\nOutras transformações podem ser mais interessantes em alguns casos, porém nem sempre de fácil interpretação, por exemplo as transformações de potência, \\(w_t = y_t^p\\). A transformação de Box-Cox envolve ambos logarítmo e potência, conforme Equação 2.10.\n\\[\nw_t = \\Bigg\\{ \\begin{matrix}\n                \\text{log}(y_t), \\text{ }\\lambda=0 \\\\\n                \\frac{|y_t|^\\lambda-1}{\\lambda}, \\text{ }\\lambda&gt;0,\n             \\end{matrix}\n\\tag{2.10}\\]\nonde \\(\\text{sinal}(y_t) = 1\\) se \\(y\\geq0\\) e \\(\\text{sinal}(y_t) =-1\\), caso contrário.\nA Figura 2.15 apresenta a série de Exportações após transformação de Box-Cox com \\(\\lambda = -0,0656\\). Pode-se observar que a transformação estabiliza a variância da série. Certamente trabalhar com a série transformada viabilizará obtenção de resíduos mais adequados e de previsões melhores. Ao final é possível isolar \\(y_t\\) em \\(w_t\\), de forma a realizar previsões na unidade original da série.\n\n\n\n\n\n\n\n\nFigura 2.15: Série temporal de Exportações com transformação de Box-Cox",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#avaliação-de-modelos-de-séries-temporais",
    "href": "ST2.html#avaliação-de-modelos-de-séries-temporais",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.8 Avaliação de modelos de séries temporais",
    "text": "2.8 Avaliação de modelos de séries temporais\nUma avaliação ideal de um modelo de séries temporais deve ser baseada no desempenho do modelo em novos dados e não somente nos valores residuais. Para tal, deve-se considerar dados separados para teste do modelo ou dados futuros. Portanto, não se deve considerar os dados usados para estimar (treinar) o modelo para avaliar seu desempenho.\nConforme visto no caso para dados de temperatura instantânea para São João del-Rei, uma primeira abordagem consiste em simplesmente usar parte inicial da série para treino do modelo e as últimas observações para teste. O percentual de observações usadas para treino/teste depende do número de observações disponíveis na série.\nNa Figura 2.16 ilustra-se arbitrariamente a separação das primeiras 75% observações para treino e os 25% restantes para teste.\n\n\n\n\n\n\n\n\nFigura 2.16: Observações de treino e teste para validar séries temporais\n\n\n\n\n\nO erro de previsão (não confundir com resíduo) é calculado conforme Equação 2.11, para \\(t=T+1, \\dots, T+h\\).\n\\[\ne_{t} = y_{t} - \\hat{y}_{t}\n\\tag{2.11}\\]\nO desempenho do modelo pode ser medido por diversas métricas. A Tabela 2.7 apresenta as principais métricas de ajuste. O erro médio absuluto (mean absolute error - MAE) e a raiz da média dos quadrados dos erros (root mean square error - RMSE) são medidos na mesma escala da variável da série. O MAE é menos suscetível a outliers e ambos devem ser minimizados. O erro percentual médio absuluto (mean absolute percentage error - MAPE) tem a vantagem de ser livre de escala, permitindo a comparação de séries distintas.\n\n\n\nTabela 2.7: Métricas de erro\n\n\n\n\n\nMétrica\nFórmula\n\n\n\n\nMAE\n\\(\\text{MAE = mean}(|e_t|)\\)\n\n\nRMSE\n\\(\\text{RMSE = }\\sqrt{\\text{mean}(e_t^2)}\\)\n\n\nMAPE\n\\(\\text{MAPE = mean}(|p_t|)\\), com \\(p_t = 100e_t/y_t\\)\n\n\nMASE\n\\(\\text{MASE = mean}(|q_j|)\\)\n\n\n\n\n\n\nAs métricas com o erro padronizado, \\(q_j\\), são alternativais ao MAPE para comparar desempenho em séries distintas. Elas consideram a escala dos dados de treino para tal. A Equação 2.12 é usada para padronizar os erros. Em séries sazonais substitui-se \\(T-1\\) por \\(T-m\\), onde \\(m\\) é o período sazonal. O erro médio absoluto e escalonado (mean absolute scaled error - MASE) na Tabela 2.8 considera tal padronização.\n\\[\nq_j = \\frac{e_j}{\\frac{1}{T-1}\\sum_{t+2}^T |y_t-y_{t-1}|}\n\\tag{2.12}\\]\nA Tabela 2.8 expõe o desempenho dos três métodos considerados nos dados de temperatura instantânea de São João-del-Rei. O método ingênuo sazonal para esta série foi o que apresentou melhor ajuste.\n\n\n\n\nTabela 2.8: Desempenho dos metodos para a previsão da temperatura instantânea em São João del-Rei\n\n\n\n\n\n\nModelo\nRMSE\nMAE\nMAPE\n\n\n\n\nIngênuo\n5,92\n4,98\n23,72\n\n\nIngênuo sazonal\n1,70\n1,41\n8,14\n\n\nmédia\n5,70\n5,17\n27,56",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST2.html#implementação-em-r",
    "href": "ST2.html#implementação-em-r",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.9 Implementação em R",
    "text": "2.9 Implementação em R\nA seguir apresenta-se parte das implementações na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo. Os dados utilizados estão disponíveis em Previsão, por Robson Bruno Dutra Pereira.\nCarregando pacotes.\n\nlibrary(forecast)\nlibrary(tsibble)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(fabletools)\nlibrary(fable)\nlibrary(ggplot2)\nlibrary(feasts)\nlibrary(lubridate)\ntheme_set(theme_bw())\n\nSeja a série de produção de energia no Brasil. O código para obter a série já foi apresentado no capítulo anterior. Para obter a média e desvio-padrão da série multivariada de produção de energia deve-se usar o comando features listando as estatísticas a serem calculadas.\n\nenergia_2023_ts |&gt;\n  features(energia, \n           list(mean = mean,\n                sd = sd))\n\nObtenção dos quartis para a mesma série.\n\nenergia_2023_ts |&gt; \n  features(energia, quantile)\n\nLeitura da série de exportações no Brasil.\n\nexport &lt;- read.csv(\"exportacoes_BR.csv\",\n                   header=T)\n\nexp_ts &lt;- export |&gt;\n  mutate(date = yearmonth(paste(ano, mes, sep = \"-\"))) |&gt;\n  select(!c(ano, mes)) |&gt;\n  as_tsibble(index = date)\n\nA obtenção das autocorrelações é realizada com a função ACF e pode-se definir o número máximo de defasagens com o argumento lag_max.\n\nexp_ts |&gt;\n  ACF(Exp, lag_max = 100) |&gt;\n  autoplot()\n\nTomando a série de IPCA a partir de 2018, também apresentada no capítulo anterior, o modelo de média pode ser obtido conforme segue usando a função model que servirá de forma geral para modelagem de séries temporais, independente do modelo e, neste caso, a função MEAN para obtenção do modelo via média.\n\nipca_fit1 &lt;- ipca_ts |&gt;\n  filter_index(\"2018\" ~ .) |&gt;\n  model(mean = MEAN(ipca))\n\nA previsão pode ser realizada com o comando forecast. O argumento h serve para definir o número de períodos da previsão.\n\nipca_pred1 &lt;- ipca_fit1 |&gt;\n  forecast(h = \"3 years\")\n\nPode-se observar a série com a previsão com o código a seguir.\n\nipca_pred1 |&gt; \n  autoplot(ipca_ts |&gt;\n  filter_index(\"2018\" ~ .), level = NULL) +\n  labs(y = \"IPCA\", x = \"\",\n       title=\"IPCA: previsão por média\")\n\nPara modelagem via método ingênuo usa-se o comando NAIVE.\n\nIPCA_fit2 &lt;- ipca_ts |&gt;\n  filter_index(\"2018\" ~ .) |&gt;\n  fill_gaps() |&gt;\n  model(naive = NAIVE(ipca))\n\nSeja a série temporal de temperatura instantânea de São João del-Rei, também apresentada no capítulo anterior. Sejam os dados dos 14 primeiros dias de maio considerando, com os 7 primeiros separados a seguir para treinar os modelos.\n\ntempo_sjdr_14_dias &lt;- tempo_sjdr_ts |&gt;\n  filter_index(\"2024-05-01 00:00:00\" ~ \"2024-05-14 23:00:00\")\n\ntrain &lt;- tempo_sjdr_14_dias |&gt;\n  filter_index(\"2024-05-01 00:00:00\" ~ \"2024-05-07 23:00:00\")\n\nÉ possível realizar a modelagem considerando múltiplos modelos. Seja abaixo a modelagem considerando os métodos da média, ingênuo e ingênuo sazonal, sendo o último obtido via comando SNAIVE.\n\ntemp_fit &lt;- train |&gt;\n  model(\n    média = MEAN(Temperatura),\n    Ingênuo = NAIVE(Temperatura),\n    `Ingênuo sazonal` = SNAIVE(Temperatura)\n  )\n\nA seguir o código para plotar as previsões com a série completa.\n\ntemp_fc &lt;- temp_fit |&gt; forecast(h = 7*24)\ntemp_fc |&gt;\n  autoplot(tempo_sjdr_14_dias, level = NULL)\n\nValores ajustados e resíduos do método ingênuo sazonal. A coluna .innov resultaria nos resíduos para séries transformadas. Em casos sem transformação, os resultados são idênticos aos da coluna .resid. O comando tail exibe apenas as últimas seis linhas dos resultados.\n\naugment(temp_fit) |&gt;\n  filter(.model == \"Ingênuo sazonal\") |&gt;\n  select(!c(.model, .innov)) |&gt;\n  tail()\n\nA série de produção de carros foi apresentada no capítulo anterior. A modelagem e previsão via método da deriva é obtida conforme segue.\n\ncarros_fit4 &lt;- carros_ts |&gt; \n  model(drift = RW(quantidade ~ drift()))\n\ncarros_pred4 &lt;- carros_fit4 |&gt;\n  forecast(h = \"3 years\")\n# carros_pred4\n\ncarros_pred4 |&gt; \n  autoplot(carros_ts, level = NULL)\n\nSérie do índice Ibovespa.\n\nibov &lt;- read.csv(\"Ibovespa_ InfoMoney_2024.csv\",\n                 header = T)\n\nibov &lt;- ibov |&gt;\n  mutate(DATA = 1:nrow(ibov)) |&gt;\n  select(DATA, FECHAMENTO) |&gt;\n  as_tsibble(index = DATA)\n\nibov |&gt; autoplot(FECHAMENTO) + \n  labs(y = \"Índice Ibovespa B3 [R$]\", x = \"\",\n       title=\"Índice Ibovespa\") \n\nModelagem e gráficos dos resíduos para o método ingênuo para a série do índice. A função gg_tsresiduals viabiliza a obtenção de todos os gráficos de resíduos explorados no capítulo.\n\nfit_naive_ibov &lt;- ibov |&gt;\n  model(NAIVE(FECHAMENTO))\n\nfit_naive_ibov |&gt;\n  gg_tsresiduals()\n\nTestes de Box-pierce e Ljung-Box para os resíduos do método ingênuo para a série do índice ibovespa. Deve-se usar os comandos box_pierce e ljung_box juntamente com o comando features.\n\naug &lt;- fit_naive_ibov |&gt;\n  augment()\n\nQ &lt;- aug |&gt; \n  features(.innov, box_pierce, lag = 10)\nQ\n\nQ_ &lt;- aug |&gt; \n  features(.innov, ljung_box, lag = 10)\nQ_\n\nTransformação de Box-Cox para a série de exportações. Deve-se usar a opção guerrero no argumento features do comando homônimo para aplicar o algoritmo de Guerrero (1993) para selecionar o lambda ótimo da transformção. Usa-se depois o comando box_cox com o lambda ótimo para transformação.\n\nlambda &lt;- exp_ts |&gt;\n  features(Exp, features = guerrero) |&gt;\n  pull(lambda_guerrero)\n\nexp_ts |&gt;\n  autoplot(box_cox(Exp, lambda)) + \n  labs(y=\"\", \n       x=\"\", \n       title=\"Exportações com transformação de Box-Cox\")\n\nDesempenho dos métodos considerados para a série de temperatura de São João del-Rei. O comando accuracy deve ser utilizado, sendo fornecidos as previsões e os dados observados para os dias correspondentes. Pode-se selecionar apenas as métricas de interesse.\n\nlast_days &lt;- tempo_sjdr_14_dias |&gt;\n  filter_index(\"2024-05-08 00:00:00\" ~.)\n\naccuracy(temp_fc, last_days) |&gt;\n  select(.model, RMSE, MAE, MAPE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST4.html#regressão-linear-simples",
    "href": "ST4.html#regressão-linear-simples",
    "title": "4  Regressão de séries temporais",
    "section": "4.1 Regressão linear simples",
    "text": "4.1 Regressão linear simples\nA regressão de séries temporais serve para prever uma série em função de outra ou mais relacionadas. Não é o método mais usual e sofisticado, uma vez que os métodos mais avançados consideram o padrão da própria série para modelagem e previsão. Entretanto, em algumas situações tal abordagem pode ser útil. Ademais, há possibilidade de combinar a regressão com ARIMA, conforme será abordado futuramente.\nSeja um problema onde deseja-se prever uma série temporal contínua, \\(y_1, y_2, ..., y_T\\), em função de outra, \\(x_1, x_2, ..., x_T\\).\nNa Figura 6.12 são plotadas as séries temporais anuais de área plantada em hectare e grãos produzidos em toneladas no Brasil de 1977 a 2022, Ipeadata. As séries apresentam tendência de crescimento não linear.\n\n\n\n\n\nFigura 4.1: Produção de grãos no Brasil\n\n\n\n\nAo plotar um diagrama de dispersão entre as séries, pode-se observar uma correlação linear positiva alta entre estas, conforme Figura 4.2.\n\n\n\n\n\nFigura 4.2: Área plantada versus Produção de grãos\n\n\n\n\nConforme observado na Figura 4.3, pode-se considerar em diversos casos a aproximação de uma função linear para tal relação.\n\n\n\n\n\nFigura 4.3: Modelo de regressão linear simples para produção de grãos em função da área plantada\n\n\n\n\nO modelo linear plotado em azul pode ser descrito conforme Equação abaixo, onde \\(\\beta_0\\) é uma constante e \\(\\beta_1\\) é um coeficiente linear.\n\\[\n\\hat{y}_t = \\beta_0+\\beta_{1}x_t\n\\]\nAs observações da série dependente ou resposta podem ser descritas conforme segue, como sendo o valor estimado, \\(\\hat y_t\\), adicionado de um termo de erro ou resíduo, \\(\\varepsilon_t\\).\n\\[\n\\begin{aligned}\ny_t = \\hat{y}_t + \\varepsilon_t \\\\\ny_t = \\beta_0 + \\beta_1x_t + \\varepsilon_t \\\\\n\\end{aligned}\n\\]\nConsiderando as \\(T\\) observações das séries, \\((x_1, y_1), (x_2, y_2), ..., (x_T, y_T)\\), pode-se pensar em um modelo que minimize os erros de previsão. Uma vez que o erro é normalmente distribuído, com média nula e variância \\(\\sigma_\\varepsilon^2\\), sendo os resíduos normalmente distribuídos, com média nula e variância igual a \\(\\sigma_\\varepsilon^2\\), \\(\\varepsilon \\sim N(0,\\sigma_\\varepsilon^2)\\), pode-se trabalhar a minimização da soma dos quadrados dos erros de previsão, \\(\\sum_{t=1}^{T}\\varepsilon_t^2\\). A Figura Figura 4.4 plota em linhas vermelhas verticais os resíduos. O modelo plotado minimiza a soma dos quadrados de tais erros.\n\n\n\n\n\nFigura 4.4: Erros de previsão para o modelo de regressão linear para produção de grãos em função da área plantada\n\n\n\n\nA análise à seguir expõe os coeficientes do modelo estimado com teste t para significância destes. Neste curso não será dada ênfase na inferência, mas na previsão. De forma simples um valor t com alta magnitude ou um p-valor (Pr(&gt;|t|)) baixo indica risco baixo de rejeitar a hipótese nula de ausência de efeito da variável ou série independente (\\(x_t\\)).\n\n\nSeries: producao \nModel: TSLM \n\nResiduals:\n   Min     1Q Median     3Q    Max \n-42054 -17157   1734  17910  39834 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -1.896e+05  1.500e+04  -12.64   &lt;2e-16 ***\narea_plantada  6.782e+00  3.138e-01   21.61   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23540 on 45 degrees of freedom\nMultiple R-squared: 0.9121, Adjusted R-squared: 0.9102\nF-statistic: 467.2 on 1 and 45 DF, p-value: &lt; 2.22e-16\n\n\nO modelo para prever a produção de grãos em função da área plantada fica:\n\\[\n\\hat{y}_t = -1,89 \\times 10^{5} + 6,782x_t\n\\]"
  },
  {
    "objectID": "ST4.html#regressão-linear-múltipla",
    "href": "ST4.html#regressão-linear-múltipla",
    "title": "4  Regressão de séries temporais",
    "section": "4.2 Regressão linear múltipla",
    "text": "4.2 Regressão linear múltipla\nNo caso de onde há múltiplas séries exógenas ou regressoras de interesse, \\(x_{t1}, x_{t2}, ..., x_{tk}\\), onde \\(k\\) é o número de séries consideradas para estimar \\(y_t\\), pode-se considerar o modelo com um coeficiente linear associado a cada variável, conforme Equação 4.3.\n\\[\n\\hat{y}_t = \\beta_0 + \\beta_1x_{t1} + \\beta_2x_{t2} + \\cdots + \\beta_kx_{tk} = \\beta_0 + \\sum_{j=1}^{k}\\beta_jx_{tj},  \n\\tag{4.3}\\]\nou de forma matricial segundo Equação 4.4, com \\(\\mathbf{X}_{[T\\times (k+1)]}\\) e \\(\\mathbf{\\beta}_{[(k+1) \\times 1]}\\):\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{\\beta}\n\\end{aligned},\n\\tag{4.4}\\]\nonde a matrix \\(\\mathbf{X}\\) contém uma coluna unitária para a constante e uma coluna para cada série independente:\n\\[\n\\mathbf{X} =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1k}\\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2k} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n1 & x_{T1} & x_{T2} & \\cdots & x_{Tk} \\\\\n\\end{bmatrix}, e\\\\\n\\]\ne \\(\\beta\\) consiste no vetor de coeficientes:\n\\[\n\\mathbf{\\beta}^T =\n\\begin{bmatrix}\n\\beta_0 & \\beta_1 & \\cdots & \\beta_k\\\\\n\\end{bmatrix}. \\\\\n\\]\nOs valores observados da série \\(\\mathbf{y}\\) podem ser recuperados somando os valores preditos e o erro, conforme Equação 4.5.\n\\[\n\\begin{aligned}\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\varepsilon}\n\\end{aligned}\n\\tag{4.5}\\]\nTomando tal notação, a soma dos quadrados dos erros pode ser descrita como \\(\\sum_{t=1}^{T}\\varepsilon_t^2 = \\mathbf{\\varepsilon}^T\\mathbf{\\varepsilon}\\). Desenvolvendo tal expressão tem-se:\n\\[\n\\begin{aligned}\nL(\\mathbf{\\beta}) = \\mathbf{\\varepsilon}^T\\mathbf{\\varepsilon} = (\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta}) \\\\\n\\mathbf{y}^T\\mathbf{y} - 2\\mathbf{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\mathbf{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\mathbf{\\beta}\n\\end{aligned}\n\\]\nPara minimizar \\(L\\) em relação à estimativa de \\(\\mathbf{\\beta}\\), pode-se diferenciar tal quantidade em relação à \\(\\mathbf{\\beta}\\) e igualar a zero:\n\\[\n\\begin{aligned}\n\\frac{\\partial L}{\\partial \\mathbf{\\beta}} = -2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\mathbf{\\beta} = 0 \\\\\n\\end{aligned}\n\\]\nAs estimativas dos coeficientes \\(\\hat\\beta\\) obtidas segundo a Equação 4.6 minimizam a soma dos quadrados dos resíduos, \\(\\sum \\varepsilon_i^2\\), sendo, portanto, as estimativas de mínimos quadrados.\n\\[\n\\hat{\\mathbf{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}(\\mathbf{X}^T\\mathbf{y})\n\\tag{4.6}\\]\nSeja a série multivariada de exportação, importação, produção e vendas de fertilizantes no Brasil em toleladas, plotada na Figura 4.5, disponível em Ipeadata. A série tem frequência mensal e possui dados a partir de 1998, exceto para a de exportação, disponível a partir de 2013. Observa-se um volume muito maior de importações que produção e exportações, além de sazonalidade. As séries de importação e vendas apresentam padrão de crescimento.\n\n\n\n\n\n\n\n\nFigura 4.5: Fertilizantes no Brasil\n\n\n\n\n\nObserva-se na Figura 4.6 diagramas de dispersão e correlações aos pares para os dados a partir de 2013. Há correlação positiva mais significativa entre as séries de vendas e importação. A partir de 2013, a queda na produção é acompanhada do aumento nas importações, o que justifica a correlação negativa.\n\n\n\n\n\n\n\n\nFigura 4.6: Correlação entre as séries de fertilizantes\n\n\n\n\n\nSeja um modelo de regressão para prever a venda de fertilizantes em função das outras séries a partir de 2013. A seguir apresenta-se tal modelo. Apenas a série de exportações não foi significativa.\n\n\nSeries: vendas \nModel: TSLM \n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1342150  -397913    32404   402134  1619150 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -8,085e+05  4,687e+05  -1,725  0,08690 .  \nproducao     1,872e+00  5,821e-01   3,215  0,00165 ** \nimportacao   1,099e+00  7,735e-02  14,210  &lt; 2e-16 ***\nexportacao  -5,323e-01  2,742e+00  -0,194  0,84640    \n---\nSignif. codes:  0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 ' ' 1\n\nResidual standard error: 585300 on 128 degrees of freedom\nMultiple R-squared: 0,6446, Adjusted R-squared: 0,6363\nF-statistic: 77,39 on 3 and 128 DF, p-value: &lt; 2,22e-16\n\n\nO modelo obtido pode ser escrito conforme Equação 4.7, onde \\(\\hat y_t\\) consiste na estimativa de vendas n período \\(t\\), \\(x_{t1}\\) consiste no volume produzido, \\(x_{t2}\\) no volume importado e \\(x_{t3}\\) no volume exportado no período \\(t\\).\n\\[\n\\hat y_t = -8,08\\times10^5 + 1,87x_{t1} + 1,10x_{t2} -5,32x_{t3}\n\\tag{4.7}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#desempenho-do-modelo-de-regressão",
    "href": "ST4.html#desempenho-do-modelo-de-regressão",
    "title": "4  Regressão de séries temporais",
    "section": "4.3 Desempenho do modelo de regressão",
    "text": "4.3 Desempenho do modelo de regressão\nUma forma de medir o ajuste do modelo obtido aos dados seria a partir do cálculo do coeficiente de determinação múltipla, \\(R^2\\), conforme a Equação 4.8,\n\\[\n\\begin{align}\nR^2 &= 1- SS_{E}/SS_T \\\\\nR^2 &= 1- \\frac{\\sum_{t=1}^{T}(y_t-\\hat{y}_t)^2}{\\sum_{i=t}^{T}(y_y-\\overline{y})^2} = 1- \\frac{\\sum_{t=1}^{T}\\varepsilon_t^2}{\\sum_{i=t}^{T}(y_y-\\overline{y})^2},\n\\end{align}\n\\tag{4.8}\\]\nonde \\(SS_E\\) consiste na soma dos quadrados dos erros e \\(SS_T\\) consiste na soma dos quadrados total, ou no numerador da variância da série a ser predita.\nO \\(R^2\\) sempre aumenta ao se adicionar novos termos no modelo, mesmo se estes não são significativos, uma vez que não leva em conta os graus de liberdade no cálculo. O coeficiente de determinação múltipla ajustado, \\(R^2_{aj}\\), é uma métrica mais interessante, já que considera as médias dos quadrados ao invés das somas dos quadrados dos erros, conforme a Equação 4.9.\n\\[\n\\begin{align}\nR^2_{aj} &= 1- MS_{E}/MS_T \\\\\nR^2_{aj} &= 1- \\frac{\\sum_{t=1}^{T}(y_t-\\hat{y}_t)^2/(T-K-1)}{\\sum_{t=1}^{T}(y_t-\\overline{y})^2/(T-1)},\n\\end{align}\n\\tag{4.9}\\]\nonde \\(K\\) é o número de termos no modelo, \\(MS_E\\) consiste média dos quadrados dos erros, que consiste na estimativa de variância dos resíduos, enquanto \\(MS_T\\) consiste na média dos quadrados total, ou na variância da série a ser predita.\nPara o modelo de regressão simples para produção de grãos em função da área plantada foi obtido um ajuste de mais de 91%, garantindo tal percentual de explicação da variabilidade da série de produção em função da área plantada. A Figura 4.7 plota a série de produção de grãos observada e a aproximada pelo modelo de regressão.\n\n\n\n\n\n\n\n\nFigura 4.7: Produção de grãos\n\n\n\n\n\nA Figura 4.8 plota a série de vendas de fertilizantes observada e a aproximada pelo modelo de regressão múltipla.\n\n\n\n\n\n\n\n\nFigura 4.8: Valores ajustados para a série de vendas de fertilizantes",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#diagnóstico-dos-resíduos",
    "href": "ST4.html#diagnóstico-dos-resíduos",
    "title": "4  Regressão de séries temporais",
    "section": "4.4 Diagnóstico dos resíduos",
    "text": "4.4 Diagnóstico dos resíduos\nA Figura 4.9 apresenta alguns gráficos dos resíduos do modelo de produção de grãos em função da área plantada. Pode-se observar que o primeiro gráfico apresenta tendências em alguns instantes, com padrão não aleatório, indicando presença de autocorrelação. O correlograma confirma presença de autocorrelação nos resíduos até a defasagem de 5 observações. Logo, há informação importante não capturada pelo modelo de regressão.\n\n\n\n\n\n\n\n\nFigura 4.9: Resíduos do modelo de produão de grãos em função da área plantada",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#preditores-úteis",
    "href": "ST4.html#preditores-úteis",
    "title": "4  Regressão de séries temporais",
    "section": "4.5 Preditores úteis",
    "text": "4.5 Preditores úteis\nMuitas séries temporais costumam apresentar tendência linear. Um modelo linear simples pode considerar o tempo, \\(t\\), como preditor, de forma a modelar a tendência, conforme Equação 4.10.\n\\[\n\\hat{y}_t = \\beta_0+\\beta_{1}t\n\\tag{4.10}\\]\nPode-se também considerar variáveis dicotômicas ou binárias (dummy) para considerar a sazonalidade, feriados, ou algum evento especial. Por exemplo, para sazonalidade anual com uma série de frequência quadrimestral, pode-se considerar como variávis dummy as expostas na Tabela Tabela 4.1, com o modelo descrito na Equação 4.11. É importante observar que não é necessária a inclusão de todas variáveis dicotômicas no modelo, uma vez que se \\(d_{2,t}=d_{3,t}=d_{4,t}=0\\), então \\(d_{1,t}=1\\).\n\n\n\nTabela 4.1: Criação de variáveis dummy\n\n\n\n\n\nQuadrimestre\n\\(d_{1,t}\\)\n\\(d_{2,t}\\)\n\\(d_{3,t}\\)\n\\(d_{4,t}\\)\n\n\n\n\nQ1\n1\n0\n0\n0\n\n\nQ2\n0\n1\n0\n0\n\n\nQ3\n0\n0\n1\n0\n\n\nQ4\n0\n0\n0\n1\n\n\nQ1\n1\n0\n0\n0\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\n\nA Equação Equação 4.11 expõe o modelo de regressão com tais variáveis além do termo de tendência.\n\\[\n\\hat{y}_t = \\beta_0+\\beta_{1}t + \\beta_2d_{2,t} + \\beta_3d_{3,t} + \\beta_4d_{4,t}\n\\tag{4.11}\\]\nA Figura 4.10 exibe a série temporal de temperatura de São João del-Rei para os dias 15 a 28 de junho com frequência horária.\n\n\n\n\n\n\n\n\nFigura 4.10: Temperatura em São João del-Rei nas duas últimas semanas de junho\n\n\n\n\n\nA Figura 4.11 expõe o gráfico sazonal da mesma série. Observa-se sazonalidade diária e uma tendência de crescimento, especialmente da temperatura mínima, para os dias considerados.\n\n\n\n\n\n\n\n\nFigura 4.11: Gráfico sazonal da temperatura em São João del-Rei\n\n\n\n\n\nUm modelo de regressão considerando a tendência e sazonalidade para este caso deve considerar como variáveis dummy o dia, de forma a capturar a variação hora a hora. Logo, neste caso, 24 variáveis dummy são criadas. Observa-se que além da tendência a maior parte de tais variáveis apresenta significância e o modelo contempla mais de 95% de variabilidade da série.\n\n\nSeries: Temperatura \nModel: TSLM \n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3,20212 -0,76300 -0,08292  0,87326  2,92845 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    1,953e+01  3,454e-01  56,556  &lt; 2e-16 ***\ntrend()        8,882e-03  6,822e-04  13,020  &lt; 2e-16 ***\nseason()day2  -1,580e+00  4,573e-01  -3,456 0,000624 ***\nseason()day3  -3,053e+00  4,573e-01  -6,678 1,12e-10 ***\nseason()day4  -4,528e+00  4,575e-01  -9,897  &lt; 2e-16 ***\nseason()day5  -5,372e+00  4,575e-01 -11,744  &lt; 2e-16 ***\nseason()day6  -6,074e+00  4,574e-01 -13,278  &lt; 2e-16 ***\nseason()day7  -6,933e+00  4,574e-01 -15,157  &lt; 2e-16 ***\nseason()day8  -7,863e+00  4,574e-01 -17,191  &lt; 2e-16 ***\nseason()day9  -8,579e+00  4,574e-01 -18,757  &lt; 2e-16 ***\nseason()day10 -9,095e+00  4,574e-01 -19,886  &lt; 2e-16 ***\nseason()day11 -9,726e+00  4,574e-01 -21,265  &lt; 2e-16 ***\nseason()day12 -1,016e+01  4,573e-01 -22,206  &lt; 2e-16 ***\nseason()day13 -1,074e+01  4,573e-01 -23,491  &lt; 2e-16 ***\nseason()day14 -1,095e+01  4,573e-01 -23,949  &lt; 2e-16 ***\nseason()day15 -9,840e+00  4,573e-01 -21,517  &lt; 2e-16 ***\nseason()day16 -6,699e+00  4,573e-01 -14,648  &lt; 2e-16 ***\nseason()day17 -1,900e+00  4,573e-01  -4,156 4,20e-05 ***\nseason()day18  2,148e+00  4,573e-01   4,697 3,97e-06 ***\nseason()day19  3,775e+00  4,573e-01   8,255 4,39e-15 ***\nseason()day20  4,637e+00  4,573e-01  10,141  &lt; 2e-16 ***\nseason()day21  5,221e+00  4,573e-01  11,418  &lt; 2e-16 ***\nseason()day22  5,298e+00  4,573e-01  11,586  &lt; 2e-16 ***\nseason()day23  4,461e+00  4,573e-01   9,755  &lt; 2e-16 ***\nseason()day24  3,252e+00  4,573e-01   7,111 7,93e-12 ***\n---\nSignif. codes:  0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 ' ' 1\n\nResidual standard error: 1,21 on 311 degrees of freedom\nMultiple R-squared: 0,961,  Adjusted R-squared: 0,958\nF-statistic: 319,5 on 24 and 311 DF, p-value: &lt; 2,22e-16\n\n\nHá uma tendência de aumento da temperatura nos dias considerados de 0,00888 °C por hora, ou 0,213°C por dia. Cada coeficiente das variáveis dummy expõe a diferença da respectiva hora em relação à primeira hora do dia. Por exemplo, às 6 da manhã a diferença de temperatura em relação a 1 da manhã é igual a -4.05°C. A Figura Figura 4.12 apresenta a série observada e a prevista pelo modelo de regressão.\n\n\n\n\n\n\n\n\nFigura 4.12: Temperatura em São João del-Rei\n\n\n\n\n\nA Figura 4.13 apresenta os valores previstos e observados plotados com as horas do dia separadas em cores distintas. Observa-se o excelente ajuste do modelo e a variação da temperatura segundo hora do dia.\n\n\n\n\n\n\n\n\nFigura 4.13: Temperatura em São João del-Rei",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#seleção-de-preditores",
    "href": "ST4.html#seleção-de-preditores",
    "title": "4  Regressão de séries temporais",
    "section": "4.6 Seleção de preditores",
    "text": "4.6 Seleção de preditores\nA Figura 4.14 exibe séries temporais de petróleo refinado e derivados produzidos no Brasil em \\(m^3\\), Dados estatísticos - Agência nacional de petróleo. O petróleo considera o volume nacional e importado.\n\n\n\n\n\n\n\n\nFigura 4.14: Petróleo refinado e produção de derivados\n\n\n\n\n\nA Figura 4.15 expõe um gráfico de correlação entre tais séries. As séries foram agrupadas segundo a magnitude e sinal das correlações. A série de petróleo refinado tem correlação positiva com asfalto, oléo diesel, outros não energéticos, querosene de avião, coque e gasolina e correlação negativa ou desprezível com as demais séries.\n\n\n\n\n\n\n\n\nFigura 4.15: Correlação entre petróleo refinado e derivados\n\n\n\n\n\nA seguir expõe-se um modelo de regressão múltipla do petróleo refinado em função do volume produzido dos derivados. Apenas GLP, coque, parafina e solvente não apresentaram significância estatística a 0,05 de significância.\n\n\nSeries: petroleo \nModel: TSLM \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-728213 -101803   13923  108790  409621 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            4,781e+05  1,720e+05   2,780 0,005800 ** \nGLP                    4,487e-01  2,633e-01   1,704 0,089439 .  \nasfalto                1,044e+00  2,804e-01   3,724 0,000237 ***\ncoque                  5,506e-01  3,585e-01   1,536 0,125750    \ngasolina               4,264e-01  9,076e-02   4,698 4,11e-06 ***\nlubrificante           3,463e+00  1,037e+00   3,339 0,000954 ***\nnafta                  1,001e+00  1,421e-01   7,048 1,39e-11 ***\noleo_combustivel       9,055e-01  7,052e-02  12,841  &lt; 2e-16 ***\noleo_diesel            1,138e+00  5,430e-02  20,960  &lt; 2e-16 ***\noutros_nao_energeticos 1,497e+00  2,916e-01   5,133 5,31e-07 ***\nparafina               6,667e+00  3,943e+00   1,691 0,091924 .  \nquerosene_aviao        1,409e+00  1,712e-01   8,230 6,99e-15 ***\nquerosene_iluminante   8,834e+00  2,943e+00   3,001 0,002929 ** \nsolvente               1,358e+00  9,322e-01   1,456 0,146383    \n---\nSignif. codes:  0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 ' ' 1\n\nResidual standard error: 176300 on 282 degrees of freedom\nMultiple R-squared: 0,9503, Adjusted R-squared: 0,948\nF-statistic: 414,9 on 13 and 282 DF, p-value: &lt; 2,22e-16\n\n\nA seguir expõe-se um modelo de regressão múltipla excluindo os termos não significativos do modelo inicial. O modelo apresentou melhora no ajuste, com \\(R^2_{aj} = 0,9558\\).\n\n\nSeries: petroleo \nModel: TSLM \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-657756  -91477    9494   92705  484690 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             1,763e+06  1,956e+05   9,010  &lt; 2e-16 ***\nasfalto                 9,308e-01  2,470e-01   3,768 0,000200 ***\ngasolina                5,786e-01  7,556e-02   7,658 2,96e-13 ***\nlubrificante            1,541e+00  9,571e-01   1,610 0,108587    \nnafta                   6,184e-01  1,180e-01   5,238 3,15e-07 ***\noleo_combustivel        1,057e+00  6,619e-02  15,975  &lt; 2e-16 ***\noleo_diesel             1,221e+00  3,998e-02  30,550  &lt; 2e-16 ***\noutros_nao_energeticos  9,912e-01  2,634e-01   3,763 0,000204 ***\nquerosene_aviao         1,546e+00  1,537e-01  10,058  &lt; 2e-16 ***\nquerosene_iluminante   -1,690e+00  2,792e+00  -0,605 0,545491    \ndata                   -6,809e+01  8,892e+00  -7,658 2,96e-13 ***\n---\nSignif. codes:  0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 ' ' 1\n\nResidual standard error: 162500 on 285 degrees of freedom\nMultiple R-squared: 0,9573, Adjusted R-squared: 0,9558\nF-statistic: 639,7 on 10 and 285 DF, p-value: &lt; 2,22e-16\n\n\nGeralmente, em regressão múltipla é interessante selecionar um modelo com os melhores preditores, de forma a melhorar a capacidade preditiva do modelo. Além do \\(R^2_{aj}\\), outras métricas podem ser usadas, por exemplo o critério de informação de Akaike, AIC. O AIC considera o número de parâmetros e o erro do modelo, sendo esta uma métrica mais interessante para seleção de modelos.\n\\[\nAIC = T\\text{ log}\\bigg(\\frac{SS_E}{T}\\bigg)+2(k+2)\n\\]\nA Tabela 4.2 apresenta os resultados de AIC, AIC corrigido e \\(R^2_{aj}\\) para o modelo completo e o modelo reduzido. O modelo reduzido apresentou melhor resultado, uma vez que minimiza AIC e AICc.\n\n\n\n\nTabela 4.2: \\(R^2_{aj}\\), AIC e AIC corrigido para os modelos\n\n\n\n\n\n\nmodel\nadj_r_squared\nAIC\nAICc\n\n\n\n\ncompleto\n0,9480198\n7167,001\n7168,715\n\n\nreduzido\n0,9558487\n7115,814\n7116,917\n\n\n\n\n\n\n\n\nA forma correta de realizar a remoção de coeficientes, não é considerando a significância. Ademais, não sugere-se a remoção manual de coeficientes. Recomenda-se o uso de um algoritmo para tal fim. O algoritmo stepwise com eliminação para trás segue os seguintes passos:\n\nComece com o modelo completo.\nRemova um preditor por vez. Mantenha o modelo com melhor desempenho, considerando por exemplo o AIC.\nRepita o procedimento até encontrar o melhor modelo.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#previsão",
    "href": "ST4.html#previsão",
    "title": "4  Regressão de séries temporais",
    "section": "4.7 Previsão",
    "text": "4.7 Previsão\nA previsão à frente não é geralmente possível quando se considera outras séries como preditoras, uma vez que não se conhece os valores futuros das séries. Por exemplo, no último caso do petróleo e derivados, os derivados vêm depois, sendo mais útil para previsão do volume refinado um modelo que considere ou a decomposição ou outros métodos mais sofisticados ainda não abordados, os quais levam em conta a autocorrelação da série. Entretanto, nos casos de regressão onde se utiliza como preditores a tendência e a sazonalidade a partir de variáveis dummy, é possível realizar a previsão à frente. A Figura 4.16 expõe a previsão de dois dias à frente para a temperatura de São joão del-Rei utilizando o modelo anteriormente obtido.\n\n\n\n\n\n\n\n\nFigura 4.16: Previsão da temperatura em São João del-Rei\n\n\n\n\n\nApesar de não ser possível realizar previsões à frente para casos de regressão considerando outras séries temporais como preditoras, é possível realizar nestes casos previsões baseadas em cenários. Seja o caso exposto anteriormente onde deseja-se prever a venda de fertilizantes. A ?fig-prev_cenar expõe a previsão para dois cenários, um de aumento e outro de decréscimo nos índices de produção de bens de capital e intermediários. Este tipo de análise pode ser útil para adiantar possíveis cenários e viabilizar ações de planejamento.\n\n\n\n\n\n\n\n\nFigura 4.17: Previsão de cenários para venda de fertilizantes",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#regressão-não-linear",
    "href": "ST4.html#regressão-não-linear",
    "title": "4  Regressão de séries temporais",
    "section": "4.8 Regressão não linear",
    "text": "4.8 Regressão não linear\nTransformações podem ser interessantes para tratar a não lineariedade na série a ser predita e nas preditoras. Há muitos casos que a tendência observada em uma série não é linear. Nestes casos podem ser considerada transformação polinomial na tendência.\nUma opção interessante em alguns casos é utilizar transformação logarítimica em ambas séries independentes e dependente ou em apenas uma destas. Para o caso simples, com transformação em ambas as séries, tem-se o seguinte modelo.\n\\[\n\\text{log} (y_t) = \\beta_0+\\beta_1\\text{log} (x_t)\n\\]\nPode-se pensar em considerar um termo quadrático ou de ordem maior para a tendência, de forma a contemplar uma tendência não linear. Entretanto, não se recomenda tal estratégia, uma vez que na maioria dos casos a previsão resultante extrapola muito a realidade.\n\\[\n\\hat{y}_t = \\beta_0+\\beta_{1}t+\\beta_{2}t^2\n\\]\nUma abordagem mais interessante é pensar em modelos lineares por partes, de forma a considerar modelos lineares distintos em cada parte do horizonte temporal da série, consistindo em um modelo não linear formado por peças lineares (piecewise regression). Por exemplo, um modelo com uma divisão no tempo, \\(\\tau\\), ´pode ser descrito conforme segue:\n\\[\n\\hat{y}_t = \\beta_0+\\beta_{1}t+\\beta_{2}(t-\\tau)_+,\n\\] onde:\n\\[\n(t-\\tau)_+ = \\bigg\\{\n\\begin{align} 0 \\text{, se } t&lt; \\tau \\\\\n              t-\\tau \\text{, se } t\\geq \\tau\n\\end{align}\n\\]\nNa Figura 4.18 é exibida a série temporal de emissões de gases de efeito estufa devido a produção de energia no Brasil. Os dados tem frequência anual e são disponibilizados desde 1990 até 2020 em SIRENE - Sistema de Registro Nacional de Emissões. As emissões são disponibilizadas em giga gramas (Gg) de dióxido de carbono equivalente. Observa-se tendência de aumento até 2014 e queda a partir de então.\n\n\n\n\n\n\n\n\nFigura 4.18: Emissões de gases de efeito estufa por atividades de produção de energia no Brasil\n\n\n\n\n\nA Figura 4.19 expõe a mesma série com três modelos, um com transformação logarítimica na resposta, resultando em um modelo exponencial, um modelo linear e outro linear por partes (piecewise). Para os três modelos foram utilizados dados de até 2017 para treinamento. Para o modelo por partes foram consideradas duas partições, em 2005 e 2014. Foi realizada a previsão para 5 anos a partir de 2018. Pode-se observar que o terceiro caso parece mais interessante pois ajusta-se melhor à queda observada nos últimos anos.\n\n\n\n\n\n\n\n\nFigura 4.19: Emissões de gases de efeito estufa por atividades de produção de energia no Brasil",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST5.html#suavização-exponencial-simples",
    "href": "ST5.html#suavização-exponencial-simples",
    "title": "5  Suavização exponencial",
    "section": "",
    "text": "Tabela 5.1: Pesos na suavização exponencial simples\n\n\n\n\n\nObservação\n\\(\\alpha=0.2\\)\n\\(\\alpha=0.5\\)\n\\(\\alpha=0.8\\)\n\n\n\n\n\\(y_T\\)\n0.200000\n0.500000\n0.800000\n\n\n\\(y_{T-1}\\)\n0.160000\n0.250000\n0.160000\n\n\n\\(y_{T-2}\\)\n0.128000\n0.125000\n0.032000\n\n\n\\(y_{T-3}\\)\n0.102400\n0.062500\n0.006400\n\n\n\\(y_{T-4}\\)\n0.081920\n0.031250\n0.001280\n\n\n\\(y_{T-5}\\)\n0.065536\n0.015625\n0.000256",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST5.html#suavização-exponencial-com-tendência",
    "href": "ST5.html#suavização-exponencial-com-tendência",
    "title": "5  Suavização exponencial",
    "section": "5.2 Suavização exponencial com tendência",
    "text": "5.2 Suavização exponencial com tendência\nEm casos com tendência pode-se aplicar o método de Holt (2004), o qual considera uma equação para o nível, \\(l_t\\), uma para a tendência, \\(b_t\\), e a de previsão, \\(\\hat y_{t+h|t}\\), conforme Equação 5.6.\n\\[\n\\begin{align}\n\\text{Equação de previsão:    } \\hat y_{t+h} &= l_t + hb_t\\\\\n\\text{Equação do nível:    } l_t &= \\alpha y_t + (1-\\alpha)(l_{t-1}+b_{t-1})\\\\\n\\text{Equação de tendência:    } b_t &= \\beta^*(l_t-l_{t-1})+(1-\\beta^*)b_{t-1}\n\\end{align}\n\\tag{5.6}\\]\nNeste caso \\(l_t\\) é uma média ponderada da observação \\(y_t\\) e da previsão um passo a frente, dada por \\(l_{t-1}+b_{t-1}\\). A equação de tendência, \\(b_t\\), consiste em uma média ponderada da tendência no tempo \\(t\\), baseada em \\(l_t-l_{t-1}\\), e na estimativa anterior da tendência, \\(b_{t-1}\\).\nA Figura 5.3 expõe a série anual da população projetada para o Brasil até 2010, revisada em 2008, disponível em IBGE. Observa-se tendência de crescimento próxima de linear.\n\n\n\n\n\n\n\n\nFigura 5.3: População do Brasil\n\n\n\n\n\nA Tabela 5.4 expõe os parâmetros estimados de suavização exponencial com tendência para a série da populaçao projetada do Brasil.\n\n\n\n\nTabela 5.4: Parâmetros de suavização exponencial com tendência para a série da população projetada do Brasil\n\n\n\n\n\n\nTermo\nEstimativa\n\n\n\n\nalpha\n1,00\n\n\nbeta\n0,44\n\n\nl[0]\n116948789,80\n\n\nb[0]\n2842713,24\n\n\n\n\n\n\n\n\n\n5.2.1 Suavização exponencial com tendência amortecida\nUm problema do método de Holt (2004) para suavização exponencial com tendência é que ele costuma apresentar uma estimativa linear que em longos horizontes de previsão que não se confirma. Uma opção é a abordagem de Gardner e Mckenzie (1985) que propõe amortecer as previsões. O método inclui o parâmetro de amortecimento \\(0&lt;\\phi&lt;1\\).\n\\[\n\\begin{align}\n\\text{Equação de previsão:    } \\hat y_{t+h} &= l_t + (\\phi+\\phi^2+...+\\phi^h)b_t\\\\\n\\text{Equação do nível:    } l_t &= \\alpha y_t + (1-\\alpha)(l_{t-1}+\\phi b_{t-1})\\\\\n\\text{Equação de tendência:    } b_t &= \\beta^*(l_t-l_{t-1})+(1-\\beta^*)\\phi b_{t-1}\n\\end{align}\n\\]\nCaso \\(\\phi=1\\), então tem-se o método de Holt já exposto. O método tende a gerar previsões com tendência não linear para curtos períodos que se tornam constantes em longos horizontes à frente das observações. A Figura 5.4 expõe as previsões 15 anos à frente para a população do Brasil considerando os dados projetados até 2010. Observa-se que o método de Holt projetaria 216 milhões de pessoas em 2022, enquanto o mesmo amortecido projetaria 210,8 milhões para o mesmo ano. Foi considerado neste caso \\(\\phi=0,97\\). Dados já observados do censo de 2022 indicam que a população do Brasil neste ano atingiu 210,3 milhões de pessoas.\n\n\n\n\n\n\n\n\nFigura 5.4: População do Brasil\n\n\n\n\n\n\n\n&lt;distribution[1]&gt;\n[1] N(2,2e+08, 1,5e+13)\n\n\nA Figura 5.5 expõe os resultados das previsões obtidas pelos mesmos métodos aplicados à série anual de emissão de gases de efeito estufa pela indústria, em Gg de CO2 equivalente, disponível em SIRENE - Sistema de Registro Nacional de Emissões. Foi considerado um \\(\\phi = 0,90\\) para o caso com amortecimento. O amortecimento é importante, uma vez que o método Holt apresenta geralmente tendência acentuada, com inclinação com mais peso em relação ao observado nos últimos anos, que pode não se confirmar a médio prazo.\n\n\n\n\n\n\n\n\nFigura 5.5: Emissões de gases de efeito estufa pela indústria",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST5.html#suavização-exponencial-com-sazonalidade",
    "href": "ST5.html#suavização-exponencial-com-sazonalidade",
    "title": "5  Suavização exponencial",
    "section": "5.3 Suavização exponencial com sazonalidade",
    "text": "5.3 Suavização exponencial com sazonalidade\nHolt (2004) e Winters (1960) adicionaram a sazonalidade na suavização exponencial. Logo, além das equações de previsão, nível e tendência, o método inclui uma equação adicional para a sazonalidade. O método considera ambos os casos aditivo e multiplicativo.\nO método Holt-Winters aditivo é denotado conforme a Equação 5.7.\n\\[\n\\begin{align}\n\\text{Equação de previsão:    } \\hat y_{t+h} &= l_t + hb_t + s_{t+h-m(k+1)}\\\\\n\\text{Equação do nível:    } l_t &= \\alpha (y_t-s_{t-m}) + (1-\\alpha)(l_{t-1}+b_{t-1})\\\\\n\\text{Equação de tendência:    } b_t &= \\beta^*(l_t-l_{t-1})+(1-\\beta^*)b_{t-1}\\\\\n\\text{Equação de sazonalidade:    } s_t &= \\gamma(y_t-l_{t-1}-b_{t-1})+(1-\\gamma)s_{t-1},\n\\end{align}\n\\tag{5.7}\\]\nonde \\(k\\) consiste na parte inteira de \\((h−1)/m\\) que garante que a estimativa dos índices sazonais usados para previsão vêm do último período sazonal da série. A equação de nível consiste em uma média ponderada entre a observação ajustada sazonalmente, \\(y_t-s_{t-m}\\), e a previsão não sazonal, \\(l_{t-1}+b_{t-1}\\), para o tempo \\(t\\). A equação de tendência não muda e a sazonal considera uma média móvel do índice sazonal atual, \\(y_t-l_{t-1}-b_{t-1}\\), e do mesmo período da estação anterior, \\(s_{t-1}\\).\nO caso multiplicativo é exposto na Equação 5.8.\n\\[\n\\begin{align}\n\\text{Equação de previsão:    } \\hat y_{t+h} &= (l_t + hb_t)  s_{t+h-m(k+1)}\\\\\n\\text{Equação do nível:    } l_t &= \\alpha \\frac{y_t}{s_{t-m}} + (1-\\alpha)(l_{t-1}+b_{t-1})\\\\\n\\text{Equação de tendência:    } b_t &= \\beta^*(l_t-l_{t-1})+(1-\\beta^*)b_{t-1}\\\\\n\\text{Equação de sazonalidade:    } s_t &= \\gamma \\frac {y_t}{(l_{t-1}-b_{t-1})}+(1-\\gamma)s_{t-1},\n\\end{align}\n\\tag{5.8}\\]\nA Figura 5.6 plota a série temporal de exportações do Brasil em US$ FOB, disponível em Resultados do Comércio Exterior Brasileiro - Dados Consolidados. Observa-se em geral tendência de crescimento, estagnação de 2011 a 2021, dada a crise político-econômica e a pandemia, seguida de nova tendência de crescimento nos anos pós-pandemia.\n\n\n\n\n\n\n\n\nFigura 5.6: Exportações do Brasil\n\n\n\n\n\nA Figura 5.7 expõe o gráfico sazonal da mesma série. O padrão cíclico não é tão claro, mas, especialmente nos últimos anos, nota-se maior volume de exportações de março a agosto.\n\n\n\n\n\n\n\n\nFigura 5.7: Gráfico sazonal para a série de exportações do Brasil\n\n\n\n\n\nA Figura 5.8 expõe modelos de suavização exponencial com tendência e sazonalidade para a série de exportações do Brasil. Os modelos foram estimados considerando dados de até 2022, sendo as previsões realizadas para 3 anos à frente. O resultado foi plotado a partir de 2020, para melhor visualização.\n\n\n\n\n\n\n\n\nFigura 5.8: Modelos de suavização exponencial com tendência e sazonalidade para a série de exportações do Brasil\n\n\n\n\n\n\n5.3.1 Suavização exponencial com tendência amortecida e sazonalidade\nO método de Holt-Winters também pode considerar o amortecimento. O caso multiplicativo geralmente fornece bons resultados, sendo descrito conforme Equação 5.9.\n\\[\n\\begin{align}\n\\text{Equação de previsão:    } \\hat y_{t+h} &= [l_t + (\\phi+\\phi^2+...+\\phi^h)b_t]  s_{t+h-m(k+1)}\\\\\n\\text{Equação do nível:    } l_t &= \\alpha \\frac{y_t}{s_{t-m}} + (1-\\alpha)(l_{t-1}+\\phi b_{t-1})\\\\\n\\text{Equação de tendência:    } b_t &= \\beta^*(l_t-l_{t-1})+(1-\\beta^*)\\phi b_{t-1}\\\\\n\\text{Equação de sazonalidade:    } s_t &= \\gamma \\frac {y_t}{(l_{t-1}-\\phi b_{t-1})}+(1-\\gamma)s_{t-1},\n\\end{align}\n\\tag{5.9}\\]\nA Figura 5.9 expõe modelos de suavização exponencial com tendência amortecida e sazonalidade para a série de exportações do Brasil. O caso multiplicativo parece uma opção interessante com boa adequação aos períodos disponíveis, fazendo uma projeção à frente mais conservadora em comparação ao sem amortecimento.\n\n\n\n\n\n\n\n\nFigura 5.9: Modelos de suavização exponencial com tendência amortecida e sazonalidade para a série de exportações do Brasil\n\n\n\n\n\nPara melhor avaliação dos resultados plotados para os modelos com sazonalidade com e sem amortecimento, a Tabela 5.5 resume os resultados das métricas de erro dos modelos para previsão de 2020 à frente, conformando que o modelo multiplicativo com amortecimento apresentou melhores resultados.\n\n\n\n\nTabela 5.5: Resultados das métricas de teste para os modelos de suavização com tendência e sazonalidade com e sem amortecimento\n\n\n\n\n\n\nmodelo\nRMSE\nMAE\nMAPE\n\n\n\n\naditivo sazonal\n2195052170\n1834091706\n6,62\n\n\naditivo sazonal amort\n2384479823\n2028508291\n7,24\n\n\nmult sazonal\n1979894926\n1550871084\n5,54\n\n\nmult sazonal amort\n1961497440\n1353227812\n4,73",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST5.html#modelos-de-ets-e-definição-de-espaço-de-estados",
    "href": "ST5.html#modelos-de-ets-e-definição-de-espaço-de-estados",
    "title": "5  Suavização exponencial",
    "section": "5.4 Modelos de ETS e definição de espaço de estados",
    "text": "5.4 Modelos de ETS e definição de espaço de estados\nOs modelos de suavização exponencial podem ser concebidos como modelos de espaço de estados, com uma equação de medição, que descreve os dados observados, e outras de estados, por exemplo as de nível, tendência e sazonalidade, que descrevem como os componentes ou estados mudam no horizonte de tempo. Outro aspecto importante ainda não abordado é que, além de considerar o erro aditivo, há a possibilidade de considerar o erro multiplicativo nos modelos de suavização exponencial.\nOs modelos de suavização exponencial são geralmente denotados por ETS(E,T,S) para descrever as três componentes (erro, tendência, suavização). O erro pode ser aditivo ou multiplicativo, E={A,M}. A tendência pode ser não considerada (N), aditiva (A) ou aditiva amortecida (damped) (Ad), T ={N,A,Ad}. Por fim, a sazonalidade pode ser desconsiderada, ou pode ser aditiva ou multiplicativa, S={N,A,M}. Logo, há 18 modelos possíveis.\nRetomando a suavização exponencial simples representada em componentes:\n\\[\n\\begin{align}\n\\text{Equação de previsão:    } \\hat y_{t+h} &= l_t\\\\\n\\text{Equação de suavização:    } l_t &= \\alpha y_t + (1-\\alpha)l_{t-1}.\\\\\n\\end{align}\n\\]\nManipulando a Equação de suavização, tem-se o resultado apresentado na Equação 5.10.\n\\[\n\\begin{align}\nl_t &= l_{t-1} + \\alpha(y_t-l_{t-1}) \\\\\n    &= l_{t-1} + \\alpha e_t,\n\\end{align}\n\\tag{5.10}\\]\nonde \\(e_t=y_t-l_{t-1}=y_t - \\hat{y}_{t|t-1}\\) é o resíduo no tempo \\(t\\). Pode-se, portanto, considerar que a observação de treino é igual ao nível anterior adicionado do erro, \\(y_t=l_{t-1}+e_t\\). Logo, deve-se assumir os resíduos como ruído branco, \\(e_t = \\varepsilon_t \\sim NID(0,\\sigma_\\varepsilon^2)\\) ou normalmente e identicamente distribuídos.\nQuando o erro é multiplicativo no caso simples tem-se \\(e_t=(y_t - \\hat{y}_{t|t-1})/\\hat{y}_{t|t-1}\\).\nA título de exemplo serão apresentados os modelos Holt-Winters aditivos com erro aditivo ETS(A,A,A) e multiplicativo ETS(M,A,A).\n\n5.4.1 Modelo de Holt-Winters aditivo, ETS(A,A,A)\nPara este caso, considerando o erro igual a \\(\\varepsilon_t =y_t - l_{t-1} + b_{t-1} + s_{t-m}\\), tem-se o modelo exposto na Equação 5.11.\n\\[\n\\begin{align}\ny_t &= l_{t-1} + b_{t-1} + s_{t-m} + \\varepsilon_t\\\\\nl_t &= l_{t-1}+b_{t-1}+ \\alpha \\varepsilon_t\\\\\nb_t &=b_{t-1} + \\beta\\varepsilon_t \\\\\ns_t &= s_{t-m} + \\gamma\\varepsilon_t, \\\\\n\\end{align}\n\\tag{5.11}\\]\nonde \\(\\beta=\\beta^*\\alpha\\).\n\n\n5.4.2 Modelo de Holt-Winters multiplicativo, ETS(M,A,A)\nPara o caso com erro multiplicativo o erro com tendência e sazonalidade aditiva, o erro é calculado conforme a Equação 5.12.\n\\[\ne_t=\n\\frac{y_t - (l_{t-1} + b_{t-1} + s_{t-m})}{(l_{t-1} + b_{t-1} + s_{t-m} )}\n\\tag{5.12}\\]\nO modelo fica conforme a Equação 5.13.\n\\[\n\\begin{align}\ny_t &= (l_{t-1} + b_{t-1} + s_{t-m} ) (1+\\varepsilon_t)\\\\\nl_t &= l_{t-1}+b_{t-1}+ \\alpha (l_{t-1}-b_{t-1}-s_{t-m})\\varepsilon_t\\\\\nb_t &=b_{t-1} + \\beta(l_{t-1} + b_{t-1} + s_{t-m} ) \\varepsilon_t \\\\\ns_t &= s_{t-m} + \\gamma(l_{t-1} + b_{t-1} + s_{t-m} ) \\varepsilon_t\\\\\n\\end{align}\n\\tag{5.13}\\]\nAqui foram apresentados apenas alguns modelos, sendo dois deles explicitados em notação de espaço de estados. RJ Hyndman e Athanasopoulos (2021) explicitam todos os 18 modelos possíveis de suavização exponencial com a notação de estado de espaços.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST5.html#previsão-e-intervalo-de-confiança-com-ets",
    "href": "ST5.html#previsão-e-intervalo-de-confiança-com-ets",
    "title": "5  Suavização exponencial",
    "section": "5.5 Previsão e intervalo de confiança com ETS",
    "text": "5.5 Previsão e intervalo de confiança com ETS\nA previsão com modelos de ETS pode ser realizada iterando as equações à frente, \\(t=T+1, ..., T+h\\). Por exemplo, para o modelo ETS(M,A,A) a previsão para o primeiro período não disponível seria \\(\\hat y_{T+1} = l_{T} + b_{T} + s_{T}\\).\nO intervalo de confiança pode ser calculado conforme já exposto anteriormente, \\(\\hat{y}_{T+h|T} \\pm1,96 \\hat\\sigma_h\\), com 1,96 sendo o valor do quantil da distribuição \\(z\\) para 0,95 de confiança. O desvio-padrão depende do método ETS usado e a estimativa é bastante complexa. Rob Hyndman et al. (2008) fornece os cálculos detalhados.\nA Figura 5.10 apresenta novamente as séries temporais de exportação, importação e produção de fertilizantes no Brasil em um mesmo painel gráfico, viabilizando a comparação entre estas. Observa-se de forma mais clara a preponderância das importações, especialmente nos últimos anos.\n\n\n\n\n\n\n\n\nFigura 5.10: Exportação, importação e Produção de fertilizantes no Brasil\n\n\n\n\n\nA série do volume de fertilizantes disponível no Brasil pode ser obtida somando os volumes de importação e exportação e subtraindo o volume de exportações. Tal série é plotada na Figura 5.11. Observa-se tendência de crescimento com variação sazonal homogênea no tempo. O ano de 2022 apresentou disponibilidade mais baixa, possivelmente em reflexo à pandemia.\n\n\n\n\n\n\n\n\nFigura 5.11: Disponibilidade de fertilizantes no Brasil\n\n\n\n\n\nA Figura 5.12 expõe o gráfico da série de disponibilidade de fertilizantes para o Brasil. Observa-se aumento da disponibilidade ao longo dos anos e maior disponibilidade no segundo semestre dos anos de observação.\n\n\n\n\n\n\n\n\nFigura 5.12: Gráfico sazonal para Disponibilidade de fertilizantes\n\n\n\n\n\nA Figura 5.13 exibe novamente a série com resultados de previsões a partir de 2022 para 4 distintos modelos ETS, aditivos e multiplicativos, com e sem amortecimento na tendência.\n\n\n\n\n\n\n\n\nFigura 5.13: Previsão para Disponibilidade de fertilizantes usando distintos modelos ETS\n\n\n\n\n\nA Tabela 5.6 resume o desempenho dos modelos considerando os dados de 2022 à frente. Observa-se que o modelo aditivo com amortecimento, ETS(A,Ad,A), apresentou melhor resultado para todas as métricas de erro.\n\n\n\n\nTabela 5.6: Desempenho dos modelos ETS para prever a disponibilidade de fertilizantes\n\n\n\n\n\n\nmodelo\nRMSE\nMAE\nMAPE\n\n\n\n\nETS(A,A,A)\n845372,4\n716194,6\n21,17\n\n\nETS(A,Ad,A)\n685842,9\n544237,5\n16,21\n\n\nETS(M,A,M)\n842781,1\n707120,8\n20,23\n\n\nETS(M,Ad,M)\n774105,7\n585567,3\n16,96\n\n\n\n\n\n\n\n\nA Figura 5.14 expõe os gráficos de resíduos para o modelo ETS(A,Ad,A). Observa-se padrão aleatório na série residual, bom ajuste à normal e autocorrelação residual com significância para duas defasagens apenas. Para esclarecer se esta autocorrelação pode representar um problema, a Tabela 5.7 exibe o resultado do teste. Não se pode garantir a ausência de autocorrelação residual.\n\n\n\n\n\n\n\n\nFigura 5.14: Gráficos de resíduos para o modelo ETS(A,Ad,A)\n\n\n\n\n\n\n\n\n\nTabela 5.7: Teste de Ljung-Box para o modelo ETS(A,Ad,A) para a série de fertilizantes\n\n\n\n\n\n\nestatística\npvalor\n\n\n\n\n32,92371\n0,0343968\n\n\n\n\n\n\n\n\nFinalmente, a Figura 5.15 expõe a previsão usando o modelo ETS(A,Ad,A) para quatro anos à frente. Observa-se boa aproximação às observações recentes, especialmente nos últimos dois anos.\n\n\n\n\n\n\n\n\nFigura 5.15: Previsão com intervalo de confiança via ETS(A,Ad,A) para disponibilidade de fertilizantes",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST2.html#exercícios-propostos",
    "href": "ST2.html#exercícios-propostos",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "2.10 Exercícios propostos",
    "text": "2.10 Exercícios propostos\n\nObtenha e interprete as estatísticas descritivas simples para a série temporal de volume de carros produzidos no Brasil.\n\n\nFaça o correlograma da série temporal de temperatura com defasagem máxima de uma semana. Interprete o padrão de autocorrelação obtido.\n\n\nRealize a modelagem com os métodos da média, ingênuo e da deriva para a série do índice Ibovespa, considerando apenas os primeiros 150 dias da série. Obtenha um gráfico com a série filtrada e a previsão para 37 dias à frente com tais métodos.\n\n\nAvalie os resíduos para os métodos considerados para a série do índice Ibovespa.\n\n\nFaça o teste do modelo com as 37 últimas observações, estimando as métricas de erro MAE, MASE e RMSE e selecione o melhor modelo.\n\n\n\n\n\nBox, George EP, Gwilym M Jenkins, Gregory C Reinsel, e Greta M Ljung. 2008. Time series analysis: forecasting and control. John Wiley & Sons.\n\n\nBox, George EP, e David A Pierce. 1970. «Distribution of residual autocorrelations in autoregressive-integrated moving average time series models». Journal of the American statistical Association 65 (332): 1509–26.\n\n\nGuerrero, Victor M. 1993. «Time-series analysis supported by power transformations». Journal of forecasting 12 (1): 37–48.\n\n\nHyndman, RJ, e G Athanasopoulos. 2021. Forecasting: principles and practice. OTexts. OTexts.com/fpp3.\n\n\nLjung, Greta M, e George EP Box. 1978. «On a measure of lack of fit in time series models». Biometrika 65 (2): 297–303.\n\n\nMakridakis, Spyros, Allan Andersen, Robert Carbone, Robert Fildes, Michele Hibon, Rudolf Lewandowski, Joseph Newton, Emanuel Parzen, e Robert Winkler. 1982. «The accuracy of extrapolation (time series) methods: Results of a forecasting competition». Journal of forecasting 1 (2): 111–53.\n\n\nMontgomery, Douglas C, Cheryl L Jennings, e Murat Kulahci. 2015. Introduction to time series analysis and forecasting. John Wiley & Sons.\n\n\nYule, G Udny. 1926. «Why do we sometimes get nonsense-correlations between Time-Series?–a study in sampling and the nature of time-series». Journal of the royal statistical society 89 (1): 1–63.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Séries Temporais e Previsão",
    "section": "",
    "text": "Prefácio\nEste livro visa abordar os principais métodos de análise e previsão de séries temporais. As séries temporais consideradas são, em sua maioria, brasileiras. Tais séries são disponibilizadas em Séries Temporais e Previsão - dados.\nO livro segue os pacotes e estilo moderno de implementação da excelente referência Hyndman and Athanasopoulos (2021), disponível em OTexts.com/fpp3, entretanto não considera os mesmos exemplos. As implementações são realizadas na linguagem de programação R.\nO livro visa trabalhar os principais métodos para séries temporais com abordagem prática e aplicada, considerando todo o processo de implementação e interpretação dos resultados, desde o tratamento inicial dos dados, estimativa, diagnóstico, previsão e avaliação do desempenho dos modelos.\nRobson Bruno Dutra Pereira\n\n\n\n\nHyndman, RJ, and G Athanasopoulos. 2021. Forecasting: Principles and Practice. OTexts. OTexts.com/fpp3.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "ST3.html#implementação-em-r",
    "href": "ST3.html#implementação-em-r",
    "title": "3  Decomposição de séries temporais",
    "section": "3.9 Implementação em R",
    "text": "3.9 Implementação em R\nA seguir apresenta-se parte das implementações na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo. Os dados utilizados estão disponíveis em Previsão, por Robson Bruno Dutra Pereira.\nCarregando pacotes.\n\nlibrary(tsibble)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(fabletools)\nlibrary(feasts)\nlibrary(fable)\nlibrary(forecast)\nlibrary(lubridate)\ntheme_set(theme_bw())\n\nSérie mensal de produção de gás natural no Brasil.\n\ngn &lt;- read.csv(\"gasnatural.csv\", header=T)\n\ngn_ts &lt;- gn |&gt;\n  mutate(Data = yearmonth(as.Date(Data, \n                                  format= \"%m/%d/%Y\"))) |&gt;\n  as_tsibble(index=Data)\n\nVisualizando.\n\ngn_ts |&gt; \n  autoplot(Producao) +\n  ggtitle(\"Produção mensal de GNV no Brasil\")\n\nNormalizando a série por número de dias de cada mês.\n\ngn_norm &lt;- gn_ts |&gt;\n  mutate(dias_no_mes = days_in_month(Data),\n         Producao_normalizada = Producao/dias_no_mes) \n\nVisualizando.\n\ngn_norm |&gt; \n  autoplot(Producao_normalizada) +\n  ggtitle(\"Produção mensal média de gás natural no Brasil\")\n\nAplicando transformação de Box-Cox na série.\n\nlambda &lt;- gn_norm |&gt;\n  features(Producao_normalizada, features = guerrero) |&gt;\n  pull(lambda_guerrero)\n\ngn_norm |&gt;\n  autoplot(box_cox(Producao_normalizada, lambda)) +\n  ggtitle(\"Série transformada de LGN no Brasil\")\n\nSérie do índice de produção de bens intermediários. A série com todos os índices foi apresentada no capítulo 1.\n\nprod_inter &lt;- prod_ts |&gt;\n  filter(indice==\"intermediarios\") |&gt;\n  select(!indice)\n\nprod_inter |&gt;\n  autoplot(valor) +\n  ggtitle(\"Índice de produção de produtos intermediários\")\n\nGráfico sazonal da série de produtos intermediários.\n\nprod_inter |&gt; \n  gg_season(valor)\n\nTendência para a série de produção de produtos intermediários via média móvel. O comando slide_dbl itera é usado para tal, sendo definida a janela com .before e .after. Faz-se inicialmente a média móvel 12-MA e depois 2-MA no resultado da primeira, de forma a obter a média móvel \\(2\\times12\\)-MA.\n\nprod_inter &lt;- prod_inter |&gt;\n  mutate(`12-MA` = slider::slide_dbl(valor, mean,\n                                     .before = 5,\n                                     .after = 6, \n                                     .complete = T),\n         `2x12-MA` = slider::slide_dbl(`12-MA`, mean,\n                                     .before = 1,\n                                     .after = 0, \n                                     .complete = T))\n\nprod_inter |&gt;\n  autoplot(valor, colour = \"grey\") +\n  geom_line(aes(y=`2x12-MA`), colour = \"seagreen\") +\n  ggtitle(\"Índice de produção de produtos intermediários\")\n\nDecomposição clássica aditiva da série de produtos intermediários. Usa-se o comando classical_decomposition com o argumento type = \"additive\".\n\ndcomp &lt;- prod_inter |&gt;\n  model(classical_decomposition(valor, \n                                type = \"additive\")) |&gt;\n  components()\n\ndcomp\n\n\ndcomp |&gt; \n  autoplot() \n\nSérie de passageiros em vôos domésticos do Brasil.\n\nvoosbr &lt;- read.csv(\"voosbr_ts.csv\", \n                   header = T)\n\n\nvoosbr_ts &lt;- voosbr |&gt;\n    mutate(data = yearmonth(data)) |&gt; \n    as_tsibble(index = data)\n\n\nvoosbr_ts |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  autoplot(Passageiros) +\n  labs(title=\"Passageiros em vôos no Brasil\", x=\"\")\n\nDecomposição via STL da série de passageiros com transformação logaritimica. Deve-se usar o comando STL. Tanta a tendência com trend quando a sazonalidade com season podem ter a janela ajustada como argumento window, com número impar. Para o exemplo abaixo foi deixado o padrão para a parte sazonal e 7 para a tendência. Se window = \"periodic\" na sazonalidade, então obtém-se a parte sazonal idêntica ao longo dos anos. O período da sazonalidade é fornecido com argumento period.\n\nvoosbr_ts |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  model(\n    STL(log(Passageiros) ~ trend(window = 7) +\n                   season(period = 12),\n    robust = TRUE)) |&gt;\n  components() |&gt;\n  autoplot() + labs(title =\n    \"Decomposição da série log(passageiros) em vôos do Brasil\")\n\nModelagem via decomposição. Modelo STL para a série de produtos intermediários.\n\npi_stl_fit &lt;- prod_inter |&gt;\n  filter(year(Data)&lt;2022) |&gt;\n  model(stl = decomposition_model(\n    STL(valor ~ trend(window = 7) + season(period = 12), \n        robust = TRUE),\n    NAIVE(season_adjust)\n  ))\n\n\npi_stl_fit |&gt; \n  gg_tsresiduals()\n\nPrevisão para 2 anos e 7 meses à frente.\n\npi_stl_fit |&gt;\n  forecast(h=31) |&gt;\n  autoplot(prod_inter) +\n  ggtitle(\"Previsão para o índice de produção de produtos intermediários\")\n\nMétricas de desempenho para a previsão.\n\npi_stl_fc &lt;- pi_stl_fit |&gt;\n  forecast(h=31)\n\npi_future &lt;- prod_inter |&gt;\n  filter(year(Data)&gt;=2022)\n\naccuracy(pi_stl_fc, pi_future) |&gt;\n  select(.model, RMSE, MAE, MAPE)\n\nDecomposição clássica multiplicativa da série de passageiros.\n\nvoosbr_ts |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  model(\n    classical_decomposition(Passageiros, type = \"multiplicative\")\n  ) |&gt;\n  components() |&gt;\n  autoplot() +\n  labs(title = \"Decomposição clássica multiplicativa da série Passageiros\")\n\nModelo via decomposição por STL. São testados dois modelos variando a janela da tendência.\n\nfit_dcmp &lt;- voosbr_ts |&gt;\n  filter(year(data)&lt;2018) |&gt;\n  model(\n    stl1 = decomposition_model(\n    STL(log(Passageiros) ~ trend(window = 7) + season(period = 12, \n                                                      window=\"periodic\"), \n        robust = TRUE),\n    NAIVE(season_adjust)),\n    stl2 = decomposition_model(\n    STL(log(Passageiros) ~ trend(window = 7) + season(period = 12,\n                                                      window = 11), \n        robust = TRUE),\n    NAIVE(season_adjust))\n  )\n\nVisualizando a previsão para 2019 e 2020 juntamente com os dados a partir de 2015.\n\nfit_dcmp |&gt;\n  forecast() |&gt;\n  autoplot(voosbr_ts |&gt; \n             filter_index(\"2015\"~\"2020\"), level = NULL) +\n  labs(y = \"\",\n       title = \"Previsão via decomposição da série de log(passageiros)\")\n\nResíduos do modelo via decomposição por STL.\n\nfit_dcmp |&gt; \n  select(stl2) |&gt;\n  gg_tsresiduals()\n\nMétricas de desempenho para os dois anos separados para teste.\n\nvoos_future &lt;- voosbr_ts |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  filter(year(data)&gt;=2018)\n\nvoos_fc &lt;- fit_dcmp |&gt;\n  forecast(h=24) \n  \naccuracy(voos_fc, voos_future) |&gt;\n  select(.model, RMSE, MAE, MAPE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#implementações-do-capítulo-3",
    "href": "ST3.html#implementações-do-capítulo-3",
    "title": "Séries temporais - Laboratório 3",
    "section": "3.9 Implementações do capítulo 3",
    "text": "3.9 Implementações do capítulo 3\nA seguir são apresentadas boa parte das implementações na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo.\nCarregando pacotes.\nSérie mensal de produção de gás natural no Brasil.\nVisualizando.\n\n\n\n\n\nNormalizando a série por número de dias de cada mês.\nVisualizando.\n\n\n\n\n\nAplicando transformação de Box-Cox na série.\n\n\n\n\n\nSérie do índice de produção de bens intermediários.\n\n\n\n\n\n\n\n\n\n\nGráfico sazonal da série de produtos intermediários.\n\n\n\n\n\nTendência para a série de produção de produtos intermediários via média móvel.\n\n\n\n\n\nDecomposição clássica aditiva da série de produtos intermediários.\n\n\n# A dable: 271 x 7 [1M]\n# Key:     .model [1]\n# :        value = trend + seasonal + random\n   .model                        Data value trend seasonal  random season_adjust\n   &lt;chr&gt;                        &lt;mth&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n 1 \"classical_decomposition… 2002 Jan  88.0  NA      -7.43 NA               95.4\n 2 \"classical_decomposition… 2002 Feb  85.2  NA     -11.7  NA               97.0\n 3 \"classical_decomposition… 2002 Mar  94.9  NA      -1.51 NA               96.5\n 4 \"classical_decomposition… 2002 Apr  96.0  NA      -4.72 NA              101. \n 5 \"classical_decomposition… 2002 May  99.1  NA       2.81 NA               96.3\n 6 \"classical_decomposition… 2002 Jun  97.2  NA       2.13 NA               95.0\n 7 \"classical_decomposition… 2002 Jul 102.   96.5     7.47 -1.76            94.7\n 8 \"classical_decomposition… 2002 Aug 102.   96.7     9.15 -4.37            92.4\n 9 \"classical_decomposition… 2002 Sep  99.1  97.1     4.90 -2.90            94.1\n10 \"classical_decomposition… 2002 Oct 105.   97.2     7.26  0.0972          97.3\n# ℹ 261 more rows\n\n\n\n\n\n\n\nDecomposição via X-11 da série de produtos intermediários.\n\n\n\n\n\nModelagem via decomposição. Modelo STL para a série de produtos intermediários.\n\n\n\n\n\nPrevisão para 2 anos e 7 meses à frente.\n\n\n\n\n\nMétricas de desempenho para a previsão.\n\n\n# A tibble: 1 × 4\n  .model  RMSE   MAE  MAPE\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 stl     2.25  1.94  1.93\n\n\nSérie de número de passageiros em vôos no Brasil. Estes dados não estão disponíveis no github do autor, mas no link citado no capítulo. Caso não consiga fazer o download, sugere-se pular os dois blocos de código seguinters e seguir com a leitura dos dados já tratados disponibilizados em seguida.\nAgregando os dados e transformando em série temporal.\nUsando os dados simplificados voosbr_ts.csv para trabalhar a série de passageiros em vôos no Brasil.\n\n\n[1] \"en_GB.UTF-8\"\n\n\nVizualizando a série.\n\n\n\n\n\n\n\n\n\n\nDecomposição clássica multiplicativa da série de passageiros.\n\n\n\n\n\nModelo via decomposição por STL.\nVisualizando a previsão para 2019 e 2020 juntamente com os dados.\n\n\n\n\n\nResíduos do modelo via decomposição por STL.\n\n\n\n\n\nMétricas de desempenho para os dois anos separados para teste.\n\n\n# A tibble: 1 × 4\n  .model    RMSE     MAE  MAPE\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 stlf   275652. 229005.  2.29"
  },
  {
    "objectID": "ST3.html#decomposição-via-stl",
    "href": "ST3.html#decomposição-via-stl",
    "title": "3  Decomposição de séries temporais",
    "section": "3.7 Decomposição via STL",
    "text": "3.7 Decomposição via STL\nA sigla STL significa Seasonal and Trend decomposition using Loess”* que em português seria decomposição de tendência e sazonalidade usando LOESS (Cleveland et al. 1990). LOESS significa locally estimated scatterplot smoothing, sendo um método de regressão não linear, que é cmumente chamado de regressão local.\nO método STL apresenta diversas vantagens em relação aos anteriores:\n\nTrata qualquer tipo de sazonalidade;\nA componente sazonal pode mudar com o tempo;\nA suavização da tendência pode ser controlada pelo usuário;\nPode ser robusto a outliers (há uma opção para tal), de forma que desvios não usuais não afetarão a tendência e ciclo, mas o resto.\n\nO método, entretanto, tem algumas limitações. As possibilidades elencadas são disponíveis apenas para decomposições aditivas. Para casos multiplicativos, recomenda-se transformar a série via logaritmo ou Box-Cox e depois fazer a decomposição aditiva.\nA Figura 3.15 expõe os gráficos da decomposição do logarítmo da série de passageiros em vôos do Brasil. A tendência é estimada usando uma janela definida para definir o intervalo do atraso para a janela da regressão local. Já a sazonalidade deve ter seu período definido, além da janela da suavização.\n\n\n\n\n\n\n\n\nFigura 3.15: Decomposição da série log(passageiros) em vôos no Brasil via STL",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#previsão-via-decomposição",
    "href": "ST3.html#previsão-via-decomposição",
    "title": "3  Decomposição de séries temporais",
    "section": "3.8 Previsão via decomposição",
    "text": "3.8 Previsão via decomposição\nA Figura Figura 3.16 apresenta a previsão via decomposição para o caso anterior. Foi considerado até o ano de 2018 para treinamento e pode-se observar a previsão para 2019 e 2020 junto com as observações disponíveis.\n\n\n\n\n\n\n\n\nFigura 3.16: Previsão via decomposição da série de log(passageiros) de vôos no Brasil\n\n\n\n\n\nA Figura 3.17 apresenta os resíduos obtidos da decomposição para o caso anterior. Observa-se que apresentam boa aderência à normal e sem presença de autocorrelação.\n\n\n\n\n\n\n\n\nFigura 3.17: Resíduos do modelo obtido via decomposição por STL da série de log(passageiros)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST3.html#exercícios-propostos",
    "href": "ST3.html#exercícios-propostos",
    "title": "3  Decomposição de séries temporais",
    "section": "3.10 Exercícios propostos",
    "text": "3.10 Exercícios propostos\n\nA seguir exibe-se o código para obtenção da série temporal mensal do volume em \\(m^3\\) de produção de asfalto no Brasil, um derivado do petróleo. A série aparenta apresentar um padrão de sazonalidade anual com variação não aditiva. Aplique a transformação de Box-Cox na série. Qual o valor ótimo do parâmetro \\(\\lambda\\)? Faça o gráfico da série transformada.\n\n\npetro &lt;- read.csv(\"petroleo_e_derivados.csv\", header=T)\npetro &lt;- petro |&gt; select(-c(gasolina_aviao,\n                            outros_energeticos))\n\npetro_ts &lt;- petro |&gt;\n  pivot_longer(cols = petroleo:solvente, \n               names_to = \"derivado\", values_to = \"volume\") |&gt;\n  mutate(data = as.Date(data, format=\"%m/%d/%Y\"))\n\npetro_ts &lt;- petro_ts |&gt; \n  as_tsibble(key = derivado, \n             index = data) |&gt;\n  mutate(data = yearmonth(data))\n\nasfalto &lt;- petro_ts |&gt;\n  filter(derivado == \"asfalto\") |&gt;\n  select(!derivado)\n\n\nUma vez que a série exibe um padrão de sazonalidade anual e tem frequência mensal, qual a ordem de média móvel seria adequada para estimar a tendência via método clássico?\nFaça um gráfico da série de produção de asfalto transformada com curva da tendência usando média móvel com a ordem adequada, segundo sua resposta na questão anterior.\n\n\nFaça a decomposição aditiva da série do índice de produção de bens de consumo duráveis usando o método clássico.\n\n\nFaça a decomposição clássica da série transformada de produção de asfalto usando o método clássico. Uma vez que a série foi transformada, você recomenda usar o método aditivo ou multiplicativo?\n\n\nEstime modelos via decomposição por STL da série de produção de asfalto. Porém, neste caso, considere a série sem transformação de Box-Cox, utilize apenas transformação logarítimica para o volume produzido. Teste modelos com janela de 5 e 11 para a tendência e janela de 11 e infinita (“periodic” ou Inf) para a sazonalidade. Faça um gráfico da série com as previsões obtidas com o modelo STL para os 32 meses disponíveis a partir de 2023 (h=32).\n\n\nCalcule as métricas de desempenho para o modelo avaliado nos meses separados para teste.\n\n\nAvalie os resíduos do melhor modelo.\n\n\n\n\n\nCleveland, Robert B, William S Cleveland, Jean E McRae, Irma Terpenning, et al. 1990. «STL: A seasonal-trend decomposition». J. off. Stat 6 (1): 3–73.\n\n\nMakridakis, Spyros, Steven C Wheelwright, e Rob J Hyndman. 2008. Forecasting methods and applications. John wiley & sons.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#implementação-em-r",
    "href": "ST4.html#implementação-em-r",
    "title": "4  Regressão de séries temporais",
    "section": "4.9 Implementação em R",
    "text": "4.9 Implementação em R\nA seguir são apresentadas boa parte das implementações na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo.\nCarregando pacotes.\nSéries temporais anuais de área plantada em hectare e grãos produzidos em toneladas. O pacote ipeadatar disponibiliza diversas séries econométricas via função ipeadata.\n\n# metadata(\"DEPAE_SAFRA\")\n# available_series()\n\n\ngraos_plan &lt;- ipeadata(\"DEPAE_SAFRAAREA\")\ngraos_prod &lt;- ipeadata(\"DEPAE_SAFRA\")\n\nTransformando as séries em tsibble.\n\ngraos  &lt;- tsibble(valor = c(graos_plan$value,\n                            graos_prod$value),\n                  data = yearmonth(c(graos_plan$date,\n                                     graos_prod$date)),\n                  id = c(rep(\"area_plantada\", nrow(graos_plan)),\n                         rep(\"producao\", nrow(graos_prod))),\n                  key=id, index=data)\n\nid.labs &lt;- c(\"área plantada [ha]\", \"produção [ton]\")\nnames(id.labs) &lt;- c(\"area_plantada\", \"producao\")\n\nVisualizando as séries.\n\ngraos |&gt; autoplot(valor) +\n  # geom_line(col = \"slategrey\") +\n  facet_wrap(nrow=2, ~ id, scales = \"free_y\",\n             labeller = labeller(id = id.labs)) + \n  guides(colour = \"none\") +\n  labs(y = \"\", x = \"\", title = \"Produção de grãos no Brasil\")\n\nDiagrama de dispersão e correlação entre as séries.\n\ndf_graos &lt;- graos |&gt;\n            pivot_wider(names_from=id,\n                        values_from=valor)\n\nggpairs(df_graos, columns = 2:3)\n\nModelo de regressão linear simples para produção em função da área plantada. Deve-se usar o comando TSLM. O modelo deve conter a série dependente e as indepndentes após ~. Neste caso há uma única série independente ou exógena, area_plantada. Porém, em casos onde há múltiplas séries exógenas, é importante usar + para separá-las.\n\nfit_graos &lt;- df_graos |&gt;\n  model(TSLM(producao ~ area_plantada))\n\nreport(fit_graos)\n\nSérie ajustada para produção de grãos a partir do modelo de regressão obtido.\n\naugment(fit_graos) |&gt;\n  ggplot(aes(x = data)) +\n  geom_line(aes(y = producao, colour = \"Data\")) +\n  geom_line(aes(y = .fitted, colour = \"Fitted\")) +\n  labs(y = \"Grãos [ton]\",\n    title = \"Produção de grãos\"\n  ) +\n  scale_colour_manual(values=c(Data=\"grey\",Fitted=\"slateblue\")) +\n  guides(colour = guide_legend(title = NULL))\n\nResíduos para o modelo de produção de grãos.\n\nfit_graos |&gt; gg_tsresiduals()\n\nSérie temporal de temperatura de São João del-Rei.\n\ntempo_sjdr &lt;- read.csv(\"sjdr2024.csv\",\n                       header=T)\ntempo_sjdr_ts &lt;- tempo_sjdr |&gt;\n  mutate(Data = as.POSIXct(paste(Data,Hora), \n                           format = \"%Y/%m/%d %H\")) |&gt;\n  select(!Hora) |&gt;\n  as_tsibble(index = Data)\n\n\ndata_inicial &lt;- as.POSIXct(\"2024-06-15 00:00:00\")\n\ndatas_especificas &lt;- seq(from = data_inicial, by = \"hour\", length.out = 14*24)\n\ntempo_sjdr_14_dias &lt;- tempo_sjdr_ts |&gt;\n  filter(Data %in% datas_especificas)\n\nModelo de regressão com termo de tendência e sazonalidade. São usados para tal os termos trend() e season(). O segundo cria as variáveis dummy necessárias para capturar a sazonalidade na regressão.\n\nfit_tempo &lt;- tempo_sjdr_14_dias |&gt;\n  model(TSLM(Temperatura ~ trend() + season()))\nreport(fit_tempo)\n\nSérie aproximada.\n\naugment(fit_tempo) |&gt;\n  ggplot(aes(x = Data)) +\n  geom_line(aes(y = Temperatura, colour = \"Data\")) +\n  geom_line(aes(y = .fitted, colour = \"Fitted\")) +\n  scale_colour_manual(\n    values = c(Data = \"black\", Fitted = \"orangered\")\n  ) +\n  guides(colour = guide_legend(title = \"Series\")) +\n  labs(x = \"\", y = \"Temp [°C]\",\n       title=\"Temperatura em São João del-Rei\")\n\nPrevisão do tempo.\n\nfc_tempo &lt;- forecast(fit_tempo)\n\nfc_tempo |&gt;\n  autoplot(tempo_sjdr_14_dias) +\n  labs(\n    title = \"Previsão do tempo para São João del-Rei\",\n    y = \"Temp [°C]\"\n  )\n\nSérie de produção de petróleo e derivados.\n\npetro &lt;- read.csv(\"petroleo_e_derivados.csv\", header=T)\npetro &lt;- petro |&gt; select(-c(gasolina_aviao,\n                            outros_energeticos)) |&gt;\n  pivot_longer(cols = petroleo:solvente, names_to = \"derivado\", values_to = \"volume\")\n\n\npetro_ts &lt;- petro |&gt;\n  mutate(data = yearmonth(as.Date(data, format=\"%m/%d/%Y\"))) |&gt; \n  as_tsibble(key = derivado, \n             index = data)\n\n\npetro_ &lt;- petro_ts |&gt;\n  pivot_wider(names_from=derivado,\n              values_from=volume)\n\n\npetro_ts |&gt; autoplot(volume) +\n  facet_wrap(nrow=14, ~ derivado, scales = \"free_y\") +\n  guides(colour = \"none\")\n\nCorrelação entre as séries. Usa-se o comando corrplot do pacote homônimo.\n\nR &lt;- cor(petro_[,2:15])\ncorrplot(R, method = 'color', order = 'hclust', type = 'upper')\n\nModelo de regressão múltipla da série de produção de petróleo em função dos derivados.\n\nfit_petro &lt;- petro_ |&gt; \n  model(TSLM(petroleo ~ .-petroleo-data))\n  report(fit_petro)\n\nSérie temporal de emissões de gases de efeito estufa por produção de energia no Brasil.\n\nemissoes &lt;- read.csv(\"emissoes.csv\", header = T)\n\nemissoes_ts &lt;- emissoes |&gt;\n  mutate(Ano = year(as.Date(paste(Ano,\"01 01\"), format = \"%Y %m %d\"))) |&gt;\n  as_tsibble(index = Ano)\n\nModelos com tendência linear, exponencial e de regressão por partes. Para o último deve-se definir os knots ou divisões e provê-los como argumento em trend.\n\nknots &lt;- year(as.Date(c(\"2005-01-01\", \"2014-01-01\"), format=\"%Y-%m-%d\"))\n\nfit_trends &lt;- emissoes_ts |&gt;\n  filter_index(~\"2017\") |&gt;\n  model(\n    linear = TSLM(Energia ~ trend()),\n    exponencial = TSLM(log(Energia) ~ trend()),\n    `linear por partes` = TSLM(Energia ~ trend(knots = knots))\n  )\nfc_trends &lt;- fit_trends |&gt; forecast(h = 5)\n\nVisualizando a série com as previsões.\n\nemissoes_ts |&gt;\n  autoplot(Energia) +\n  geom_line(data = fitted(fit_trends),\n            aes(y = .fitted, colour = .model)) +\n  autolayer(fc_trends, alpha = 0.5, level = NULL) + labs(x=\"Ano\", y=\"Gg de CO2e\", title=\"Emissões de gases de efeito estufa na produção de energia no Brasil\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html#exercícios-propostos",
    "href": "ST4.html#exercícios-propostos",
    "title": "4  Regressão de séries temporais",
    "section": "4.10 Exercícios propostos",
    "text": "4.10 Exercícios propostos\nO código à seguir é utilizado para obter as séries de fertilizantes apresentadas neste capítulo.\n\nfert_venda &lt;- ipeadata(\"ANDA12_VFERTILIZ12\")\nfert_prod &lt;- ipeadata(\"ANDA12_PFERTILIZ12\")\nfert_exp &lt;- ipeadata(\"ANDA12_NPKFERTILIZ12\")\nfert_imp &lt;- ipeadata(\"ANDA12_MFERTILIZ12\")\n\n\nfert  &lt;- tsibble(valor = c(fert_venda$value,\n                           fert_prod$value,\n                           fert_exp$value,\n                           fert_imp$value\n                           ),\n                  data = yearmonth(c(fert_venda$date,\n                                     fert_prod$date,\n                                     fert_exp$date,\n                                     fert_imp$date\n                                     )),\n                  id = c(rep(\"vendas\", nrow(fert_venda)),\n                         rep(\"producao\", nrow(fert_prod)),\n                         rep(\"exportacao\", nrow(fert_exp)),\n                         rep(\"importacao\", nrow(fert_imp))),\n                  key=id, index=data)\n\nid.labs &lt;- c(\"Vendas\", \"Produção\", \"Exportação\", \"Importação\")\nnames(id.labs) &lt;- c(\"vendas\", \"producao\", \"exportacao\", \"importacao\")\n\n\nObtenha um modelo para prever o volume de vendas de fertilizantes em função dos volumes de produção, importação e exportação a partir de 2013 até o fim de 2023. Use filter_index(~ \"2023-12\") para definir o horizonte de tempo. Use o modelo vendas ~ producao + importacao + exportacao em TSLM. Interprete o modelo obtido.\n\n\nSe algum termo não for significativo, refaça o modelo desconsiderando-o e compare os modelos obtidos.\n\n\nObtenha um modelo para a venda de fertilizantes em função apenas da tendência e sazonalidade da própria série.\n\nO código a seguir obtém \\(R^2_{aj}\\), AIC e AICc dos modelos (adapte os nomes dos três modelos, segundo seu código).\n\nfit1 &lt;- glance(fit_fert) |&gt;\n  select(adj_r_squared, AIC, AICc)\nfit2 &lt;- glance(fit_fert2) |&gt;\n  select(adj_r_squared, AIC, AICc)\nfit3 &lt;- glance(fit_fert3) |&gt;\n  select(adj_r_squared, AIC, AICc)\n\nbind_rows(fit1,fit2,fit3) |&gt;\n    mutate(model = c(\"completo\", \"reduzido\", \"tredn+season\")) |&gt;\n  relocate(model)\n\n\nFaça a análise de resíduos para o melhor modelo obtido.\n\n\nCompare a capacidade de previsão dos modelos considerando dados de janeiro de 2024 até maio de 2025 como dados de teste. Use o argumento new_data em forecast e forneça a série de 17 observações para os modelos que dependem das variáveis exógenas. Para o último modelo forneça apenas h=17.\n\n\nFaça um modelo de regressão para a série de produção de bens de consumo duráveis em função da série de bens de capital e da série de bens intermediários. Interprete o modelo obtido.\n\n\nFaça a análise dos resíduos para o modelo obtido no exercício anterior. Interprete os resultados.\n\n\nObtenha os valores ajustados e visualize-os junto à série de bens de consumo duráveis.\n\nA seguir expõe-se o código para realizar a previsão baseada em cenários para o modelo de regressão para produção de grãos em função da área plantada. Foram considerados dois cenários: um de aumento na área plantada nos dois próximos anos com 82000 e 85000 hectares plantados; outro de queda na área plantada nos dois próximos anos com 75000 e 72000 hectares.\n\nfuture_scenarios &lt;- scenarios(\n  Aumento = new_data(df_graos, 2) |&gt;\n    mutate(area_plantada = c(82000,85000)),\n  Queda = new_data(df_graos, 2) |&gt;\n    mutate(area_plantada = c(75000, 72000)),\n  names_to = \"Cenários\")\n\n\nfc &lt;- forecast(fit_graos, new_data = future_scenarios)\n\ndf_graos |&gt;\n  autoplot(producao) +\n  autolayer(fc, level = 95) +\n  labs(title = \"Previsão de cenários para produção de grãos\", y = \"\")\n\n\nFaça uma previsão de cenários usando o modelo de regressão para a série de produção de bens de consumo duráveis. Considere três meses à frente e um cenários de queda e outro de aumento nos índices de produção de bens de capital e da série de bens intermediários. A seguir expõe-se como seria implementado um cenário para este caso de regressão múltipla.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST1.html",
    "href": "ST1.html",
    "title": "1  Introdução e gráficos",
    "section": "",
    "text": "1.1 Introdução às séries temporais e previsão\nUma série temporal consiste em um conjunto de observações de uma variável aleatória ordenadas no tempo. Uma série temporal pode ser descrita matematicamente como \\(y_1, ..., y_T\\), onde \\(T\\) consiste no último período da série. A análise de séries temporais visa o estudo e obtenção de modelos preditivos para este tipo de dados. O objetivo ao final é realizar previsões com o modelo obtido, de forma a viabilizar ações de planejamento, prever cenários e possibilidades.\nA previsão é importante em diversos contextos das engenharias, administração e ciências. Por exemplo, para decidir o nível de produção e planejar o próximo período é necessário prever a demanda. Para avaliar se um investimento é viável é importante prever a sua rentabilidade. Para planejamento dos sistemas energéticos é importante prever o consumo de energia. Para prever a capacidade de produção de energia hidroelétrica é preciso prever a precipitação.\nNeste curso serão apresentados diversos modelos para análise e previsão de séries temporais, sendo boa parte dos exemplos obtidos de casos brasileiros. Serão consideradas séries de dados de produção, indústria, agricultura, clima, energia, economia, investimentos, mobilidade, transporte, saúde, entre outros.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução e gráficos</span>"
    ]
  },
  {
    "objectID": "ST2.html",
    "href": "ST2.html",
    "title": "2  Análise descritiva, métodos simples de previsão e diagnóstico",
    "section": "",
    "text": "2.1 Estatísticas descritivas\nAnteriormente à realização da modelagem de séries temporais é importante observar agumas estatísticas simples da série de interesse, de forma a compreender a magnitude da série, tendência central, dispersão e distribuição das observações da série.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análise descritiva, métodos simples de previsão e diagnóstico</span>"
    ]
  },
  {
    "objectID": "ST3.html",
    "href": "ST3.html",
    "title": "3  Decomposição de séries temporais",
    "section": "",
    "text": "3.1 Decomposição\nAs séries temporais exibem comportamentos variados. Quando uma série temporal apresenta um padrão subjacente, este padrão pode ser separado da aleatoriedade, viabilizando sua projeção para períodos futuros. Em muitos casos pode ser interessantes ainda decompor a série temporal em componentes. A decomposição pode facilitar a análise e previsão. Geralmente considera-se a tendência, sazonalidade e o resto ou resíduos na decomposição, havendo vários métodos para separar tais componentes. Antes, porém, são importantes algumas considerações sobre tratamentos iniciais às vezes necessários.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decomposição de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST4.html",
    "href": "ST4.html",
    "title": "4  Regressão de séries temporais",
    "section": "",
    "text": "4.1 Regressão linear simples\nA regressão de séries temporais visa modelar uma série de interesse, dita dependente, em função de outra ou mais séries, referidas como independentes, às quais são supostamente relacionadas. Os métodos mais tradicionais consideram a dependência temporal da própria série para modelagem e previsão. Entretanto, em situações onde há séries relacionadas disponíveis a regressão pode ser útil. Ademais, há possibilidade de combinar a regressão com modelos autoregressivos integrados de m[edias móveis, conforme será abordado no capítulo 7.\nSeja um problema onde deseja-se prever uma série temporal contínua, \\(y_1, y_2, ..., y_T\\), em função de outra, \\(x_1, x_2, ..., x_T\\).\nNa Figura 7.6 são plotadas as séries temporais anuais de área plantada em hectare e grãos produzidos em toneladas no Brasil de 1977 a 2022, Ipeadata. As séries apresentam tendência de crescimento não linear com algumas flutuações.\nFigura 4.1: Produção de grãos no Brasil\nAo plotar um diagrama de dispersão entre as séries, pode-se observar uma correlação linear positiva alta entre estas, conforme Figura 4.2.\nFigura 4.2: Área plantada versus Produção de grãos\nConforme observado na Figura 4.3, pode-se considerar neste caso e em diversos outros a aproximação de uma função linear para tal relação.\nFigura 4.3: Modelo de regressão linear simples para produção de grãos em função da área plantada\nO modelo linear plotado em azul pode ser descrito conforme a Equação 4.1, onde \\(\\beta_0\\) é uma constante e \\(\\beta_1\\) é um coeficiente linear.\n\\[\n\\hat{y}_t = \\beta_0+\\beta_{1}x_t\n\\tag{4.1}\\]\nAs observações da série dependente ou resposta, \\(y_t\\), podem ser descritas conforme Equação 4.2, como sendo o valor estimado, \\(\\hat y_t\\), adicionado de um termo de erro ou resíduo, \\(\\varepsilon_t\\).\n\\[\n\\begin{aligned}\ny_t = \\hat{y}_t + \\varepsilon_t \\\\\ny_t = \\beta_0 + \\beta_1x_t + \\varepsilon_t \\\\\n\\end{aligned}\n\\tag{4.2}\\]\nConsiderando as \\(T\\) observações disponíveis das séries, \\((x_1, y_1), (x_2, y_2), ..., (x_T, y_T)\\), pode-se pensar em um modelo que minimize os erros de previsão. Uma vez que o erro é normalmente distribuído, com média nula e variância \\(\\sigma_\\varepsilon^2\\), \\(\\varepsilon \\sim N(0,\\sigma_\\varepsilon^2)\\), pode-se trabalhar a minimização da soma dos quadrados dos erros de previsão, \\(\\sum_{t=1}^{T}\\varepsilon_t^2\\). A Figura Figura 4.4 plota em linhas vermelhas verticais os resíduos. O modelo plotado minimiza a soma dos quadrados dos erros.\nFigura 4.4: Erros de previsão para o modelo de regressão linear para produção de grãos em função da área plantada\nA análise à seguir expõe os coeficientes do modelo estimado com teste t para significância destes. Neste curso não será dada ênfase na inferência, mas na previsão. De forma simples um valor t com alta magnitude ou um p-valor (Pr(&gt;|t|)) baixo indica risco baixo de rejeitar a hipótese nula de ausência de efeito da variável ou série independente (\\(x_t\\)).\nSeries: producao \nModel: TSLM \n\nResiduals:\n   Min     1Q Median     3Q    Max \n-40729 -18733   1072  18188  35065 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -1,726e+05  1,248e+04  -13,84   &lt;2e-16 ***\narea_plantada  6,285e+00  2,561e-01   24,54   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 ' ' 1\n\nResidual standard error: 21080 on 46 degrees of freedom\nMultiple R-squared: 0,929,  Adjusted R-squared: 0,9275\nF-statistic: 602,2 on 1 and 46 DF, p-value: &lt; 2,22e-16\nO modelo para prever a produção de grãos, \\(y_t\\), em função da área plantada, \\(x_t\\), fica:\n\\[\n\\hat{y}_t = -1,726 \\times 10^{5} + 6,285x_t\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressão de séries temporais</span>"
    ]
  },
  {
    "objectID": "ST5.html",
    "href": "ST5.html",
    "title": "5  Suavização exponencial",
    "section": "",
    "text": "5.1 Suavização exponencial simples\nA suavização exponencial consiste em uma média ponderada das observações anteriores, com peso decaindo exponencialmente à medida que as observações ficam mais distantes no tempo.\nA previsão para a suavização exponencial simples pode ser denotada conforme Equação 5.1\n\\[\n\\hat y_{T+1|T} = \\alpha y_T + \\alpha(1-\\alpha)y_{T-1} + \\alpha(1-\\alpha)^2y_{T-2}+...\n\\tag{5.1}\\]\nonde \\(0&lt; \\alpha &lt;1\\) consiste no parâmetro de suavização. A previsão um passo à frente consiste em uma média ponderada das observações anteriores, \\(y_1,...,y_T\\), com taxa de decrescimento dos pesos controlada pelo parâmetro \\(\\alpha\\). A Tabela 5.1 expõe os pesos para as cinco últimas observações para distintos valores de \\(\\alpha\\). Observa-se que a soma dos pesos é próxima de 1.\nA Figura 5.1 expõe os mesmos pesos plotados segundo o tempo. Observa-se que quanto maior o \\(\\alpha\\), maior a taxa de decrescimento dos pesos da última observação em relação às anteriores.\nFigura 5.1: Pesos na suavização exponencial simples\nO modelo exposto para prever a observação futura pode ser descrito sempre considerando a última observação e a previsão desta, conforme Equação 5.2.\n\\[\n\\hat y_{T+1|T} = \\alpha y_T +(1-\\alpha)\\hat y_{T|T-1}\n\\tag{5.2}\\]\nDe forma similar, os valores ajustados para a série ficam conforme Equação 5.3.\n\\[\n\\hat y_{t+1|t} = \\alpha y_t +(1-\\alpha)\\hat y_{t|t-1},\n\\tag{5.3}\\]\npara \\(t=1,...,T\\).\nSeja \\(l_0\\) o valor estimado para a primeira observação, \\(t=1\\), então:\n\\[\n\\begin{align}\n\\hat y_{2|1} &= \\alpha y_1 +(1-\\alpha) l_0 \\\\\n\\hat y_{3|2} &= \\alpha y_2 +(1-\\alpha) \\hat y_{2|1} \\\\\n\\hat y_{4|3} &= \\alpha y_3 +(1-\\alpha) \\hat y_{3|2} \\\\\n\\vdots \\\\\n\\hat y_{T|T-1} &= \\alpha y_{T-1} +(1-\\alpha) \\hat y_{T-1|T-2} \\\\\n\\hat y_{T+1|T} &= \\alpha y_{T} +(1-\\alpha) \\hat y_{T|T-1} \\\\\n\\end{align}\n\\]\nObserve que cada equação pode ser substituída na posterior, conforme Equação 5.4.\n\\[\n\\begin{align}\n\\hat y_{3|2} &= \\alpha y_2 +(1-\\alpha) [\\alpha y_1 +(1-\\alpha) l_0] \\\\\n&= \\alpha y_2 + \\alpha(1-\\alpha)y_1 +(1-\\alpha)^2 l_0\\\\\n\\hat y_{4|3} &= \\alpha y_3 +(1-\\alpha)[\\alpha y_2 + \\alpha(1-\\alpha y_1 +(1-\\alpha)^2 l_0] \\\\\n&= \\alpha y_3 +\\alpha(1-\\alpha) y_2 +\\alpha(1-\\alpha)^2 y_1 +(1-\\alpha)^3 l_0 \\\\\n\\vdots \\\\\n\\hat y_{T+1|T} &= \\sum_{j=0}^{T-1} \\alpha (1-\\alpha)^j y_{T-j}+ (1-\\alpha)^T l_0 \\\\\n\\end{align}\n\\tag{5.4}\\]\nComo o último termo fica muito pequeno para \\(T\\) grande, então a equação fica conforme o modelo apresentado inicialmente.\nA representação em componentes também é comum para a suavização exponencial, sendo o caso simples expresso na Equação 5.5.\n\\[\n\\begin{align}\n\\text{Equação de previsão:    } \\hat y_{t+h} &= l_t\\\\\n\\text{Equação de suavização:    } l_t &= \\alpha y_t + (1-\\alpha)l_{t-1},\\\\\n\\end{align}\n\\tag{5.5}\\]\nonde \\(l_t\\) consiste no nível no período \\(t\\) e \\(\\hat y_{t+h} = l_t\\) a previsão no período \\(t+h\\).\nSe \\(h=0\\), tem-se o valor ajustado para \\(y_t\\), enquanto se \\(t=T\\) e \\(h \\geq1\\), tem-se a previsão para além dos dados observados ou disponíveis para treino ou estimativa da série. Fazendo \\(l_t = \\hat y_{t+1|t}\\) e \\(l_{t-1} = \\hat y_{t|t-1}\\), tem-se o modelo ponderado já exposto. Tal representação não é tão útil para o caso simples, porém, quando considerados termos de tendência e suavização, será. O modelo simples, até aqui explicitado é recomendado para casos sem tendência e sazonalidade.\nA Figura 5.2 expõe o resultado da suavização exponencial simples para a série do IPCA no Brasil a partir de 2019. Os parâmetros estimados, \\(\\alpha\\) e \\(l_0\\), expostos na Tabela 5.2 foram estimados minimizando a soma dos quadrados dos erros para as estimativas um passo à frente.\nTabela 5.2: Parâmetros de suavização exponencial simples para a série do IPCA no Brasil a partir de 2019\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\nalpha\n0,5722074\n\n\nl[0]\n0,3963222\nFigura 5.2: Previsão e valores ajustados para o IPCA via suavização exponencial simples\nA Tabela 5.3 apresenta os valores ajustados \\(\\hat y_t\\) para as últimas observações da série.\nTabela 5.3: Pesos na suavização exponencial simples\n\n\n\n\n\n\nData\nVariação\ny_hat\n\n\n\n\n2025 fev\n1,31\n0,30\n\n\n2025 mar\n0,56\n0,88\n\n\n2025 abr\n0,43\n0,70\n\n\n2025 mai\n0,26\n0,54\n\n\n2025 jun\n0,24\n0,38\n\n\n2025 jul\n0,26\n0,30",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST6.html",
    "href": "ST6.html",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "",
    "text": "6.1 Estacionariedade em séries temporais\nAs séries temporais estacionárias são aquelas que não apresentam tendência ou sazonalidade, de forma que suas propriedades estatísticas permaneçam constantes ao longo do tempo. Séries estacionárias variam com média e variância constantes. Apesar de muitas séries temporais não serem estacionárias, não é difícil torná-las estacionárias. Um ruído branco é um exemplo de série estacionária. Algumas séries cíclicas podem ser estacionárias, caso os picos e vales não sejam previsíveis devido a variabilidade na dimensão do ciclo.\nA Figura 6.1 expõe exemplos de séries temporais estacionárias. À esquerda observa-se um ruído branco e à direita a série de variação na ação PETR3 para pouco mais de 10 meses de 2024.\nFigura 6.1: Exemplos de séries temporais estacionárias",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST7.html",
    "href": "ST7.html",
    "title": "7  Regressão dinâmica",
    "section": "",
    "text": "7.1 Regressão dinâmica\nOs modelos de regressão dinâmica possibilitam a inclusão de variáveis ou séries temporais regressoras, além de considerar o próprio padrão dinâmico da série via ARIMA, unindo as capacidades dos métodos expostos nos capítulos 4 e 6. Um modelo de regressão dinâmica pode ser expresso conforme segue, onde \\(\\varepsilon_t\\) é ruído branco. Ou seja, o modelo permite que os resíduos do modelo de regressão, agora denominados \\(\\eta_t\\) sejam autocorrelacionados, de forma que a autocorrelação seja tratada por um modelo ARIMA.\nUm modelo de regressão dinâmica pode ser representado conforme segue. Pode-se observar que o modelo de regressão contempla de uma até \\(k\\) séries temporais regressoras, \\(x_{t1}, \\ldots, x_{tk}\\), com erro \\(\\eta_t\\), o qual pode ser autocorrelacionado. A informação não tratada pelo modelo de regressão, \\(\\eta_t\\), é tratada via ARIMA.\n\\[\n\\begin{matrix}\ny_t = \\beta_0 + \\beta_1x_{t1} + \\cdots + \\beta_kx_{tk} + \\eta_t, \\\\\n(1-\\phi_1B- \\ldots - \\phi_pB^p)(1-B)^d\\eta_t = c+( 1+\\theta_1B+\\ldots+\\theta_qB^q)\\varepsilon_t\n\\end{matrix}\n\\]\nOs coeficientes de regressão, \\(\\beta_0, \\ldots, \\beta_k\\), e do modelo ARIMA, \\(\\phi_1B, \\ldots, \\phi_p, \\theta_1, \\ldots, \\theta_q\\) são estimados em conjunto minimizando \\(\\varepsilon_t\\) . A estimativa isolada dos coeficientes de regressão minimizando \\(\\eta_t\\) acarretaria diversos problemas no modelo. É importante também que a série a ser predita e as regressoras sejam estacionárias, de forma que o grau de diferenciação \\(d\\) necessário para se obter a estacionariedade seja aplicado.\nA Figura 7.1 plota séries temporais com frequência diária de consumo médio de eletricidade advinda de geração hidráulica no subsistema do sudeste e centro oeste do Brasil e de temperatura média diária da cidade de Uberlândia em Minas Gerais. Tal cidade foi considerada por ser uma que representa melhor a temperatura média de ambas as regiões dentre as monitoras pelo INMET. Pode-se sugerir um modelo de regressão dinâmica para o consumo diário de energia em função da temperatura média diária, descrevendo os erros com um modelo ARIMA.\nFigura 7.1: Consumo de energia elétrica e temperatura no sudeste e centro oeste do Brasil\nA seguir expõe-se o resultado obtido.\nSeries: hidraulica \nModel: LM w/ ARIMA(3,0,1)(1,1,1)[7] errors \n\nCoefficients:\n         ar1      ar2     ar3      ma1     sar1     sma1  temperatura\n      1.7559  -0.9554  0.1928  -0.8358  -0.0487  -0.9290      62.7853\ns.e.  0.1008   0.1102  0.0590   0.0929   0.0704   0.0537      60.2675\n\nsigma^2 estimated as 2229014:  log likelihood=-3005.54\nAIC=6027.08   AICc=6027.51   BIC=6057.8\nO modelo obtido pode ser expresso conforme segue.\n\\[\n\\begin{align}\ny_t &= 62.7853x_t + \\eta_t\\\\\n(1-1,76B+0.96B^2-0.19B^3)(1+0.0487B^{7})\\eta_t &= (1+0.8358B)( 1+0.9290B^{7})\\varepsilon_t\n\\end{align}\n\\]\nOs resíduos do modelo ARIMA, \\(\\varepsilon_t\\) devem apresentar padrão de ruído branco. Já os de regressão, \\(\\eta_t\\), não apresentam pressuposição. A Figura 7.2 apresenta os gráficos de resíduos para \\(\\eta_t\\). Observa-se autocorrelação e padrão de sazonalidade semanal.\nFigura 7.2: Gráficos de resíduos para regressão\nA Figura 7.3 apresenta os gráficos de resíduos para \\(\\varepsilon_t\\). Observa-se independência no tempo e boa aproximação com a normal.\nFigura 7.3: Gráficos de resíduos para o erro ARIMA\nA Tabela 7.1 expõe o resultado do teste de Ljung-Box. O teste deve considerar 6 graus de liberdade, uma vez que o modelo ARIMA apresenta seis coeficientes. O teste confirma ausência de autocorrelação residual.\nTabela 7.1: Teste Ljung-Box para o modelo de regressão dinâmica para o consumo de energia hidráulica\n\n\n\n\n\n\n.model\nlb_stat\nlb_pvalue\n\n\n\n\nARIMA(hidraulica ~ temperatura)\n9.402437\n0.3094918\nA Figura 7.4 expõe a série ajustada para o consumo de energia hidráulica. Observa-se boa aproximação com a série original.\nFigura 7.4: Série ajustada para o consumo de energia hidráulica\nA Figura 7.5 expõe a previsão para as duas últimas semanas do ano para o consumo de energia hidráulica.\nFigura 7.5: Previsão para o consumo de energia hidráulica\nUm outro exemplo adequado à regressão dinâmica seria o de previsão de produção de grãos considerando a área plantada como série regressora. Conforme, visto no capítulo 4, ao se considerar tal caso a regressão apenas não foi suficiente, uma vez que os resíduos apresentavam autocorrelação positiva e significativa até a defasagem de 4 unidades de tempo. A Figura 7.6 plota novamente as séries em questão.\nFigura 7.6: Produção de grãos no Brasil\nA seguir expõe-se o resultado da modelagem de regressão dinâmica obtido para prever a produção de grãos.\nSeries: producao \nModel: LM w/ ARIMA(1,1,0) errors \n\nCoefficients:\n          ar1  area_plantada  intercept\n      -0.5777         2.3417  3330.9042\ns.e.   0.1248         0.6146   967.0258\n\nsigma^2 estimated as 87293212:  log likelihood=-442.22\nAIC=892.45   AICc=893.53   BIC=899.4\n\\[\ny_t = 4780.28 + 0.65 x_t + \\eta_t \\\\\n(1 + 0.4952B)(1 - B)\\eta_t = \\varepsilon_t\n\\]\nOu sem usar o operador de defasagem:\n\\[\n\\begin{align}\ny'_t &= 4780.28 + 0.65 x'_t + \\eta'_t \\\\\n\\eta'_t &= -0.4952 \\eta'_{t-1} + \\varepsilon_t\\end{align}\n\\]\nA Figura 7.7 plota os resíduos obtidos para o modelo de regressão dinâmica para produção de grãos no Brasil. Os resíduos do modelo autoregressivo devem atender às pressuposições.\nFigura 7.7: Resíduos para o modelo de regressão dinâmica para produção de grãos no Brasil\nA Figura 7.8 expõe os gráficos dos resíduos do modelo autoregressivo do erro do modelo de regressão para produção de de grãos em função da área plantada. Pode-se observar a ausência de autocorrelação e boa aproximação com a distribuição normal.\nFigura 7.8: Resíduos do modelo autoregressivo do erro do modelo de regressão para produção de grãos em função da área plantada\nO teste de Ljung-Box, aprensentado na Tabela 7.2, confirma a ausência de autocorrelação residual.\nTabela 7.2: Teste Ljung-Box para o modelo de regressão dinâmica para produção de grãos\n\n\n\n\n\n\n.model\nlb_stat\nlb_pvalue\n\n\n\n\nARIMA(producao ~ area_plantada)\n7.915622\n0.5426714\nA Figura 7.9 plota os valores ajustados do modelo de regressão dinâmica para produção de grãos em função da área plantada. É interessante comparar tal modelo com o obtido no capítulo 4 onde apenas se considerava um modelo de regressão de séries temporais.\nFigura 7.9: Valores ajustados do modelo de regressão dinâmica para produção de grãos em função da área plantada\nA Figura 7.10 plota a previsão de 2020 a 2023 para o modelo de regressão dinâmica em discussão. É importante alimentar o modelo não somente com o tempo desejado à frente, mas também com dados da variável regressora. Neste caso, foram separados dados dos últimos 4 anos disponíveis para tal. Observa-se que para os dois últimos anos a quantidade produzida superou a quantidade prevista pelo modelo, mesmo com a queda em 2023.\nFigura 7.10: Valores ajustados do modelo de regressão dinâmica para produção de grãos em função da área plantada",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regressão dinâmica</span>"
    ]
  },
  {
    "objectID": "ST7.html#regressão-dinâmica-harmônica",
    "href": "ST7.html#regressão-dinâmica-harmônica",
    "title": "7  Regressão dinâmica",
    "section": "7.2 Regressão dinâmica harmônica",
    "text": "7.2 Regressão dinâmica harmônica\nUma possibilidade para casos com frequência horária ou menor, a regressão dinâmica harmônica considera termos estimados via série de Fourier. Modelos ARIMA e ETS tradicionais foram concebidos para considerar um número limitado de estações ou períodos sazonais, por exemplo, \\(m=12\\) para séries anuais e \\(m=4\\) para trimestrais. A regressão dinâmica harmônica é viável para séries longas, podendo aproximar séries que incluam simultaneamente sazonalidade de frequências dinstintas.\nOs dados de demanda de eletricidade do sudeste e centro oeste do Brasil anteriormente considerados na regressão dinâmica em função da temperatura foram considerados em frequência diária, sendo tomada a média do consumo em função da temperatura média. É possível trabalhar a mesma série disponível em frequência horária usando regressão dinâmica com termos de Fourier.\nA Figura 7.11 expõe a série temporal de geração de energia hidráulica para o sudeste e centro oeste do Brasil no ano de 2023 com frequência horária. Tal série apresenta 8760 observações.\n\n\n\n\n\n\n\n\nFigura 7.11: Série temporal com frequência horária de geração de energia hidráulica para o sudeste e centro oeste no ano de 2023\n\n\n\n\n\nA Tabela 7.3 expõe os resultados de ajuste de seis modelos de regressão dinâmica harmônica para a série de demanda de eletricidade do sudeste e centro oeste do Brasil considerando de 1 a 6 termos de Fourier. Observa-se que a adição de mais termos melhora o ajuste do modelo.\n\n\n\n\nTabela 7.3: Modelos de regressão dinâmica harmônica para a série de geração de eletricidade hidráulica no sudeste e centro oeste\n\n\n\n\n\n\n.model\nsigma2\nlog_lik\nAIC\nAICc\nBIC\n\n\n\n\nK = 1\n0.0008775\n14470.13\n-28922.26\n-28922.24\n-28860.73\n\n\nK = 2\n0.0007887\n14836.38\n-29660.77\n-29660.76\n-29619.74\n\n\nK = 3\n0.0007882\n14839.71\n-29663.41\n-29663.39\n-29608.71\n\n\nK = 4\n0.0007642\n14949.39\n-29870.79\n-29870.73\n-29775.06\n\n\nK = 5\n0.0007641\n14950.75\n-29869.50\n-29869.42\n-29760.10\n\n\nK = 6\n0.0006942\n15282.75\n-30527.50\n-30527.39\n-30397.59\n\n\n\n\n\n\n\n\nA Figura 7.12 plota a previsão uma semana a frente para os modelos obtidos. Os dados foram plotados de Setembro em diante para facilitar a visualização.\n\n\n\n\n\n\n\n\nFigura 7.12: Previsão uma semana a frente para os modelos de regressão dinâmica harmônica para a série de consumo de eletricidade no sudeste e centro oeste\n\n\n\n\n\nA Tabela 7.4 plota o desempenho obtido para a previsão uma semana a frente considerando os modelos de regressão dinâmica harmônica. Observa-se que o modelo com “K = 3” termos apresentou melhor resultado.\n\n\n\n\nTabela 7.4: Desempenho dos modelos de regressão dinâmica harmônica para a série de consumo de eletricidade no sudeste e centro oeste\n\n\n\n\n\n\n.model\nRMSE\nMAE\nMAPE\n\n\n\n\nK = 1\n5942.818\n4771.082\n16.62897\n\n\nK = 2\n5271.837\n4197.735\n14.80960\n\n\nK = 3\n5254.738\n4185.858\n14.78036\n\n\nK = 4\n5394.069\n4321.885\n15.21199\n\n\nK = 5\n5384.912\n4313.968\n15.18825\n\n\nK = 6\n5345.797\n4310.099\n15.25338",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regressão dinâmica</span>"
    ]
  },
  {
    "objectID": "ST5.html#implementação-em-r",
    "href": "ST5.html#implementação-em-r",
    "title": "5  Suavização exponencial",
    "section": "5.6 Implementação em R",
    "text": "5.6 Implementação em R\nA seguir são apresentadas boa parte das implementações na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo.\nCarregando pacotes.\n\nlibrary(ggplot2)\nlibrary(tsibble)\nlibrary(fable)\nlibrary(fabletools)\nlibrary(forecast)\nlibrary(feasts)\nlibrary(lubridate)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(knitr)\nlibrary(ipeadatar)\ntheme_set(theme_bw())\n\nSérie do IPCA a partir de 2019. Esta série já foi apresentada no primeiro capítulo.\n\nipca_2019_ &lt;- ipca_ts |&gt; \n  filter_index(\"2019-01\"~.)\n\nModelo de suavização exponencial simples para a série do IPCA. Usa-se a função ETS e deve-se definir os tipos de termos de erro, tendência e sazonalidade com error, trend e season.\n\nfit_ipca &lt;- ipca_2019_  |&gt;\n  model(ETS(ipca ~ error(\"A\") + trend(\"N\") + season(\"N\")))\n\ntidy(fit_ipca)[,-1]\n\nPrevisão 5 meses à frente.\n\nfc_ipca &lt;- fit_ipca |&gt;\n  forecast(h = 5)\nfc_ipca\n\nPlotando a série com os valores ajustados e a previsão.\n\nfc_ipca |&gt; \n  autoplot(ipca_2019_) +\n  geom_line(aes(y = .fitted), col=\"orangered\",\n            data = augment(fit_ipca)) +\n  labs(y = \"IPCA\", x = \"\", \n        title=\"IPCA no Brasil a partir de 2019\") +\n  guides(colour = \"none\")\n\nValores ajustados e observados para os últimos meses da série.\n\naugment(fit_ipca) |&gt; \n  tail()\n\nPopulação projetada no Brasil.\n\npop_br &lt;- read.csv(\"populacao_br.csv\", header=T)\npop_br &lt;- pop_br |&gt; filter(ano&lt;=2010)\n\npop_ts &lt;- pop_br |&gt;\n  mutate(data = year(as.Date(as.character(ano),format=\"%Y\"))) |&gt;\n  select(-ano) |&gt;\n  as_tsibble(index=data)\n\n\npop_ts |&gt; autoplot(pop) +\n  labs(title = \"População projetada do Brasil\",\n       y = \"Pessoas\", x=\"\")\n\nModelo de suavização exponencial com tendência (método de Holt).\n\nfit &lt;- pop_ts |&gt;\n  model(\n    `Holt` = ETS(pop ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n    `Holt amortecido` = ETS(pop ~ error(\"A\") +\n                       trend(\"Ad\", phi = 0.9) + season(\"N\"))\n  )\n\ntidy(fit)\n\nPrevisão com modelos de Holt e Holt amortecido.\n\nfc_pop &lt;- fit |&gt;\n  forecast(h = 15) \n\nfc_pop |&gt;\n  autoplot(pop_ts, level = NULL) +\n  labs(title = \"População do Brasil\",\n       y = \"Milhões\",x=\"\") +\n  guides(colour = guide_legend(title = \"Forecast\"))\n\nSérie de emissões de CO2.\n\nemissoes &lt;- read.csv(\"emissoes.csv\", header = T)\n\nemissoes_ts &lt;- emissoes |&gt;\n  mutate(Ano = year(as.Date(paste(Ano,\"01 01\"), format = \"%Y %m %d\"))) |&gt;\n  as_tsibble(index = Ano)\n\nModelo de Holt e Holt amortecido para Emissões de Co2 pela indústria.\n\nemissoes_ts |&gt;\n  model(\n    `Holt` = ETS(Industria ~ error(\"A\") +\n                       trend(\"A\") + season(\"N\")),\n    `Holt amortecido` = ETS(Industria ~ error(\"A\") +\n                       trend(\"Ad\", phi = 0.90) + season(\"N\"))\n  ) |&gt;\n  forecast(h = 15) |&gt;\n  autoplot(emissoes_ts , level = NULL) +\n  labs(title = \"Emissões de gases de efeito estufa pela indústria\",\n       y = \"Gg de CO2e\",x=\"\") +\n  guides(colour = guide_legend(title = \"Previsão\"))\n\nSeja a série de exportações do Brasil. A série já foi lida no capítulo 2. Gráfico sazonal da série.\n\nexp_ts |&gt; gg_season(Exp) +\n  labs(x=\"\",y=\"Exportações [US$ FOB]: Gráfico sazonal\")\n\nModelos de suavização exponencial com sazonalidade aditiva e multiplicativa para exportações e com tendência amortecida ou não.\n\nfit_export &lt;- exp_ts |&gt; \n  filter(year(date) &lt;=2022) |&gt;\n  model(\n    `ETS(A,A,A)` = ETS(Exp ~ error(\"A\") + trend(\"A\") +\n                                                season(\"A\")),\n    `ETS(M,A,M)` = ETS(Exp ~ error(\"M\") + trend(\"A\") +\n                                                season(\"M\")),\n    `ETS(A,Ad,A)` = ETS(Exp ~ error(\"A\") + trend(\"Ad\") +\n                                                season(\"A\")),\n    `ETS(M,Ad,M)` = ETS(Exp ~ error(\"M\") + trend(\"Ad\") +\n                                                season(\"M\"))\n  )\nfc_export &lt;- fit_export |&gt; forecast(h = \"3 years\")\nfc_export |&gt;\n  autoplot(exp_ts |&gt; \n  filter(year(date) &gt;=2020), level = NULL) +\n  labs(title=\"Suavização com tendência e sazonalidade para a série de exportações\",\n       y=\"\") +\n  guides(colour = guide_legend(title = \"Previsão\"))\n\nA série de disponibilidade de fertilizantes é obtida considerando as séries de exportação, importação e produção de fertilizantes, já apresentadas no capítulo 4.\n\nfert_ &lt;- fert |&gt; \n  pivot_wider(names_from=id,\n              values_from=valor)\n\nfert_disp &lt;- fert_ |&gt;\n  filter_index(\"2013-01\"~.) |&gt;\n  mutate(disponibilidade = producao+importacao-exportacao)\n\nPlotando a série.\nGráfico sazonal.\n\nfert_disp |&gt;\n  gg_season(disponibilidade, labels = \"right\",\n            labels_repel = T)\n\nEstimando 4 modelos ETS para a disponibilidade até 2021.\n\nfit_disp &lt;- fert_disp |&gt; \n  filter_index(~\"2021-12\") |&gt;\n  model(\n    `ETS(A,A,A)` = ETS(disponibilidade ~ error(\"A\") + trend(\"A\") + season(\"A\")),\n    `ETS(M,A,M)` = ETS(disponibilidade ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n    `ETS(A,Ad,A)` = ETS(disponibilidade ~ error(\"A\") + trend(\"Ad\") + season(\"A\")),\n    `ETS(M,Ad,M)` = ETS(disponibilidade ~ error(\"M\") + trend(\"Ad\") + season(\"M\"))\n  )\n\nPrevisão de 2022 até o fim de 2025.\n\nfc_disp &lt;- fit_disp |&gt; \n  forecast(h = \"4 years\")\n\nfc_disp |&gt;\n  autoplot(fert_disp, level = NULL) +\n  labs(title=\"Previsão via ETS para disponibilidade de fertilizantes\",\n       y=\"\") +\n  guides(colour = guide_legend(title = \"Modelo\"))\n\nAvaliando a acuracidade dos modelos usando dados de 2022 até junho de 2025.\n\naccuracy(fc_disp, fert_disp |&gt; \n           filter_index(\"2022-01\"~.)) |&gt;\n  select(.model, RMSE, MAE, MAPE)\n\nGráficos de resíduos do melhor modelo.\n\nfit_disp |&gt;\n  select(`ETS(A,Ad,A)`) |&gt;\n  gg_tsresiduals()\n\nTeste de Ljung-Box para os resíduos do melhor modelo. Consideram-se 4 termos no modelo no caso amortecido.\n\naugment(fit_disp |&gt;\n          select(`ETS(A,Ad,A)`)) |&gt;\n  features(.innov, ljung_box, dof = 4, lag = 24)\n\nPrevisão com intervalo de confiança para o melhor modelo.\n\nfc_disp |&gt;\n  filter(.model==\"ETS(A,Ad,A)\") |&gt;\n  autoplot(fert_disp) +\n  labs(title=\"Previsão via ETS(A,Ad,A) para disponibilidade de fertilizantes\",\n       y=\"\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST5.html#exercícios-propostos",
    "href": "ST5.html#exercícios-propostos",
    "title": "5  Suavização exponencial",
    "section": "5.7 Exercícios propostos",
    "text": "5.7 Exercícios propostos\n\nSeja a série de produção de grãos. Separe os últimos cinco anos para testar o modelo. Aplique um modelo de suavização exponencial com tendência. Considere também o caso amortecido com \\(\\phi = 0,9\\) e \\(\\phi=0,95\\).\n\n\nAvalie os resíduos dos modelos obtidos.\n\n\nCalcule as métricas de ajuste para os dados de teste e escolha o melhor modelo.\n\n\nSeja a série de volume de exportações do Brasil exposta neste capítulo. Considerando os modelos obtidos de suavização exponencial com sazonalidade aditiva e multiplicativa e com tendência simples ou amortecida, avalie os resíduos de todos os modelos. Calcule as métricas de teste para os dados de 2023 à frente e escolha o melhor modelo.\n\nSeja a série de produção de asfalto obtida conforme segue a partir da série de derivados do petróleo do capítulo 4.\n\nasfalto &lt;- petro_ts |&gt;\n  filter(derivado == \"asfalto\") |&gt;\n  select(!derivado)\n\nasfalto |&gt; autoplot(volume)\n\n\nFiltre a série até o fim do ano de 2023 e estime 8 modelos ETS usando sazonalidade aditiva ou multiplicativa, tendência com ou sem amortecimento e erro aditivo ou multiplicativo e plote os resultados.\n\n\nFaça a previsão 2 anos à frente para a série.\n\n\nAvalie o desempenho dos modelos considerando observações disponíveis de 2024.\n\n\nAvalie os resíduos do modelo que apresentou menor erro.\n\n\nFaça o teste de Ljung-Box para o melhor modelo.\n\nSeja a série de passageiros em vôos do Brasil já apresentada no capítulo 3.\n\nFiltre a série até o fim do ano de 2017 e estime 8 modelos ETS usando sazonalidade aditiva ou multiplicativa, tendência com ou sem amortecimento e erro aditivo ou multiplicativo e plote os resultados.\n\n\nFaça a previsão 2 anos à frente para a série.\n\n\nAvalie o desempenho dos modelos considerando observações disponíveis de 2024.\n\n\nAvalie os resíduos do modelo que apresentou menor erro.\n\n\nFaça o teste de Ljung-Box para o melhor modelo.\n\n\n\n\n\nGardner, Everette S., e Ed. Mckenzie. 1985. «Forecasting Trends in Time Series». Management Science 31 (10): 1237–46. https://doi.org/10.1287/mnsc.31.10.1237.\n\n\nHolt, Charles C. 2004. «Forecasting seasonals and trends by exponentially weighted moving averages». International Journal of Forecasting 20 (1): 5–10. https://doi.org/https://doi.org/10.1016/j.ijforecast.2003.09.015.\n\n\nHyndman, RJ, e G Athanasopoulos. 2021. Forecasting: principles and practice. OTexts. OTexts.com/fpp3.\n\n\nHyndman, Rob, Anne B Koehler, J Keith Ord, e Ralph D Snyder. 2008. Forecasting with exponential smoothing: the state space approach. Springer Science & Business Media.\n\n\nWinters, Peter R. 1960. «Forecasting Sales by Exponentially Weighted Moving Averages». Management Science 6 (3): 324–42. https://doi.org/10.1287/mnsc.6.3.324.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Suavização exponencial</span>"
    ]
  },
  {
    "objectID": "ST6.html#implementações-do-capítulo-6",
    "href": "ST6.html#implementações-do-capítulo-6",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.7 Implementações do capítulo 6",
    "text": "6.7 Implementações do capítulo 6\nA seguir são apresentadas boa parte das implementações na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo.\nCarregando pacotes.\n\nlibrary(ggplot2)\nlibrary(tsibble)\nlibrary(fpp3)\nlibrary(fabletools)\nlibrary(feasts)\nlibrary(rbcb)\nlibrary(ipeadatar)\ntheme_set(theme_bw())\n\nSimulando uma série temporal de ruído branco.\n\nset.seed(33)\nwhite &lt;- tsibble(date = as.Date(\"2024-01-01\") + 0:199,\n                 value = rnorm(200)+70)\n\nwhite |&gt; autoplot(value) + labs(x=\"\",y=\"\",\n                                      title=\"Ruído branco\")\n\nDiferenciação da série do índice Ibovespa.\n\nibov &lt;- read.csv(\"Ibovespa_ InfoMoney_2024.csv\",\n                 header=T)\n\nibov &lt;- ibov |&gt;\n  mutate(DATA = 1:nrow(ibov)) |&gt;\n  select(DATA,FECHAMENTO) |&gt;\n  as_tsibble(index = DATA)\n\n\nibov |&gt;\n  autoplot(FECHAMENTO) + \n  labs(y = \"R$\", x = \"\",\n       title=\"Índice Ibovespa\") \n\n\nibov |&gt;\n  autoplot(difference(FECHAMENTO)) + \n  labs(y = \"R$\", x = \"\",\n       title=\"Variação Índice Ibovespa\") \n\n\nibov |&gt;\n  ACF(FECHAMENTO, lag_max = 30) |&gt;\n  autoplot() + \n  labs(x = \"\",\n       title=\"Índice Ibovespa\") \n\n\nibov |&gt;\n  ACF(difference(FECHAMENTO), lag_max = 30) |&gt;\n  autoplot() + \n  labs(x = \"\",\n       title=\"Variação Índice Ibovespa\") \n\nTeste de raíz unitária da série do índice Ibovespa.\n\nkpss1 &lt;- ibov |&gt;\n  features(FECHAMENTO, unitroot_kpss)\n\nkpss1\n\nSimulação de modelos autorregressivos AR(1) e AR(2).\n\nset.seed(6)\n\ny &lt;- numeric(105)\ne &lt;- rnorm(105)\nfor(i in 2:105)\n  y[i] &lt;- 15 - 0.5*y[i-1] + e[i]\n\nsim &lt;- tsibble(idx = 1:100, y = y[-c(1:5)], index = idx)\n\nsim |&gt; autoplot(y) +labs(x=\"tempo\", title = \"AR(1)\")\n\n\nset.seed(6)\n\ny2 &lt;- numeric(110)\ne2 &lt;- rnorm(110)\nfor(i in 3:110)\n  y2[i] &lt;- 8 + 1.3*y2[i-1] -0.7*y2[i-2] + e2[i]\n\nsim2 &lt;- tsibble(idx = 1:100, y = y2[-c(1:10)], index = idx)\n\nsim2 |&gt; autoplot(y) +labs(x=\"tempo\", title = \"AR(2)\")\n\nSimulação de modelos de média móvel MA(1) e MA(2).\n\nset.seed(6)\n\ny &lt;- numeric(105)\ne &lt;- rnorm(105)\nfor(i in 2:105)\n  y[i] &lt;- 15 + e[i] + 0.6*e[i-1]\nsim &lt;- tsibble(idx = 1:100, y = y[-c(1:5)], index = idx)\n\nsim |&gt; autoplot(y) +labs(x=\"tempo\", title = \"MA(1)\")\n\n\nset.seed(8)\n\ny2 &lt;- numeric(110)\ne2 &lt;- rnorm(110)\nfor(i in 3:110)\n  y2[i] &lt;- 8 + e2[i] - 0.9*e2[i-1] + 0.5*e2[i-2] \n\nsim2 &lt;- tsibble(idx = 1:100, y = y2[-c(1:10)], index = idx)\n\nsim2 |&gt; autoplot(y) +labs(x=\"tempo\", title = \"MA(2)\")\n\nSérie de produção de coque.\n\npetro &lt;- read.csv(\"petroleo_e_derivados.csv\", header=T)\ncoque &lt;- petro |&gt; select(data,coque)\ncoque_ts &lt;- coque |&gt;\n  mutate(data = as.Date(data, format=\"%m/%d/%Y\"))\n\ncoque_ts &lt;- coque_ts |&gt; \n  as_tsibble(index = data) |&gt;\n  filter_index(\"2021-01-01\"~.) |&gt;\n  mutate(data = yearmonth(data))\n\n\ncoque_ts |&gt;\n  autoplot(coque) +\n  guides(colour = \"none\") +\n  labs(x=\"\",y=\"m^3\", title=\"Produção de coque no Brasil\")\n\nAuto ARIMA para a série de produção de coque.\n\nfit1 &lt;- coque_ts |&gt;\n  model(ARIMA(coque))\n\nreport(fit1)\n\nPrevisão 10 meses à frente.\n\nfit1 |&gt; forecast(h=10) |&gt;\n  autoplot(coque_ts) +\n  labs(x=\"\",y=\"m^3\", title=\"Produção de coque no Brasil\")\n\nSérie temporal do valor da ação VALE3 a partir de 2020.\n\nvale &lt;- read.csv(\"VALE3.csv\", header = T, dec=\",\")\n\nvale_ts &lt;- tsibble(Date = as.Date(vale$Data,\n                                  format = \"%d.%m.%Y\"),\n                   Valor = vale$Último,\n                   index = Date)\n\n\nvale_ts &lt;- vale_ts |&gt;\n  filter(year(Date) &gt; 2020) |&gt;\n  mutate(Date = yearmonth(Date))\n\nvale_ts |&gt;  \n  autoplot(Valor) + labs(x=\"\", y = \"R$\",\n                         title=\"Valor da ação VALE3\")\n\nModelo ARIMA obtido automaticamente para a série.\n\nfit2 &lt;- vale_ts |&gt;\n  model(ARIMA(Valor))\n\nreport(fit2)\n\nAvaliando os resíduos do modelo.\n\nfit2 |&gt;\n  gg_tsresiduals()\n\nPrevisão 10 meses à frente.\n\nfit2 |&gt; forecast(h=10) |&gt;\n  autoplot(vale_ts) +\n  labs(x=\"\",y=\"R$\", title=\"Valor da ação VALE3\")\n\nCorrelogramas de autocorrelação ACF e PACF da série VALE3.\n\nvale_ts |&gt;\n  ACF(Valor) |&gt;\n  autoplot()\n\n\nvale_ts |&gt;\n  PACF(Valor) |&gt;\n  autoplot()\n\nModelo ARIMA(3,0,0).\n\nfit3 &lt;- vale_ts |&gt;\n  model(ARIMA(Valor ~ pdq(3,0,0)))\n\nreport(fit3)\n\nSérie de produção de grãos.\n\ngraos_prod &lt;- ipeadata(\"DEPAE_SAFRA\")\n\ngraos  &lt;- tsibble(valor = c(graos_prod$value),\n                  data = yearmonth(graos_prod$date),\n                  index=data) |&gt;\n  mutate(data=year(data))\n\n\n\n\n\n\n\n\n\n\nTransformação de Box-Cox da série.\n\nlambda &lt;- graos |&gt;\n  features(valor, features = guerrero) |&gt;\n  pull(lambda_guerrero)\ngraos |&gt;\n  autoplot(box_cox(valor, lambda)) + \n  labs(y=\"\", x=\"\", title=\"Produção de grãos no Brasil: transformação de Box-Cox\")\n\nVariação da série transformada.\n\ngraos |&gt;  \n  autoplot(difference(box_cox(valor, lambda))) + \n  labs(x=\"\", y = \"\",\n       title=\"Variação na produção de grãos no Brasil\")\n\nCorrelogramas de ACF e PACF.\n\ngraos |&gt;\n  ACF(difference(box_cox(valor, lambda))) |&gt;\n  autoplot()\n\n\ngraos |&gt;\n  PACF(difference(box_cox(valor, lambda))) |&gt;\n  autoplot()\n\nModelo ARIMA(1,1,0).\n\nfit4 &lt;- graos |&gt;\n  model(ARIMA(box_cox(valor, lambda) ~ pdq(1,1,0)))\n\nreport(fit4)\n\nModelo ARIMA(0,1,1).\n\nfit5 &lt;- graos |&gt;\n  model(ARIMA(box_cox(valor, lambda) ~ pdq(0,1,1)))\n\nreport(fit5)\n\nAvaliação dos resíduos do modelo ARIMA(1,1,0).\n\nfit4 |&gt;\n  gg_tsresiduals()\n\nTteste de Ljung-Box para os resíduos do modelo ARIMA(1,1,0).\n\nQQ_ &lt;- fit4 |&gt;\n  augment() |&gt; \n  features(.innov, ljung_box, lag = 10, dof = 1)\n\nQQ_\n\nPrevisão 10 anos à frente.\n\nfit4 |&gt; forecast(h=10) |&gt;\n  autoplot(graos) +\n  labs(x=\"\",y=\"ton\", title=\"Produção de grãos\")\n\nSérie de passageiros em vôos no Brasil.\n\nlibrary(vroom)\nvoosbr &lt;- vroom(\"voos_BR_comp.csv\", col_names = T, skip = 1)\n\n\nvoosbr_ts &lt;- voosbr |&gt;\n  select(MES,ANO,PASSAGEIROS_PAGOS,PASSAGEIROS_GRATIS) |&gt;\n  mutate(Passageiros = PASSAGEIROS_GRATIS+PASSAGEIROS_PAGOS) |&gt;\n  mutate(data = yearmonth(ymd(\n    paste(ANO, MES, \"01\", sep = \"-\")))) |&gt;\n  select(!c(MES,ANO,PASSAGEIROS_PAGOS,PASSAGEIROS_GRATIS)) |&gt;\n  group_by(data) |&gt;\n  summarise(Passageiros = sum(Passageiros, na.rm = T)) |&gt; \n  as_tsibble(index=data)\n\nVariação sazonal da série de log(passageiros) em vôos do Brasil e correlogramas de ACF e PACF.\n\nvoosbr_ts  |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  gg_tsdisplay(difference(log(Passageiros), 12),\n               plot_type='partial', lag=36) +\n  labs(title=\"log(Passageiros) de vôos no Brasil: Variação sazonal\", y=\"\")\n\nSérie transformada com diferenciação simples e sazonal, além dos correlogramas de ACF e PACF.\n\nvoosbr_ts  |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  gg_tsdisplay(difference(log(Passageiros), 12) |&gt; difference(),\n               plot_type='partial', lag=36) +\n  labs(title=\"Variação dupla\", y=\"\")\n\nTestando modelos \\(ARIMA(0,1,1)(0,1,1)_{12}\\), \\(ARIMA(1,1,0)(2,1,0)_{12}\\), além do autoarima.\n\nfit6 &lt;- voosbr_ts  |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  model(\n    arima011011 = ARIMA(log(Passageiros) ~ pdq(0,1,1) + PDQ(0,1,1)),\n    arima110210 = ARIMA(log(Passageiros) ~ pdq(1,1,0) + PDQ(2,1,0)),\n    auto = ARIMA(log(Passageiros), stepwise = FALSE, approx = FALSE)\n  )\nkable(\nfit6 |&gt; pivot_longer(everything(), names_to = \"Modelo\",\n                     values_to = \"Ordem\")\n)\n\nResultado dos três modelos.\n\nglance(fit6) |&gt; arrange(AICc) |&gt; select(.model:BIC)\n\nCoeficientes do modelo automático, \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\nreport(fit6 |&gt; select(auto))\n\nGráficos de resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\nfit6 |&gt; select(auto) |&gt; gg_tsresiduals(lag=36)\n\nTeste de Ljung-Box para os resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\nkable(\naugment(fit6) |&gt;\n  filter(.model == \"auto\") |&gt;\n  features(.innov, ljung_box, lag=24, dof=3)\n)\n\nPrevisão para 3 anos à frente para a série de passageiros em vôos do Brasil.\n\nforecast(fit6, h=36) |&gt;\n  filter(.model=='auto') |&gt;\n  autoplot(voosbr_ts |&gt;\n  filter(year(data)&lt;2020)) +\n  labs(title = \"Passageiros em vôos do Brasil\",\n       y=\"Passageiros\")\n\n\n\n\n\nHyndman, Rob J, e Yeasmin Khandakar. 2008. «Automatic time series forecasting: the forecast package for R». Journal of statistical software 27: 1–22.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#implementações-em-r",
    "href": "ST6.html#implementações-em-r",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.7 Implementações em R",
    "text": "6.7 Implementações em R\nA seguir são apresentadas boa parte das implementações na linguagem R para obter os dados, gráficos e análises expostos no presente capítulo.\nCarregando pacotes.\n\nlibrary(ggplot2)\nlibrary(tsibble)\nlibrary(forecast)\nlibrary(fable)\nlibrary(fabletools)\nlibrary(feasts)\nlibrary(lubridate)\nlibrary(rbcb)\nlibrary(ipeadatar)\ntheme_set(theme_bw())\n\nSimulando uma série temporal de ruído branco. A função básica rnorm serve para gerar números aleatórios na distribuição normal.\n\nset.seed(33)\nwhite &lt;- tsibble(date = as.Date(\"2024-01-01\") + 0:199,\n                 value = rnorm(200)+70)\n\nwhite |&gt; \n  autoplot(value) + \n  labs(x=\"\",\n       y=\"\",\n       title=\"Ruído branco\")\n\nDiferenciação da série do índice Ibovespa. Usa-se o comando difference.\n\nibov &lt;- read.csv(\"Ibovespa_ InfoMoney_2024.csv\",\n                 header=T)\n\nibov &lt;- ibov |&gt;\n  mutate(DATA = 1:nrow(ibov)) |&gt;\n  select(DATA,FECHAMENTO) |&gt;\n  as_tsibble(index = DATA)\n\n\nibov |&gt;\n  autoplot(difference(FECHAMENTO)) + \n  labs(y = \"R$\", x = \"\",\n       title=\"Variação Índice Ibovespa\") \n\nA autocorrelação é obtida via função ACF, com o argumento lag_max para definir a diferenciação máxima. Usando a função autoplot em sequência, ao invés de se exibir as autocorrelações, plota-se o correlograma.\n\nibov |&gt;\n  ACF(FECHAMENTO, lag_max = 30) |&gt;\n  autoplot() + \n  labs(x = \"\",\n       title=\"Índice Ibovespa\") \n\nPara obter o correlograma da série diferenciada procedendo conforme segue.\n\nibov |&gt;\n  ACF(difference(FECHAMENTO), lag_max = 30) |&gt;\n  autoplot() + \n  labs(x = \"\",\n       title=\"Variação Índice Ibovespa\") \n\nTeste de KPSS da série do índice Ibovespa. Usa-se a opção unitroot_kpss no argumento da função features.\n\nkpss1 &lt;- ibov |&gt;\n  features(FECHAMENTO, features = unitroot_kpss)\n\nkpss1\n\nSérie de produção de coque.\n\npetro &lt;- read.csv(\"petroleo_e_derivados.csv\", header=T)\ncoque &lt;- petro |&gt; select(data,coque)\ncoque_ts &lt;- coque |&gt;\n  mutate(data = as.Date(data, format=\"%m/%d/%Y\"))\n\ncoque_ts &lt;- coque_ts |&gt; \n  as_tsibble(index = data) |&gt;\n  filter_index(\"2021-01-01\"~.) |&gt;\n  mutate(data = yearmonth(data))\n\n\ncoque_ts |&gt;\n  autoplot(coque) +\n  guides(colour = \"none\") +\n  labs(x=\"\",y=\"m^3\", title=\"Produção de coque no Brasil\")\n\nA série é estacionária, conforme confirma-se pelo teste de KPSS.\n\ncoque_ts |&gt;\n  features(coque, unitroot_kpss)\n\ncoque_ts |&gt;\n  ACF(coque) |&gt;\n  autoplot()\n\nARIMA automática para a série de produção de coque. Usa-se ARIMA em model e apenas a série de interesse.\n\nfit1 &lt;- coque_ts |&gt;\n  model(ARIMA(coque))\n\nreport(fit1)\n\nPrevisão 10 meses à frente.\n\nfit1 |&gt; \n  forecast(h=10) |&gt;\n  autoplot(coque_ts) +\n  labs(x=\"\",y=\"m^3\", title=\"Produção de coque no Brasil\")\n\nSérie temporal do valor da ação VALE3 a partir de 2020.\n\nvale &lt;- read.csv(\"VALE3.csv\", header = T, dec=\",\")\n\nvale_ts &lt;- tsibble(Date = as.Date(vale$Data,\n                                  format = \"%d.%m.%Y\"),\n                   Valor = vale$Último,\n                   index = Date)\n\n\nvale_ts &lt;- vale_ts |&gt;\n  filter(year(Date) &gt; 2020) |&gt;\n  mutate(Date = yearmonth(Date))\n\nvale_ts |&gt;  \n  autoplot(Valor) + \n  labs(x=\"\", y = \"R$\",\n       title=\"Valor da ação VALE3\")\n\nModelo ARIMA obtido automaticamente para a série.\n\nfit2 &lt;- vale_ts |&gt;\n  model(ARIMA(Valor))\n\nreport(fit2)\n\nAvaliando os resíduos do modelo.\n\nfit2 |&gt;\n  gg_tsresiduals()\n\nPrevisão 10 meses à frente.\n\nfit2 |&gt; \n  forecast(h=10) |&gt;\n  autoplot(vale_ts) +\n  labs(x=\"\",y=\"R$\", title=\"Valor da ação VALE3\")\n\nCorrelogramas de autocorrelação ACF e PACF da série VALE3.\n\nvale_ts |&gt;\n  ACF(Valor) |&gt;\n  autoplot()\n\n\nvale_ts |&gt;\n  PACF(Valor) |&gt;\n  autoplot()\n\nModelo ARIMA(3,0,0). Deve-se usar pdq(p,d,q) para definir a ordem do modelo ARIMA.\n\nfit3 &lt;- vale_ts |&gt;\n  model(ARIMA(Valor ~ pdq(3,0,0)))\n\nreport(fit3)\n\nSérie de produção de grãos.\n\ngraos_prod &lt;- ipeadata(\"DEPAE_SAFRA\")\n\ngraos  &lt;- tsibble(valor = c(graos_prod$value),\n                  data = yearmonth(graos_prod$date),\n                  index=data) |&gt;\n  mutate(data=year(data))\n\n\ngraos |&gt;  \n  autoplot(valor) + \n  labs(x=\"\",\n       y = \"ton\",\n       title=\"Produção de grãos no Brasil\")\n\nTransformação de Box-Cox da série.\n\nlambda &lt;- graos |&gt;\n  features(valor, features = guerrero) |&gt;\n  pull(lambda_guerrero)\n\ngraos |&gt;\n  autoplot(box_cox(valor, lambda)) + \n  labs(y=\"\", x=\"\", \n       title=\"Produção de grãos no Brasil: transformação de Box-Cox\")\n\nVariação da série transformada.\n\ngraos |&gt;  \n  autoplot(difference(box_cox(valor, lambda))) + \n  labs(x=\"\", y = \"\",\n       title=\"Variação na produção de grãos no Brasil\")\n\nCorrelogramas de ACF e PACF para a série transformada e diferenciada.\n\ngraos |&gt;\n  ACF(difference(box_cox(valor, lambda))) |&gt;\n  autoplot()\n\n\ngraos |&gt;\n  PACF(difference(box_cox(valor, lambda))) |&gt;\n  autoplot()\n\nModelo ARIMA(1,1,0) para série transformada e diferenciada.\n\nfit4 &lt;- graos |&gt;\n  model(ARIMA(box_cox(valor, lambda) ~ pdq(1,1,0)))\n\nreport(fit4)\n\nModelo ARIMA(0,1,1).\n\nfit5 &lt;- graos |&gt;\n  model(ARIMA(box_cox(valor, lambda) ~ pdq(0,1,1)))\n\nreport(fit5)\n\nAvaliação dos resíduos do modelo ARIMA(1,1,0).\n\nfit4 |&gt;\n  gg_tsresiduals()\n\nTteste de Ljung-Box para os resíduos do modelo ARIMA(1,1,0). Considera-se um grau de liberdade, pois o modelo tem apenas um termo autorregressivo, \\(p=1\\). A diferenciação não conta.\n\nQQ_ &lt;- fit4 |&gt;\n  augment() |&gt; \n  features(.innov, ljung_box, lag = 10, dof = 1)\n\nQQ_\n\nPrevisão 10 anos à frente.\n\nfit4 |&gt; forecast(h=10) |&gt;\n  autoplot(graos) +\n  labs(x=\"\",y=\"ton\", title=\"Produção de grãos\")\n\nSérie de passageiros em vôos no Brasil.\n\nlibrary(vroom)\nvoosbr &lt;- vroom(\"voosbr_ts.csv\", \n                col_names = T)\n\nvoosbr_ts &lt;- voosbr |&gt;\n    mutate(data = yearmonth(data)) |&gt; \n    as_tsibble(index = data)\n\nVariação sazonal da série de log(passageiros) em vôos do Brasil e correlogramas de ACF e PACF.\n\nvoosbr_ts  |&gt;\n  filter_index(~\"2019-01\") |&gt;\n  gg_tsdisplay(difference(log(Passageiros), 12),\n               plot_type='partial', lag=36) +\n  labs(title=\"log(Passageiros) de vôos no Brasil: Variação sazonal\", y=\"\")\n\nSérie transformada com diferenciação simples e sazonal (\\(m=12\\)), além dos correlogramas de ACF e PACF.\n\nvoosbr_ts  |&gt;\n  filter_index(~\"2019-01\") |&gt;\n  gg_tsdisplay(difference(log(Passageiros), 12) |&gt; difference(),\n               plot_type='partial', lag=36) +\n  labs(title=\"Variação dupla\", y=\"\")\n\nTestando modelos \\(ARIMA(0,1,1)(0,1,1)_{12}\\), \\(ARIMA(1,1,0)(2,1,0)_{12}\\), além do autoarima. Para a parte sazonal soma-se no modelo PDP(P,D,Q) para definir a ordem.\n\nfit6 &lt;- voosbr_ts  |&gt;\n  filter(year(data)&lt;2020) |&gt;\n  model(\n    sarima011011 = ARIMA(log(Passageiros) ~ pdq(0,1,1) + PDQ(0,1,1)),\n    sarima110210 = ARIMA(log(Passageiros) ~ pdq(1,1,0) + PDQ(2,1,0)),\n    auto = ARIMA(log(Passageiros), stepwise = FALSE, approx = FALSE)\n  )\n\nkable(\nfit6 |&gt; pivot_longer(everything(), names_to = \"Modelo\",\n                     values_to = \"Ordem\")\n)\n\nResultados dos três modelos.\n\nglance(fit6) |&gt; \n  arrange(AICc) |&gt; \n  select(.model:BIC)\n\nCoeficientes do modelo automático, \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\nreport(fit6 |&gt; \n         select(auto))\n\nGráficos de resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\nfit6 |&gt; \n  select(auto) |&gt; \n  gg_tsresiduals(lag=36)\n\nTeste de Ljung-Box para os resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\nkable(\naugment(fit6) |&gt;\n  filter(.model == \"auto\") |&gt;\n  features(.innov, ljung_box, lag=24, dof=3)\n)\n\nPrevisão para 3 anos à frente para a série de passageiros em vôos do Brasil.\n\nforecast(fit6, h=36) |&gt;\n  filter(.model=='auto') |&gt;\n  autoplot(voosbr_ts |&gt;\n  filter_index(~\"2020-01\")) +\n  labs(title = \"Passageiros em vôos do Brasil\",\n       y=\"Passageiros\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#exercícios-propostos.",
    "href": "ST6.html#exercícios-propostos.",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.8 Exercícios propostos.",
    "text": "6.8 Exercícios propostos.\nA seguir o código para obter a série de produção de asfalto.\n\npetro &lt;- read.csv(\"petroleo_e_derivados.csv\", header=T)\nasfalto &lt;- petro |&gt; select(data,asfalto)\nasfalto_ts &lt;- asfalto |&gt;\n  mutate(data = as.Date(data, format=\"%m/%d/%Y\"))\n\nasfalto_ts &lt;- asfalto_ts |&gt; \n  as_tsibble(index = data) |&gt;\n  mutate(data = yearmonth(data))\n\nasfalto_ts |&gt; autoplot(asfalto)\n\nNos exercícios 1 ao 3 filtre a série até 2020.\n\nFaça os correlogramas de ACF e PACF da série.\n\n\nTeste distintos modelos ARIMA, segundo autocorrelações observadas e compare com o ARIMA automático.\n\n\nAvalie os resíduos dos modelos testados.\n\n\nConsidere os dados de 2021 à frente e faça a previsão. Calcule as métricas de erro e escolha o melhor modelo.\n\n\nTeste distintos modelos de suavização exponencial com sazonalidade para a série de produção de asfalto e compare com o melhor modelo ARIMA obtido.\n\nSeja a série de chegadas de turistas internacionais no Brasil, apresentada neste capítulo, obtida conforme segue.\n\nObtenha com a função gg_tsdisplay a diferenciação sazonal (m=12) do log da série e os correlogramas de ACF e PACF.\nFaça o teste de KPSS para avaliar se a variação sazonal do log da série é estacionária.\nObtenha modelos SARIMA segundo propõem os padrões dos correlogramas de ACF e PACF. Considere o período de 2015 a 2019. Selecione o melhor modelo segundo a métrica \\(AICc\\) e obtenha os coficientes deste via report.\nObtenha os resíduos do melhor modelo e faça o teste de Ljung-Box para avaliar a autocorrelação destes.\nFaça a previsão cinco anos à frente (h=60), plote os resultados e compare o desempenho dos modelos considerando os anos de 2023 e 2024.\nConsiderando a série de produção de bens de consumo duráveis, apresentada no primeiro capítulo, realize o mesmo fluxo proposto nas questões 6 a 10, com as devidas adaptações (por exemplo, decidindo entre diferenciação simples, sazonal ou dupla, segundo o padrão da série). Obtenha modelos ARIMA adequados à série usando dados de até 2020 e compare-os para os últimos anos da série.\n\n\n\n\n\nBox, George EP, Gwilym M Jenkins, Gregory C Reinsel, e Greta M Ljung. 2008. Time series analysis: forecasting and control. John Wiley & Sons.\n\n\nHamilton, James D. 1994. Time series analysis. Princeton university press.\n\n\nHyndman, RJ, e G Athanasopoulos. 2021. Forecasting: principles and practice. OTexts. OTexts.com/fpp3.\n\n\nHyndman, Rob J, e Yeasmin Khandakar. 2008. «Automatic time series forecasting: the forecast package for R». Journal of statistical software 27: 1–22.\n\n\nKwiatkowski, Denis, Peter CB Phillips, Peter Schmidt, e Yongcheol Shin. 1992. «Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root?» Journal of econometrics 54 (1-3): 159–78.\n\n\nMakridakis, Spyros, Steven C Wheelwright, e Rob J Hyndman. 2008. Forecasting methods and applications. John wiley & sons.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  },
  {
    "objectID": "ST6.html#sarima-arima-com-sazonalidade",
    "href": "ST6.html#sarima-arima-com-sazonalidade",
    "title": "6  Modelos auto-regressivos integrados de médias móveis (ARIMA)",
    "section": "6.6 SARIMA: ARIMA com sazonalidade",
    "text": "6.6 SARIMA: ARIMA com sazonalidade\nModelos ARIMA também podem ser aplicados a casos sazonais, sendo denotados \\(ARIMA(p,d,q)(P,D,Q)_m\\), onde \\(m\\) é o período sazonal e os termos da parte sazonal do modelo são denotados por letras maiúsculas. Um modelo \\(ARIMA(1,1,1)(1,1,1)_{12}\\) para uma série de frequência mensal seria para sazonalidade anual e pode ser escrito em notação de defasagem conforme Equação 6.23, onde \\(\\Phi_1\\) e \\(\\Theta_1\\) são, respectivamente, os termos autorregressivo e de média móvel, para a parte sazonal. Os modelos ARIMA sazonais são comumente chamados de SARIMA.\n\\[\n(1-\\phi_1B)(1-\\Phi_1B^{12})(1-B)(1-B^{12})y_t = c+( 1+\\theta_1B)( 1+\\Theta_1B^{12})\\varepsilon_t\n\\tag{6.23}\\]\nA Figura 6.17 expõe graficamente a série de chegada de turistas no Brasil, incluindo brasileiros que vivem no exterior e estrangeiros. A série tem frequência mensal e está disponível em Estimativas de Chegadas de Turistas Internacionais ao Brasil. Observa-se tendência de crescimento no volume de chegadas com variação sazonal anual com padrão não constante. A partir de 2020 observa-se queda brusca no volume de chegadas devido à pandemia de COVID-19.\n\n\n\n\n\n\n\n\nFigura 6.17: Série de chegada turistas do exterior no Brasil\n\n\n\n\n\nA Figura 6.18 ilustra o gráfico sazonal da série de chegada de turistas no Brasil. Confirma-se a sazonalidade anual, com maior volume nas chegadas em dezembro e janeiro, além de volume maior em julho, em relação aos meses do outono e do inverno. Fica clara, também, a tendência de crescimento na duas últimas décadas, em relação aos anos 90 e início dos anos 2000. Destaca-se, também, o pico de chegadas em junho de 2014, devido à copa do mundo de futebol, além do aumento do volume de chegadas em agosto de 2016, devido às olimpíadas do Rio de Janeiro.\n\n\n\n\n\n\n\n\nFigura 6.18: Chegada turistas no Brasil: gráfico sazonal\n\n\n\n\n\nA Figura 6.19 expõe novamente a série de chegada de turistas do exterior no Brasil, considerando o período de 2015 a 2019. A Figura também apresenta a série transformada via logarítmo, com diferenciação sazonal e diferenciação dupla. Observa-se que, por neste período a série não apresentar tendência clara, a diferenciação sazonal já praticamente viabiliza a estacionariedade. A Tabela 6.8 expõe o resultado do teste de KPSS, o qual indica a não rejeição da hipótese nula de estacionariedade da variação no log série de chegada turistas no Brasil.\n\n\n\n\n\n\n\n\nFigura 6.19: Chegada turistas do exterior no Brasil\n\n\n\n\n\n\n\n\n\nTabela 6.8: Teste de KPSS para a variação sazonal no log série de chegada turistas no Brasil\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n0,0591714\n0,1\n\n\n\n\n\n\n\n\nA Figura 6.20 expõe os correlogramas de ACF e PACF para a variação sazonal no log série de chegada turistas no Brasil. Observa-se no correlograma de ACF pico nas autocorrelações com defasagem de uma e de doze observações, sugerindo \\(q=1\\) e \\(Q=1\\). O correlograma de PACF apresenta padrão similar, sugerindo \\(p=1\\) e \\(P=1\\). Logo, serão testados os modelos \\(ARIMA(1,0,0)(1,1,0)_{12}\\) e \\(ARIMA(0,0,1)(0,1,1)_{12}\\), além do modelo ARIMA automático.\n\n\n\n\n\n\n\n\nFigura 6.20: Correlogramas para a variação sazonal no log série de chegada turistas no Brasil\n\n\n\n\n\nA Tabela 6.9 apresenta o resultado dos modelos ARIMA testados para o log série de chegada turistas no Brasil. Observa-se que o modelo automático apresentou os mesmos resultados que o modelo \\(ARIMA(0,0,1)(0,1,1)_{12}\\). A seguir expõe-se a saída do modelo automático, indicando que ele é exatamente igual ao supracitado. Logo, foi possível identificar via PACF a ordem da média móvel da parte simples e da sazonal do modelo SARIMA.\n\n\n\n\nTabela 6.9: Modelos ARIMA para o log série de chegada turistas no Brasil\n\n\n\n\n\n\nModelo\nsigma2\nlog_lik\nAIC\nAICc\nBIC\n\n\n\n\nsarima001011\n0,0164671\n29,06562\n-52,13123\n-51,58578\n-46,51763\n\n\nauto\n0,0164671\n29,06562\n-52,13123\n-51,58578\n-46,51763\n\n\nsarima100110\n0,0173195\n28,71595\n-51,43190\n-50,88645\n-45,81830\n\n\n\n\n\n\n\n\n\n\nSeries: Chegadas \nModel: ARIMA(0,0,1)(0,1,1)[12] \nTransformation: log(Chegadas) \n\nCoefficients:\n         ma1     sma1\n      0,2236  -0,5806\ns.e.  0,1361   0,2472\n\nsigma^2 estimated as 0,01647:  log likelihood=29,07\nAIC=-52,13   AICc=-51,59   BIC=-46,52\n\n\nA Figura 6.21 expõe os gráficos de resíduos, indicando autocorrelção isolada para o lag 3, além de histograma com um pouco de assimetria à esquerda, porém, não representando desvio grave de normalidade. A Tabela 6.10 expõe o resultado do teste de Ljung-Box, que sugere a não rejeição da hipótese nula de ausência de autocorrelação nos resíduos.\n\n\n\n\n\n\n\n\nFigura 6.21: Gráficos para os resíduos do modelo \\(ARIMA(0,0,1)(0,1,1)_{12}\\) para a variação sazonal no log série de chegada turistas no Brasil\n\n\n\n\n\n\n\n\n\nTabela 6.10: Modelos ARIMA para o log série de chegada turistas no Brasil\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n31,34185\n0,0893296\n\n\n\n\n\n\n\n\nA Figura 6.22 expõe o resultado da previsão dos modelos ARIMA considerados. Obviamente ambos os modelos não capturam a queda no volume de vôos nos anos da pandemia. Entretanto, as previsões apresentam boa proximidade com os resultados dos anos de 2023 e 2024. A Tabela 6.11 expõe o desempenho dos modelos para os anos de 2023 e 2024. Confirma-se que o modelo \\(ARIMA(0,0,1)(0,1,1)_{12}\\) apresentou melhor desempenho, com 10,3% de erro para estes anos.\n\n\n\n\n\n\n\n\nFigura 6.22: Previsão dos modelos ARIMA para a chegada turistas no Brasil\n\n\n\n\n\n\n\n\n\nTabela 6.11: Desempenho dos modelos ARIMA para o log série de chegada turistas no Brasil para os anos de 2023 e 2024\n\n\n\n\n\n\n.model\nRMSE\nMAE\nMAPE\n\n\n\n\nsarima001011\n55576,20\n47824,28\n10,29882\n\n\nsarima100110\n74167,86\n64851,82\n14,18985\n\n\n\n\n\n\n\n\nA Figura 6.23 expõe a variação sazonal da série de log(passageiros) em vôos do Brasil, além dos correlogramas de ACF e PACF. Pode-se observar que a série sazonalmente diferenciada ainda apresenta alta tendência. É ainda necessário uma diferenciação de primeira ordem.\n\n\n\n\n\n\n\n\nFigura 6.23: Variação sazonal no log(passageiros) de vôos no Brasil\n\n\n\n\n\nA Figura 6.24 apresenta a série mais uma vez diferenciada. Examinando-se o correlograma de ACF, pode-se sugerir um modelo MA(1) para a parte não sazonal, dada a significância no lag 1, e um modelo MA(1) para a parte sazonal, dada a significância no lag 12. Logo, pode-se sugerir um modelo \\(ARIMA(0,1,1)(0,1,1)_{12}\\). Ao observar o correlograma de PACF, há indícios de que um modelo autorregressivo de ordem AR(1) seja adequado para a parte não sazonal, enquanto um modelo AR(3) pode ser interessante para a parte sazonal, devido aos picos de 12, 24 e 36 meses. Entretanto, ao se tentar estimar um modelo \\(ARIMA(1,1,0)(3,1,0)_{12}\\) não foram reportados resultados, sendo então aproximado um modelo \\(ARIMA(1,1,0)(2,1,0)_{12}\\).\n\n\n\n\n\n\n\n\nFigura 6.24: Série de passageiros de vôos no Brasil\n\n\n\n\n\nAlém dos modelos sugeridos, o método automático do pacote fable sugere um modelo de ordem \\(ARIMA(1,1,1)(0,1,1)_{12}\\), conforme Tabela 6.12, muito próximo dos considerados inicialmente.\n\n\n\n\nTabela 6.12: Modelos ARIMA testados para a série log(passageiros)\n\n\n\n\n\n\nModelo\nOrdem\n\n\n\n\nsarima011011\n&lt;ARIMA(0,1,1)(0,1,1)[12]&gt;\n\n\nsarima110210\n&lt;ARIMA(1,1,0)(2,1,0)[12]&gt;\n\n\nauto\n&lt;ARIMA(1,1,1)(0,1,1)[12]&gt;\n\n\n\n\n\n\n\n\nA Tabela 6.13 resume o resultado dos três modelos. Considerando o AICc, o modelo automático apresentou por pouco o melhor resultado.\n\n\n\n\nTabela 6.13: Resultados dos modelos ARIMA testados para a série log(passageiros)\n\n\n\n\n\n\nModelo\nsigma2\nlog_lik\nAIC\nAICc\nBIC\n\n\n\n\nauto\n0,0010447\n455,1001\n-902,2002\n-902,0201\n-888,5004\n\n\nsarima011011\n0,0010532\n453,7601\n-901,5202\n-901,4126\n-891,2453\n\n\nsarima110210\n0,0011762\n444,0289\n-880,0578\n-879,8776\n-866,3580\n\n\n\n\n\n\n\n\nA seguir são apresentados os coeficientes do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\).\n\n\nSeries: Passageiros \nModel: ARIMA(1,1,1)(0,1,1)[12] \nTransformation: log(Passageiros) \n\nCoefficients:\n         ar1      ma1     sma1\n      0,5214  -0,6437  -0,7410\ns.e.  0,2121   0,1859   0,0584\n\nsigma^2 estimated as 0,001045:  log likelihood=455,1\nAIC=-902,2   AICc=-902,02   BIC=-888,5\n\n\nA Figura 6.25 apresenta os gráficos de resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\). A série residual apresenta padrão estacionário e não há indícios de desvio de normalidade pelo histograma. Há significância na autocorrelação para as defasagens de 11, 13 e 22 observações.\n\n\n\n\n\n\n\n\nFigura 6.25: Série de passageiros de vôos no Brasil\n\n\n\n\n\nA Tabela 6.14 apresenta o resultado do teste de Ljung-Box para os resíduos do modelo \\(ARIMA(1,1,1)(0,1,1)_{12}\\) para a série log(passageiros). No caso sazonal, considera-se \\(K=p+q+P+Q\\) graus de liberdade no teste. Considerando um nível de significância de 0,05, não há indícios suficientes para rejeição da hipótese nula de ausência de autocorrelação residual.\n\n\n\n\nTabela 6.14: Teste Ljung-Box para o modelo ARIMA(1,1,1)(0,1,1)12 para a série log(passageiros)\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n28,77407\n0,1195322\n\n\n\n\n\n\n\n\nA Figura 6.26 apresenta a previsão para 3 anos à frente para a série de passageiros em vôos do Brasil. Sabe-se que a pandemia reduziu o volume de vôos para níveis menores que os dos anos 2000. Entretanto, o modelo capturou bem o padrão dos últimos anos e o padrão de sazonalidade no número de passageiros. Após alguns anos de observação pós-pandemia, modelos ARIMA seguirão sendo úteis para modelar a variação observada no volume de passageiros em vôos do Brasil.\n\n\n\n\n\n\n\n\nFigura 6.26: Previsão para 3 anos à frente para a série de passageiros de vôos no Brasil\n\n\n\n\n\nA Figura 6.27 expõe a série de produtos não duráveis no Brasil. Observa-se padrão sazonal anual com tendência de crescimento até 2015 e depois de queda, com pior resultado em 2020, devido a pandemia. Após, 2021 observa-se tendência de recuperação.\n\n\n\n\n\n\n\n\nFigura 6.27: Produção mensal de bens não duráveis no Brasil\n\n\n\n\n\nA Figura 6.28 expõe a série de bens de consumo não duráveis duplamente diferenciada - simples e sazonal (\\(m=12\\)), considerando os dados de até dezembro de 2021. Pode-se sugerir pelo correlograma de PACF um modelo de ordem (2,1,0) para a parte não sazonal e um modelo de ordem (1,1,0) para a parte sazonal, dado o pico no atraso 12 meses. Já pelo correlograma de ACF, pode-se sugerir um modelo de ordem (0,1,1) para a parte não sazonal e um modelo de ordem (0,1,1) para a parte sazonal. Apesar de haverem outras autocorrelações siginificativas, estas não serão consideradas, uma vez que não são em sequência tanto para a tendência quanto para a sazonalidade.\n\n\n\n\n\n\n\n\nFigura 6.28: Variação sazonal na produção de bens de consumo não duráveis\n\n\n\n\n\nA Tabela 6.15 expõe os modelos testados manualmente e o selecionado automaticamente.\n\n\n\n\nTabela 6.15: Modelos ARIMA testados para a série de bens não duráveis\n\n\n\n\n\n\nModelo\nOrdem\n\n\n\n\narima210110\n&lt;ARIMA(2,1,0)(1,1,0)[12]&gt;\n\n\narima011011\n&lt;ARIMA(0,1,1)(0,1,1)[12]&gt;\n\n\nauto\n&lt;ARIMA(4,1,1)(0,1,1)[12]&gt;\n\n\n\n\n\n\n\n\nA Tabela 6.16 apresenta os resultados para os modelos testados na série de bens de consumo não duráveis. O modelo \\(ARIMA(4,1,1)(0,1,1)_{12}\\), selecionado via pacote fable apresenta melhor ajuste. R. J. Hyndman e Khandakar (2008) descrevem a abordagem usada no pacote para seleção automática de modelos SARIMA sem e com sazonalidade e também para modelos ETS.\n\n\n\n\nTabela 6.16: Resultados dos ARIMA testados para a série de bens não duráveis\n\n\n\n\n\n\n.model\nsigma2\nlog_lik\nAIC\nAICc\nBIC\n\n\n\n\nauto\n14,09469\n-591,4166\n1196,833\n1197,374\n1220,428\n\n\narima011011\n14,94719\n-599,7525\n1205,505\n1205,619\n1215,617\n\n\narima210110\n16,92686\n-609,0919\n1226,184\n1226,374\n1239,666\n\n\n\n\n\n\n\n\nA Figura 6.29 apresenta os gráficos residuais para o modelo \\(ARIMA(4,1,1)(0,1,1)_{12}\\) para a série de bens de consumo não duráveis. O valor discrepante março de 2021 é atribuído à pandemia. Observa-se picos de autocorrelação parcial para defasagens próximas de 2 anos. No entanto, pelo teste de Ljung-Box, apresentado na Tabela 6.17, não há indícios suficientes que indicam a rejeição da hipótese de independência dos resíduos.\n\n\n\n\n\n\n\n\nFigura 6.29: Resíduos do modelo ARIMA(4,1,1)(0,1,1)12 para série de produção de bens de consumo não duráveis\n\n\n\n\n\n\n\n\n\nTabela 6.17: Teste de Ljung-Box para os resíduos da série de produção de bens de consumo não duráveis\n\n\n\n\n\n\nEstatística\npvalor\n\n\n\n\n25,45438\n0,1129033\n\n\n\n\n\n\n\n\nA Figura 6.30 apresenta graficamente os resultados de previsão para além de 2021, juntamente com os dados disponíveis e separados para teste. Observa-se boa proximidade com os dados não considerados para treinamento do modelo. Apesar da queda em 2021 devido à pandemia, o modelo treinado conseguiu apresentar uma boa projeção à curto e médio prazo.\n\n\n\n\n\n\n\n\nFigura 6.30: Previsão para 3 anos à frente para a série de bens de consumo não duráveis\n\n\n\n\n\nA Tabela 6.18 finaliza a análise comparando o desempenho dos modelos estimados aplicados aos dados de teste para a série de bens de consumo não duráveis. Confirma-se a superioridade do modelo estimado automaticamente.\n\n\n\n\nTabela 6.18: Métricas para comparar o desenho dos modelos testados para a série de bens de consumo não duráveis\n\n\n\n\n\n\nModelo\nRMSE\nMAE\nMAPE\n\n\n\n\narima011011\n5,184891\n4,167655\n4,123478\n\n\narima210110\n7,123093\n5,999505\n5,991313\n\n\nauto\n5,714044\n4,262668\n4,127184",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos auto-regressivos integrados de médias móveis (ARIMA)</span>"
    ]
  }
]